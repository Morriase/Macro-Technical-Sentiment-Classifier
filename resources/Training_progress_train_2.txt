7.1s 1 0.00s - Debugger warning: It seems that frozen modules are being used, which may
7.1s 2 0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
7.1s 3 0.00s - to python to disable frozen modules.
7.1s 4 0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
7.7s 5 0.00s - Debugger warning: It seems that frozen modules are being used, which may
7.7s 6 0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off
7.7s 7 0.00s - to python to disable frozen modules.
7.7s 8 0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.
10.3s 9 Cloning into 'Macro-Technical-Sentiment-Classifier'...
10.8s 10 remote: Enumerating objects: 729, done.[K
10.8s 11 remote: Counting objects:   0% (1/116)[K
remote: Counting objects:   1% (2/116)[K
remote: Counting objects:   2% (3/116)[K
remote: Counting objects:   3% (4/116)[K
remote: Counting objects:   4% (5/116)[K
remote: Counting objects:   5% (6/116)[K
remote: Counting objects:   6% (7/116)[K
remote: Counting objects:   7% (9/116)[K
remote: Counting objects:   8% (10/116)[K
remote: Counting objects:   9% (11/116)[K
remote: Counting objects:  10% (12/116)[K
remote: Counting objects:  11% (13/116)[K
remote: Counting objects:  12% (14/116)[K
remote: Counting objects:  13% (16/116)[K
remote: Counting objects:  14% (17/116)[K
remote: Counting objects:  15% (18/116)[K
remote: Counting objects:  16% (19/116)[K
remote: Counting objects:  17% (20/116)[K
remote: Counting objects:  18% (21/116)[K
remote: Counting objects:  19% (23/116)[K
remote: Counting objects:  20% (24/116)[K
remote: Counting objects:  21% (25/116)[K
remote: Counting objects:  22% (26/116)[K
remote: Counting objects:  23% (27/116)[K
remote: Counting objects:  24% (28/116)[K
remote: Counting objects:  25% (29/116)[K
remote: Counting objects:  26% (31/116)[K
remote: Counting objects:  27% (32/116)[K
remote: Counting objects:  28% (33/116)[K
remote: Counting objects:  29% (34/116)[K
remote: Counting objects:  30% (35/116)[K
remote: Counting objects:  31% (36/116)[K
remote: Counting objects:  32% (38/116)[K
remote: Counting objects:  33% (39/116)[K
remote: Counting objects:  34% (40/116)[K
remote: Counting objects:  35% (41/116)[K
remote: Counting objects:  36% (42/116)[K
remote: Counting objects:  37% (43/116)[K
remote: Counting objects:  38% (45/116)[K
remote: Counting objects:  39% (46/116)[K
remote: Counting objects:  40% (47/116)[K
remote: Counting objects:  41% (48/116)[K
remote: Counting objects:  42% (49/116)[K
remote: Counting objects:  43% (50/116)[K
remote: Counting objects:  44% (52/116)[K
remote: Counting objects:  45% (53/116)[K
remote: Counting objects:  46% (54/116)[K
remote: Counting objects:  47% (55/116)[K
remote: Counting objects:  48% (56/116)[K
remote: Counting objects:  49% (57/116)[K
remote: Counting objects:  50% (58/116)[K
remote: Counting objects:  51% (60/116)[K
remote: Counting objects:  52% (61/116)[K
remote: Counting objects:  53% (62/116)[K
remote: Counting objects:  54% (63/116)[K
remote: Counting objects:  55% (64/116)[K
remote: Counting objects:  56% (65/116)[K
remote: Counting objects:  57% (67/116)[K
remote: Counting objects:  58% (68/116)[K
remote: Counting objects:  59% (69/116)[K
remote: Counting objects:  60% (70/116)[K
remote: Counting objects:  61% (71/116)[K
remote: Counting objects:  62% (72/116)[K
remote: Counting objects:  63% (74/116)[K
remote: Counting objects:  64% (75/116)[K
remote: Counting objects:  65% (76/116)[K
remote: Counting objects:  66% (77/116)[K
remote: Counting objects:  67% (78/116)[K
remote: Counting objects:  68% (79/116)[K
remote: Counting objects:  69% (81/116)[K
remote: Counting objects:  70% (82/116)[K
remote: Counting objects:  71% (83/116)[K
remote: Counting objects:  72% (84/116)[K
remote: Counting objects:  73% (85/116)[K
remote: Counting objects:  74% (86/116)[K
remote: Counting objects:  75% (87/116)[K
remote: Counting objects:  76% (89/116)[K
remote: Counting objects:  77% (90/116)[K
remote: Counting objects:  78% (91/116)[K
remote: Counting objects:  79% (92/116)[K
remote: Counting objects:  80% (93/116)[K
remote: Counting objects:  81% (94/116)[K
remote: Counting objects:  82% (96/116)[K
remote: Counting objects:  83% (97/116)[K
remote: Counting objects:  84% (98/116)[K
remote: Counting objects:  85% (99/116)[K
remote: Counting objects:  86% (100/116)[K
remote: Counting objects:  87% (101/116)[K
remote: Counting objects:  88% (103/116)[K
remote: Counting objects:  89% (104/116)[K
remote: Counting objects:  90% (105/116)[K
remote: Counting objects:  91% (106/116)[K
remote: Counting objects:  92% (107/116)[K
remote: Counting objects:  93% (108/116)[K
remote: Counting objects:  94% (110/116)[K
remote: Counting objects:  95% (111/116)[K
remote: Counting objects:  96% (112/116)[K
remote: Counting objects:  97% (113/116)[K
remote: Counting objects:  98% (114/116)[K
remote: Counting objects:  99% (115/116)[K
remote: Counting objects: 100% (116/116)[K
remote: Counting objects: 100% (116/116), done.[K
10.8s 12 remote: Compressing objects:   1% (1/86)[K
remote: Compressing objects:   2% (2/86)[K
remote: Compressing objects:   3% (3/86)[K
remote: Compressing objects:   4% (4/86)[K
remote: Compressing objects:   5% (5/86)[K
remote: Compressing objects:   6% (6/86)[K
remote: Compressing objects:   8% (7/86)[K
remote: Compressing objects:   9% (8/86)[K
remote: Compressing objects:  10% (9/86)[K
remote: Compressing objects:  11% (10/86)[K
remote: Compressing objects:  12% (11/86)[K
remote: Compressing objects:  13% (12/86)[K
remote: Compressing objects:  15% (13/86)[K
remote: Compressing objects:  16% (14/86)[K
remote: Compressing objects:  17% (15/86)[K
remote: Compressing objects:  18% (16/86)[K
remote: Compressing objects:  19% (17/86)[K
remote: Compressing objects:  20% (18/86)[K
remote: Compressing objects:  22% (19/86)[K
remote: Compressing objects:  23% (20/86)[K
remote: Compressing objects:  24% (21/86)[K
remote: Compressing objects:  25% (22/86)[K
remote: Compressing objects:  26% (23/86)[K
remote: Compressing objects:  27% (24/86)[K
remote: Compressing objects:  29% (25/86)[K
remote: Compressing objects:  30% (26/86)[K
remote: Compressing objects:  31% (27/86)[K
remote: Compressing objects:  32% (28/86)[K
remote: Compressing objects:  33% (29/86)[K
remote: Compressing objects:  34% (30/86)[K
remote: Compressing objects:  36% (31/86)[K
remote: Compressing objects:  37% (32/86)[K
remote: Compressing objects:  38% (33/86)[K
remote: Compressing objects:  39% (34/86)[K
remote: Compressing objects:  40% (35/86)[K
remote: Compressing objects:  41% (36/86)[K
remote: Compressing objects:  43% (37/86)[K
remote: Compressing objects:  44% (38/86)[K
remote: Compressing objects:  45% (39/86)[K
remote: Compressing objects:  46% (40/86)[K
remote: Compressing objects:  47% (41/86)[K
remote: Compressing objects:  48% (42/86)[K
remote: Compressing objects:  50% (43/86)[K
remote: Compressing objects:  51% (44/86)[K
remote: Compressing objects:  52% (45/86)[K
remote: Compressing objects:  53% (46/86)[K
remote: Compressing objects:  54% (47/86)[K
remote: Compressing objects:  55% (48/86)[K
remote: Compressing objects:  56% (49/86)[K
remote: Compressing objects:  58% (50/86)[K
remote: Compressing objects:  59% (51/86)[K
remote: Compressing objects:  60% (52/86)[K
remote: Compressing objects:  61% (53/86)[K
remote: Compressing objects:  62% (54/86)[K
remote: Compressing objects:  63% (55/86)[K
remote: Compressing objects:  65% (56/86)[K
remote: Compressing objects:  66% (57/86)[K
remote: Compressing objects:  67% (58/86)[K
remote: Compressing objects:  68% (59/86)[K
remote: Compressing objects:  69% (60/86)[K
remote: Compressing objects:  70% (61/86)[K
remote: Compressing objects:  72% (62/86)[K
remote: Compressing objects:  73% (63/86)[K
remote: Compressing objects:  74% (64/86)[K
remote: Compressing objects:  75% (65/86)[K
remote: Compressing objects:  76% (66/86)[K
remote: Compressing objects:  77% (67/86)[K
remote: Compressing objects:  79% (68/86)[K
remote: Compressing objects:  80% (69/86)[K
remote: Compressing objects:  81% (70/86)[K
remote: Compressing objects:  82% (71/86)[K
remote: Compressing objects:  83% (72/86)[K
remote: Compressing objects:  84% (73/86)[K
remote: Compressing objects:  86% (74/86)[K
remote: Compressing objects:  87% (75/86)[K
remote: Compressing objects:  88% (76/86)[K
remote: Compressing objects:  89% (77/86)[K
remote: Compressing objects:  90% (78/86)[K
remote: Compressing objects:  91% (79/86)[K
remote: Compressing objects:  93% (80/86)[K
remote: Compressing objects:  94% (81/86)[K
remote: Compressing objects:  95% (82/86)[K
remote: Compressing objects:  96% (83/86)[K
remote: Compressing objects:  97% (84/86)[K
remote: Compressing objects:  98% (85/86)[K
remote: Compressing objects: 100% (86/86)[K
remote: Compressing objects: 100% (86/86), done.[K
12.1s 13 Receiving objects:   0% (1/729)
Receiving objects:   1% (8/729)
Receiving objects:   2% (15/729)
Receiving objects:   2% (16/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:   3% (22/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:   4% (30/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:   5% (37/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:   6% (44/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:   7% (52/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:   8% (59/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:   9% (66/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  10% (73/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  11% (81/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  12% (88/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  13% (95/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  14% (103/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  15% (110/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  16% (117/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  17% (124/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  18% (132/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  19% (139/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  20% (146/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  21% (154/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  22% (161/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  23% (168/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  24% (175/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  25% (183/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  26% (190/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  27% (197/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  28% (205/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  29% (212/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  30% (219/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  31% (226/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  32% (234/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  33% (241/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  34% (248/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  35% (256/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  36% (263/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  37% (270/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  38% (278/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  39% (285/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  40% (292/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  41% (299/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  42% (307/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  43% (314/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  44% (321/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  45% (329/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  46% (336/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  47% (343/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  48% (350/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  49% (358/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  50% (365/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  51% (372/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  52% (380/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  53% (387/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  54% (394/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  55% (401/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  56% (409/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  57% (416/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  58% (423/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  59% (431/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  60% (438/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  61% (445/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  62% (452/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  63% (460/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  64% (467/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  65% (474/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  66% (482/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  67% (489/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  68% (496/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  69% (504/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  70% (511/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  71% (518/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  72% (525/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  73% (533/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  74% (540/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  75% (547/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  76% (555/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  77% (562/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  78% (569/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  79% (576/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  80% (584/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  81% (591/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  82% (598/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  83% (606/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  84% (613/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  85% (620/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  86% (627/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  87% (635/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  88% (642/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  89% (649/729), 26.94 MiB | 26.96 MiB/s
remote: Total 729 (delta 29), reused 106 (delta 24), pack-reused 613 (from 1)[K
12.1s 14 Receiving objects:  90% (657/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  91% (664/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  92% (671/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  93% (678/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  94% (686/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  95% (693/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  96% (700/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  97% (708/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  98% (715/729), 26.94 MiB | 26.96 MiB/s
Receiving objects:  99% (722/729), 26.94 MiB | 26.96 MiB/s
Receiving objects: 100% (729/729), 26.94 MiB | 26.96 MiB/s
Receiving objects: 100% (729/729), 41.73 MiB | 31.33 MiB/s, done.
12.4s 15 Resolving deltas:   0% (0/411)
Resolving deltas:   1% (5/411)
Resolving deltas:   2% (9/411)
Resolving deltas:   3% (13/411)
Resolving deltas:   4% (17/411)
Resolving deltas:   5% (21/411)
Resolving deltas:   6% (25/411)
Resolving deltas:   7% (29/411)
Resolving deltas:   8% (33/411)
Resolving deltas:   9% (37/411)
Resolving deltas:  10% (42/411)
Resolving deltas:  11% (46/411)
Resolving deltas:  12% (50/411)
Resolving deltas:  13% (54/411)
Resolving deltas:  14% (58/411)
Resolving deltas:  15% (62/411)
Resolving deltas:  16% (66/411)
Resolving deltas:  17% (70/411)
Resolving deltas:  18% (74/411)
Resolving deltas:  19% (79/411)
Resolving deltas:  20% (83/411)
Resolving deltas:  21% (87/411)
Resolving deltas:  22% (91/411)
Resolving deltas:  23% (95/411)
Resolving deltas:  24% (99/411)
Resolving deltas:  25% (103/411)
Resolving deltas:  26% (107/411)
Resolving deltas:  27% (111/411)
Resolving deltas:  28% (116/411)
Resolving deltas:  29% (120/411)
Resolving deltas:  30% (124/411)
Resolving deltas:  31% (128/411)
Resolving deltas:  32% (132/411)
Resolving deltas:  33% (136/411)
Resolving deltas:  34% (140/411)
Resolving deltas:  35% (144/411)
Resolving deltas:  36% (148/411)
Resolving deltas:  37% (153/411)
Resolving deltas:  38% (157/411)
Resolving deltas:  39% (161/411)
Resolving deltas:  40% (165/411)
Resolving deltas:  41% (169/411)
Resolving deltas:  42% (173/411)
Resolving deltas:  43% (177/411)
Resolving deltas:  44% (181/411)
Resolving deltas:  45% (185/411)
Resolving deltas:  46% (190/411)
Resolving deltas:  47% (194/411)
Resolving deltas:  48% (198/411)
Resolving deltas:  49% (202/411)
Resolving deltas:  50% (206/411)
Resolving deltas:  51% (210/411)
Resolving deltas:  52% (214/411)
Resolving deltas:  53% (218/411)
Resolving deltas:  54% (222/411)
Resolving deltas:  55% (227/411)
Resolving deltas:  56% (231/411)
Resolving deltas:  57% (235/411)
Resolving deltas:  58% (239/411)
Resolving deltas:  59% (243/411)
Resolving deltas:  60% (247/411)
Resolving deltas:  61% (251/411)
Resolving deltas:  62% (255/411)
Resolving deltas:  63% (259/411)
Resolving deltas:  64% (264/411)
Resolving deltas:  65% (268/411)
Resolving deltas:  66% (272/411)
Resolving deltas:  67% (276/411)
Resolving deltas:  68% (280/411)
Resolving deltas:  69% (284/411)
Resolving deltas:  70% (288/411)
Resolving deltas:  71% (292/411)
Resolving deltas:  72% (296/411)
Resolving deltas:  73% (301/411)
Resolving deltas:  74% (305/411)
Resolving deltas:  75% (309/411)
Resolving deltas:  76% (313/411)
Resolving deltas:  77% (317/411)
Resolving deltas:  78% (321/411)
Resolving deltas:  79% (325/411)
Resolving deltas:  80% (329/411)
Resolving deltas:  81% (333/411)
Resolving deltas:  82% (338/411)
Resolving deltas:  83% (342/411)
Resolving deltas:  84% (346/411)
Resolving deltas:  85% (350/411)
Resolving deltas:  86% (354/411)
Resolving deltas:  87% (358/411)
Resolving deltas:  88% (362/411)
Resolving deltas:  89% (366/411)
Resolving deltas:  90% (370/411)
Resolving deltas:  91% (375/411)
Resolving deltas:  92% (379/411)
Resolving deltas:  93% (383/411)
Resolving deltas:  94% (387/411)
Resolving deltas:  95% (391/411)
Resolving deltas:  96% (395/411)
Resolving deltas:  97% (399/411)
Resolving deltas:  98% (403/411)
Resolving deltas:  99% (407/411)
Resolving deltas: 100% (411/411)
Resolving deltas: 100% (411/411), done.
14.0s 16 Filtering content: 100% (16/16)
Filtering content: 100% (16/16), 69.71 MiB | 53.71 MiB/s, done.
14.1s 17 /kaggle/working/Macro-Technical-Sentiment-Classifier
14.1s 18 /kaggle/working/Macro-Technical-Sentiment-Classifier
14.2s 19 total 564
14.2s 20 drwxr-xr-x 10 root root  4096 Nov 25 15:43 .
14.2s 21 drwxr-xr-x  3 root root  4096 Nov 25 15:43 ..
14.2s 22 -rw-r--r--  1 root root   713 Nov 25 15:43 ADAPTIVE_STOPLOSS_SYSTEM.md
14.2s 23 -rw-r--r--  1 root root   360 Nov 25 15:43 app.py
14.2s 24 -rw-r--r--  1 root root  6326 Nov 25 15:43 ARCHITECTURE.md
14.2s 25 -rw-r--r--  1 root root  9043 Nov 25 15:43 AUTOMATED_RETRAINING.md
14.2s 26 -rw-r--r--  1 root root  1586 Nov 25 15:43 CHANGES_APPLIED.txt
14.2s 27 -rw-r--r--  1 root root  7907 Nov 25 15:43 DAILY_TRADE_LIMIT.md
14.2s 28 -rw-r--r--  1 root root     0 Nov 25 15:43 DEPENDENCY_FIXES.md
14.2s 29 -rw-r--r--  1 root root  1526 Nov 25 15:43 deploy_hf.sh
14.2s 30 -rw-r--r--  1 root root  5061 Nov 25 15:43 DEPLOYMENT_COMPARISON.md
14.2s 31 -rw-r--r--  1 root root     0 Nov 25 15:43 DEPLOY_NOW.md
14.2s 32 -rw-r--r--  1 root root  5556 Nov 25 15:43 DEPLOY_TO_HF.sh
14.2s 33 -rw-r--r--  1 root root  2506 Nov 25 15:43 deploy_to_huggingface.sh
14.2s 34 -rw-r--r--  1 root root  2175 Nov 25 15:43 Dockerfile
14.2s 35 -rw-r--r--  1 root root  2405 Nov 25 15:43 Dockerfile.hf
14.2s 36 -rw-r--r--  1 root root   294 Nov 25 15:43 .dockerignore
14.2s 37 -rw-r--r--  1 root root  6157 Nov 25 15:43 download_macro_events.py
14.2s 38 -rw-r--r--  1 root root  5444 Nov 25 15:43 DOWNLOAD_MODELS.md
14.2s 39 -rw-r--r--  1 root root  2261 Nov 25 15:43 download_mt5_data.py
14.2s 40 -rw-r--r--  1 root root  5314 Nov 25 15:43 EA_INFERENCE_UPDATE.md
14.2s 41 -rw-r--r--  1 root root  3532 Nov 25 15:43 EA_OPTIMIZATION.md
14.2s 42 -rw-r--r--  1 root root  5920 Nov 25 15:43 EA_POSITION_MANAGEMENT.md
14.2s 43 -rw-r--r--  1 root root  7598 Nov 25 15:43 EA_SERVER_COMMUNICATION.md
14.2s 44 -rw-r--r--  1 root root  3710 Nov 25 15:43 ENUM_TIME_UPDATE.md
14.2s 45 -rw-r--r--  1 root root   576 Nov 25 15:43 .env.example
14.2s 46 -rw-r--r--  1 root root  2863 Nov 25 15:43 FEATURE_MISMATCH_FIX.md
14.2s 47 -rw-r--r--  1 root root     0 Nov 25 15:43 FIXES_APPLIED.md
14.2s 48 -rw-r--r--  1 root root  5442 Nov 25 15:43 FIXES_APPLIED_SUMMARY.md
14.2s 49 drwxr-xr-x  9 root root  4096 Nov 25 15:43 .git
14.2s 50 -rw-r--r--  1 root root   100 Nov 25 15:43 .gitattributes
14.2s 51 drwxr-xr-x  3 root root  4096 Nov 25 15:43 .github
14.2s 52 -rw-r--r--  1 root root  1051 Nov 25 15:43 .gitignore
14.2s 53 -rw-r--r--  1 root root  4578 Nov 25 15:43 HOW_MODEL_LEARNS.md
14.2s 54 -rw-r--r--  1 root root  3674 Nov 25 15:43 HUGGINGFACE_DEPLOYMENT_COMPLETE.md
14.2s 55 -rw-r--r--  1 root root  5476 Nov 25 15:43 HUGGINGFACE_DEPLOYMENT.md
14.2s 56 -rw-r--r--  1 root root  3404 Nov 25 15:43 IMPLEMENTATION_SUMMARY.md
14.2s 57 -rw-r--r--  1 root root  5477 Nov 25 15:43 INFERENCE_BUGS_CRITICAL.md
14.2s 58 -rw-r--r--  1 root root 24190 Nov 25 15:43 inference_server.py
14.2s 59 -rw-r--r--  1 root root 10050 Nov 25 15:43 KAGGLE_AUTOMATED_RETRAINING.md
14.2s 60 -rw-r--r--  1 root root   419 Nov 25 15:43 KAGGLE_FIX.md
14.2s 61 drwxr-xr-x  2 root root  4096 Nov 25 15:43 kaggle_notebooks
14.2s 62 -rw-r--r--  1 root root  6756 Nov 25 15:43 KAGGLE_SETUP.md
14.2s 63 -rw-r--r--  1 root root  3952 Nov 25 15:43 LOCAL_SERVER_GUIDE.md
14.2s 64 -rw-r--r--  1 root root 31572 Nov 25 15:43 main.py
14.2s 65 drwxr-xr-x  2 root root  4096 Nov 25 15:43 models
14.2s 66 drwxr-xr-x  2 root root  4096 Nov 25 15:43 MQL5
14.2s 67 -rw-r--r--  1 root root  2330 Nov 25 15:43 NEWS_KEYWORDS_CONFIG.txt
14.2s 68 -rw-r--r--  1 root root  8659 Nov 25 15:43 OVERFITTING_ANALYSIS.md
14.2s 69 -rw-r--r--  1 root root     0 Nov 25 15:43 OVERFITTING_FIXES_APPLIED.md
14.2s 70 -rw-r--r--  1 root root  4637 Nov 25 15:43 POSITION_DUPLICATE_FIX.md
14.2s 71 -rw-r--r--  1 root root 16013 Nov 25 15:43 prepare_kaggle_data.py
14.2s 72 -rw-r--r--  1 root root  3424 Nov 25 15:43 PRODUCT_OVERVIEW.txt
14.2s 73 -rw-r--r--  1 root root  1898 Nov 25 15:43 README_HF.md
14.2s 74 -rw-r--r--  1 root root 16786 Nov 25 15:43 README.md
14.2s 75 -rw-r--r--  1 root root  5802 Nov 25 15:43 RENDER_DEPLOYMENT.md
14.2s 76 -rw-r--r--  1 root root  3935 Nov 25 15:43 RENDER_DEPLOYMENT_VERIFIED.md
14.2s 77 -rw-r--r--  1 root root   857 Nov 25 15:43 .renderignore
14.2s 78 -rw-r--r--  1 root root  4805 Nov 25 15:43 RENDER_MEMORY_FIX.md
14.2s 79 -rw-r--r--  1 root root   470 Nov 25 15:43 render.yaml
14.2s 80 -rw-r--r--  1 root root  1520 Nov 25 15:43 requirements_kaggle.txt
14.2s 81 -rw-r--r--  1 root root  1492 Nov 25 15:43 requirements_render.txt
14.2s 82 -rw-r--r--  1 root root  1543 Nov 25 15:43 requirements.txt
14.2s 83 drwxr-xr-x  2 root root  4096 Nov 25 15:43 resources
14.2s 84 -rw-r--r--  1 root root 18127 Nov 25 15:43 RETRAINING_FLOW.md
14.2s 85 -rw-r--r--  1 root root  1096 Nov 25 15:43 run_local_server.py
14.2s 86 drwxr-xr-x  2 root root  4096 Nov 25 15:43 scripts
14.2s 87 -rw-r--r--  1 root root  4715 Nov 25 15:43 SESSION_FILTER_ENUM_GUIDE.md
14.2s 88 -rw-r--r--  1 root root  2476 Nov 25 15:43 SESSION_FILTER_IMPLEMENTATION.md
14.2s 89 -rw-r--r--  1 root root  1675 Nov 25 15:43 SESSION_FILTER_QUICK_START.md
14.2s 90 -rw-r--r--  1 root root  1159 Nov 25 15:43 setup_git_lfs.bat
14.2s 91 -rw-r--r--  1 root root  2295 Nov 25 15:43 SETUP_KAGGLE_CLI.sh
14.2s 92 -rw-r--r--  1 root root  9516 Nov 25 15:43 SETUP.md
14.2s 93 -rw-r--r--  1 root root     0 Nov 25 15:43 SIGNAL_QUALITY_INTEGRATION.md
14.2s 94 drwxr-xr-x  6 root root  4096 Nov 25 15:43 src
14.2s 95 -rw-r--r--  1 root root  1314 Nov 25 15:43 start.sh
14.2s 96 -rw-r--r--  1 root root  2744 Nov 25 15:43 TALIB_INSTALL_WINDOWS.md
14.2s 97 -rw-r--r--  1 root root  3724 Nov 25 15:43 test_docker.ps1
14.2s 98 -rw-r--r--  1 root root  2702 Nov 25 15:43 test_docker.sh
14.2s 99 -rw-r--r--  1 root root  4921 Nov 25 15:43 test_feature_alignment.py
14.2s 100 -rw-r--r--  1 root root  7250 Nov 25 15:43 test_hf_deployment.py
14.2s 101 -rw-r--r--  1 root root  1730 Nov 25 15:43 test_hf_simple.sh
14.2s 102 -rw-r--r--  1 root root 14480 Nov 25 15:43 test_inference_server.py
14.2s 103 -rw-r--r--  1 root root  5268 Nov 25 15:43 test_local_server.py
14.2s 104 -rw-r--r--  1 root root 11354 Nov 25 15:43 TRADING_SESSION_FILTER.md
14.2s 105 -rw-r--r--  1 root root  5743 Nov 25 15:43 validate_server.py
14.2s 106 -rw-r--r--  1 root root  1673 Nov 25 15:43 verify_all_models.py
14.2s 107 -rw-r--r--  1 root root   716 Nov 25 15:43 verify_scaler.py
16.7s 108 Collecting loguru
16.8s 109 Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)
16.8s 110 Downloading loguru-0.7.3-py3-none-any.whl (61 kB)
16.9s 111 [?25l   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m0.0/61.6 kB[0m [31m?[0m eta [36m-:--:--[0m
[2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m61.6/61.6 kB[0m [31m2.8 MB/s[0m eta [36m0:00:00[0m
18.8s 112 [?25hInstalling collected packages: loguru
18.8s 113 Successfully installed loguru-0.7.3
20.6s 114 Collecting TA-LIB
20.6s 115 Downloading ta_lib-0.6.8-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)
20.7s 116 Requirement already satisfied: build in /usr/local/lib/python3.11/dist-packages (from TA-LIB) (1.2.2.post1)
20.7s 117 Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from TA-LIB) (1.26.4)
20.7s 118 Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build->TA-LIB) (25.0)
20.7s 119 Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build->TA-LIB) (1.2.0)
20.7s 120 Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->TA-LIB) (1.3.8)
20.7s 121 Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->TA-LIB) (1.2.4)
20.7s 122 Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->TA-LIB) (0.1.1)
20.7s 123 Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->TA-LIB) (2025.2.0)
20.7s 124 Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->TA-LIB) (2022.2.0)
20.7s 125 Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->TA-LIB) (2.4.1)
20.7s 126 Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->TA-LIB) (2024.2.0)
20.7s 127 Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->TA-LIB) (2022.2.0)
20.7s 128 Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->TA-LIB) (1.4.0)
20.7s 129 Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->TA-LIB) (2024.2.0)
20.7s 130 Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->TA-LIB) (2024.2.0)
20.7s 131 Downloading ta_lib-0.6.8-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.1 MB)
20.8s 132 [?25l   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m0.0/4.1 MB[0m [31m?[0m eta [36m-:--:--[0m
[2K   [91mâ”â”â”â”[0m[90mâ•º[0m[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m0.5/4.1 MB[0m [31m13.5 MB/s[0m eta [36m0:00:01[0m
[2K   [91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[91mâ•¸[0m[90mâ”â”â”â”â”â”[0m [32m3.5/4.1 MB[0m [31m50.9 MB/s[0m eta [36m0:00:01[0m
[2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m4.1/4.1 MB[0m [31m40.4 MB/s[0m eta [36m0:00:00[0m
22.8s 133 [?25hInstalling collected packages: TA-LIB
22.9s 134 Successfully installed TA-LIB-0.6.8
117.5s 135 [31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
117.5s 136 bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.
117.5s 137 pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == "x86_64", but you have pyarrow 22.0.0 which is incompatible.
117.5s 138 cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == "x86_64", but you have pyarrow 22.0.0 which is incompatible.
117.5s 139 bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.
117.5s 140 bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.
117.5s 141 thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.
117.5s 142 libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.
117.5s 143 cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.
117.5s 144 pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.
117.5s 145 pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.
117.5s 146 pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.[0m[31m
125.0s 147 [0m[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
125.0s 148 bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.
125.0s 149 datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.
125.0s 150 bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.
125.0s 151 bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.
125.0s 152 cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.
125.0s 153 pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.[0m[31m
128.7s 154 [0mPyTorch version: 2.6.0+cu124
128.7s 155 CUDA available: True
128.7s 156 CUDA version: 12.4
128.7s 157 GPU: Tesla T4
129.0s 158 From https://github.com/Morriase/Macro-Technical-Sentiment-Classifier
129.0s 159 * branch            main       -> FETCH_HEAD
129.0s 160 Already up to date.
130.8s 161 [?25l     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m0.0/130.7 kB[0m [31m?[0m eta [36m-:--:--[0m
[2K     [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m130.7/130.7 kB[0m [31m4.5 MB/s[0m eta [36m0:00:00[0m
131.9s 162 [?25h[?25l   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m0.0/8.5 MB[0m [31m?[0m eta [36m-:--:--[0m
[2K   [91mâ”â”â”â”â”â”â”â”[0m[91mâ•¸[0m[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m1.9/8.5 MB[0m [31m56.7 MB/s[0m eta [36m0:00:01[0m
[2K   [91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[90mâ•º[0m [32m8.4/8.5 MB[0m [31m121.8 MB/s[0m eta [36m0:00:01[0m
[2K   [91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[91mâ•¸[0m [32m8.5/8.5 MB[0m [31m119.2 MB/s[0m eta [36m0:00:01[0m
[2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m8.5/8.5 MB[0m [31m77.6 MB/s[0m eta [36m0:00:00[0m
131.9s 163 [?25h[?25l   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m0.0/401.2 kB[0m [31m?[0m eta [36m-:--:--[0m
[2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m401.2/401.2 kB[0m [31m26.8 MB/s[0m eta [36m0:00:00[0m
132.0s 164 [?25h[?25l   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m0.0/3.6 MB[0m [31m?[0m eta [36m-:--:--[0m
[2K   [91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[91mâ•¸[0m [32m3.6/3.6 MB[0m [31m217.2 MB/s[0m eta [36m0:00:01[0m
[2K   [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [32m3.6/3.6 MB[0m [31m92.2 MB/s[0m eta [36m0:00:00[0m
140.5s 165 [?25h[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
140.5s 166 datasets 4.4.1 requires huggingface-hub<2.0,>=0.25.0, but you have huggingface-hub 0.23.0 which is incompatible.
140.5s 167 datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.
140.5s 168 sentence-transformers 5.1.2 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.
140.5s 169 diffusers 0.34.0 requires huggingface-hub>=0.27.0, but you have huggingface-hub 0.23.0 which is incompatible.
140.5s 170 peft 0.16.0 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.0 which is incompatible.
140.5s 171 gradio 5.38.1 requires huggingface-hub>=0.28.1, but you have huggingface-hub 0.23.0 which is incompatible.[0m[31m
141.0s 172 [0mFrom https://github.com/Morriase/Macro-Technical-Sentiment-Classifier
141.0s 173 * branch            main       -> FETCH_HEAD
141.0s 174 Already up to date.
141.1s 175 /kaggle/working/Macro-Technical-Sentiment-Classifier
168.9s 176 2025-11-25 15:46:28.012174: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
169.1s 177 WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
169.1s 178 E0000 00:00:1764085588.177532     164 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
169.1s 179 E0000 00:00:1764085588.228529     164 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
185.2s 180 2025-11-25 15:46:44 | INFO | main:<module>:63 | Running on Kaggle
185.2s 181 2025-11-25 15:46:44 | INFO | main:<module>:66 | GPU: Tesla T4
185.2s 182 2025-11-25 15:46:44 | INFO | main:<module>:67 | CUDA Version: 12.4
185.2s 183 2025-11-25 15:46:44 | INFO | main:<module>:70 | Device: cuda
185.2s 184 2025-11-25 15:46:44 | INFO | main:main:686 |
185.2s 185 ================================================================================
185.2s 186 2025-11-25 15:46:44 | INFO | main:main:687 | STARTING TRAINING FOR XAU_USD
185.2s 187 2025-11-25 15:46:44 | INFO | main:main:688 | ================================================================================
185.2s 188 
185.2s 189 2025-11-25 15:46:44 | INFO | kaggle_loader:__init__:36 | FX Data Directory: /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data
185.2s 190 2025-11-25 15:46:44 | INFO | kaggle_loader:__init__:37 | Macro Events Directory: /kaggle/input/macros-and-ohlc/data/kaggle_dataset/macro_events
185.2s 191 2025-11-25 15:46:44 | INFO | news_loader:__init__:38 | Kaggle News Dataset: miguelaenlle/massive-stock-news-analysis-db-for-nlpbacktests
185.2s 192 2025-11-25 15:46:44 | INFO | news_loader:__init__:39 | Kaggle News Data Directory: /kaggle/input/massive-stock-news-analysis-db-for-nlpbacktests
185.2s 193 2025-11-25 15:46:44 | INFO | main:__init__:98 | Using Kaggle dataset
185.2s 194 2025-11-25 15:46:44 | INFO | sentiment_features:__init__:39 | Loading sentiment model: ProsusAI/finbert
185.4s 195 config.json:   0%|                                    | 0.00/758 [00:00<?, ?B/s]
config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 758/758 [00:00<00:00, 3.39MB/s]
188.3s 196 pytorch_model.bin:   0%|                             | 0.00/438M [00:00<?, ?B/s]
pytorch_model.bin:   2%|â–Œ                    | 10.5M/438M [00:00<00:04, 102MB/s]
pytorch_model.bin:  10%|â–ˆâ–ˆ                   | 41.9M/438M [00:00<00:02, 185MB/s]
pytorch_model.bin:  17%|â–ˆâ–ˆâ–ˆâ–Œ                 | 73.4M/438M [00:00<00:01, 226MB/s]
pytorch_model.bin:  24%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                | 105M/438M [00:00<00:01, 229MB/s]
pytorch_model.bin:  31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š               | 136M/438M [00:00<00:01, 248MB/s]
pytorch_model.bin:  38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 168M/438M [00:00<00:01, 259MB/s]
pytorch_model.bin:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ            | 199M/438M [00:00<00:00, 269MB/s]
pytorch_model.bin:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ          | 231M/438M [00:00<00:00, 267MB/s]
pytorch_model.bin:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 262M/438M [00:01<00:00, 273MB/s]
pytorch_model.bin:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹       | 294M/438M [00:01<00:00, 277MB/s]
pytorch_model.bin:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 325M/438M [00:01<00:00, 280MB/s]
pytorch_model.bin:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 357M/438M [00:01<00:00, 280MB/s]
pytorch_model.bin:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 388M/438M [00:01<00:00, 281MB/s]
pytorch_model.bin:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 419M/438M [00:01<00:00, 283MB/s]
pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 438M/438M [00:01<00:00, 262MB/s]
189.0s 197 tokenizer_config.json:   0%|                          | 0.00/252 [00:00<?, ?B/s]
tokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 252/252 [00:00<00:00, 2.86MB/s]
189.1s 198 vocab.txt: 0.00B [00:00, ?B/s]
vocab.txt: 232kB [00:00, 12.4MB/s]
189.4s 199 special_tokens_map.json:   0%|                        | 0.00/112 [00:00<?, ?B/s]
special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112/112 [00:00<00:00, 826kB/s]
189.7s 200 2025-11-25 15:46:48 | SUCCESS | sentiment_features:__init__:50 | âœ“ Sentiment model loaded successfully
189.7s 201 2025-11-25 15:46:48 | SUCCESS | main:__init__:117 | âœ“ Sentiment features enabled
189.7s 202 2025-11-25 15:46:48 | INFO | main:__init__:130 | Pipeline initialized for XAU_USD
189.7s 203 2025-11-25 15:46:48 | INFO | main:run_full_pipeline:630 | ============================================================
189.7s 204 2025-11-25 15:46:48 | INFO | main:run_full_pipeline:631 | FOREX CLASSIFIER PIPELINE - FULL EXECUTION
189.7s 205 2025-11-25 15:46:48 | INFO | main:run_full_pipeline:632 | Currency Pair: XAU_USD
189.7s 206 2025-11-25 15:46:48 | INFO | main:run_full_pipeline:633 | ============================================================
189.7s 207 2025-11-25 15:46:48 | INFO | main:fetch_data:141 | ============================================================
189.7s 208 2025-11-25 15:46:48 | INFO | main:fetch_data:142 | STEP 1: DATA ACQUISITION
189.7s 209 2025-11-25 15:46:48 | INFO | main:fetch_data:143 | ============================================================
189.7s 210 2025-11-25 15:46:48 | INFO | main:fetch_data:148 | Loading data for XAU_USD from Kaggle dataset
189.7s 211 2025-11-25 15:46:48 | INFO | kaggle_loader:load_symbol_data:74 | Loading XAUUSD data from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data/XAUUSD_M5.parquet
189.8s 212 2025-11-25 15:46:48 | INFO | kaggle_loader:load_symbol_data:77 | Loaded 80,000 candles for XAUUSD
189.8s 213 2025-11-25 15:46:48 | INFO | kaggle_loader:load_symbol_data:78 | Date range: 2024-10-09 19:15:00 to 2025-11-25 17:20:00
189.8s 214 2025-11-25 15:46:48 | INFO | main:fetch_data:154 | Loaded 80,000 M5 candles
189.8s 215 2025-11-25 15:46:48 | INFO | kaggle_loader:load_symbol_data:74 | Loading XAUUSD data from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data/XAUUSD_H1.parquet
189.8s 216 2025-11-25 15:46:48 | INFO | kaggle_loader:load_symbol_data:77 | Loaded 7,000 candles for XAUUSD
189.8s 217 2025-11-25 15:46:48 | INFO | kaggle_loader:load_symbol_data:78 | Date range: 2024-09-19 12:00:00 to 2025-11-25 17:00:00
189.8s 218 2025-11-25 15:46:48 | INFO | main:fetch_data:163 | Loaded 7,000 H1 candles
189.8s 219 2025-11-25 15:46:48 | INFO | kaggle_loader:load_symbol_data:74 | Loading XAUUSD data from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data/XAUUSD_H4.parquet
189.8s 220 2025-11-25 15:46:48 | INFO | kaggle_loader:load_symbol_data:77 | Loaded 2,000 candles for XAUUSD
189.8s 221 2025-11-25 15:46:48 | INFO | kaggle_loader:load_symbol_data:78 | Date range: 2024-08-12 08:00:00 to 2025-11-25 16:00:00
189.8s 222 2025-11-25 15:46:48 | INFO | main:fetch_data:163 | Loaded 2,000 H4 candles
189.8s 223 2025-11-25 15:46:48 | INFO | kaggle_loader:load_macro_events:153 | Loading macro events for XAUUSD from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/macro_events/XAUUSD_events.parquet
189.8s 224 2025-11-25 15:46:48 | INFO | kaggle_loader:load_macro_events:156 | Loaded 45 events for XAUUSD
189.8s 225 2025-11-25 15:46:48 | INFO | kaggle_loader:load_macro_events:157 | Date range: 2024-10-18 17:29:28.981847 to 2025-10-17 17:29:28.981847
189.8s 226 2025-11-25 15:46:48 | SUCCESS | main:fetch_data:171 | âœ“ Loaded 45 macro events
189.8s 227 2025-11-25 15:46:48 | WARNING | news_loader:_download_and_unzip_data:53 | News dataset not found at /kaggle/input/massive-stock-news-analysis-db-for-nlpbacktests/analyst_ratings_processed.csv
189.8s 228 2025-11-25 15:46:48 | WARNING | news_loader:_download_and_unzip_data:54 | News sentiment features will be disabled. To enable, attach 'massive-stock-news-analysis-db-for-nlpbacktests' as input.
189.8s 229 2025-11-25 15:46:48 | INFO | news_loader:load_historical_news:105 | News dataset unavailable - returning empty DataFrame
189.8s 230 2025-11-25 15:46:48 | INFO | main:fetch_data:199 | Fetched 80000 primary price bars
189.8s 231 2025-11-25 15:46:48 | INFO | main:engineer_features:205 | ============================================================
189.8s 232 2025-11-25 15:46:48 | INFO | main:engineer_features:206 | STEP 2: FEATURE ENGINEERING
189.8s 233 2025-11-25 15:46:48 | INFO | main:engineer_features:207 | ============================================================
189.8s 234 2025-11-25 15:46:48 | INFO | main:engineer_features:213 | Calculating base technical features on primary timeframe...
189.9s 235 2025-11-25 15:46:49 | SUCCESS | main:engineer_features:219 | âœ“ Calculated 67 base features.
189.9s 236 2025-11-25 15:46:49 | INFO | technical_features:add_multi_timeframe_features:259 | Adding multi-timeframe features and regime classification...
190.0s 237 2025-11-25 15:46:49 | INFO | technical_features:add_multi_timeframe_features:263 | Calculating features for H1 timeframe...
190.0s 238 2025-11-25 15:46:49 | SUCCESS | technical_features:add_multi_timeframe_features:289 | âœ“ Merged H1 features.
190.0s 239 2025-11-25 15:46:49 | INFO | technical_features:add_multi_timeframe_features:263 | Calculating features for H4 timeframe...
190.1s 240 2025-11-25 15:46:49 | SUCCESS | technical_features:add_multi_timeframe_features:289 | âœ“ Merged H4 features.
190.1s 241 2025-11-25 15:46:49 | INFO | main:engineer_features:276 | Dropped 0 rows with NaNs after feature engineering.
190.1s 242 2025-11-25 15:46:49 | INFO | main:engineer_features:278 | âœ“ 86 total features created, 79800 samples ready.
190.1s 243 2025-11-25 15:46:49 | INFO | main:create_target:295 | ============================================================
190.1s 244 2025-11-25 15:46:49 | INFO | main:create_target:296 | STEP 3: TARGET CREATION
190.1s 245 2025-11-25 15:46:49 | INFO | main:create_target:297 | ============================================================
190.1s 246 2025-11-25 15:46:49 | INFO | main:create_target:314 | Using pip multiplier for XAU_USD: 10000
190.1s 247 2025-11-25 15:46:49 | INFO | main:create_target:325 | Using fixed threshold: 4.0 pips
190.1s 248 2025-11-25 15:46:49 | INFO | main:create_target:381 | Target class distribution:
190.1s 249 2025-11-25 15:46:49 | INFO | main:create_target:385 |   Buy: 41721 (52.3%)
190.1s 250 2025-11-25 15:46:49 | INFO | main:create_target:385 |   Sell: 37949 (47.6%)
190.1s 251 2025-11-25 15:46:49 | INFO | main:create_target:385 |   Hold: 124 (0.2%)
190.1s 252 2025-11-25 15:46:49 | INFO | main:train_model:399 | ============================================================
190.1s 253 2025-11-25 15:46:49 | INFO | main:train_model:400 | STEP 4: MODEL TRAINING
190.1s 254 2025-11-25 15:46:49 | INFO | main:train_model:401 | ============================================================
190.1s 255 2025-11-25 15:46:49 | INFO | main:train_model:417 | Using 81 features for training
190.1s 256 2025-11-25 15:46:49 | INFO | walk_forward:run_walk_forward_optimization:285 | Starting Walk-Forward Optimization
190.1s 257 2025-11-25 15:46:49 | INFO | walk_forward:split:94 | Split 1: Train [2024-10-10 12:55:00 to 2025-04-10 12:50:00], Test [2025-04-10 12:55:00 to 2025-06-10 12:50:00]
190.1s 258 2025-11-25 15:46:49 | INFO | walk_forward:run_walk_forward_optimization:291 |
190.1s 259 ============================================================
190.1s 260 2025-11-25 15:46:49 | INFO | walk_forward:run_walk_forward_optimization:292 | Walk-Forward Fold 1
190.1s 261 2025-11-25 15:46:49 | INFO | walk_forward:run_walk_forward_optimization:293 | ============================================================
190.2s 262 2025-11-25 15:46:49 | INFO | walk_forward:optimize_hyperparameters:240 | Starting hyperparameter optimization
190.2s 263 [32m[I 2025-11-25 15:46:49,303][0m A new study created in memory with name: no-name-536a2564-9e16-475a-8c37-208547a44cc5[0m
190.3s 264 0%|                                                     | 0/5 [00:00<?, ?it/s]2025-11-25 15:46:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
190.3s 265 2025-11-25 15:46:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
190.3s 266 2025-11-25 15:46:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
190.3s 267 2025-11-25 15:46:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
217.0s 268 2025-11-25 15:47:16 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8267, Val Loss: 0.8194, Train Acc: 0.5570, Val Acc: 0.5159
222.1s 269 2025-11-25 15:47:21 | INFO | lstm_model:fit:461 | Early stopping at epoch 13 - Val Loss: 0.8219
222.5s 270 2025-11-25 15:47:21 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
225.6s 271 2025-11-25 15:47:24 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8282, Val Loss: 0.8189, Train Acc: 0.5400, Val Acc: 0.5443
236.2s 272 2025-11-25 15:47:35 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8275, Val Loss: 0.8264, Train Acc: 0.5140, Val Acc: 0.5159
245.9s 273 2025-11-25 15:47:44 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8204, Val Loss: 0.8169, Train Acc: 0.5300, Val Acc: 0.5197
255.2s 274 2025-11-25 15:47:54 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 0.8197
255.7s 275 2025-11-25 15:47:54 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
258.9s 276 2025-11-25 15:47:58 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8198, Val Loss: 0.8215, Train Acc: 0.5450, Val Acc: 0.5043
264.7s 277 2025-11-25 15:48:03 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8123, Val Loss: 0.8197, Train Acc: 0.5790, Val Acc: 0.5390
282.6s 278 2025-11-25 15:48:21 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8032, Val Loss: 0.8186, Train Acc: 0.6030, Val Acc: 0.5486
287.0s 279 2025-11-25 15:48:26 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8146, Val Loss: 0.8230, Train Acc: 0.5760, Val Acc: 0.5062
289.8s 280 2025-11-25 15:48:28 | INFO | lstm_model:fit:461 | Early stopping at epoch 21 - Val Loss: 0.8247
296.7s 281 2025-11-25 15:48:35 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8273, Val Loss: 0.8190, Train Acc: 0.5480, Val Acc: 0.5159
299.3s 282 2025-11-25 15:48:38 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.7856, Val Loss: 0.8520, Train Acc: 0.6220, Val Acc: 0.5478
315.8s 283 2025-11-25 15:48:54 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.7563, Val Loss: 0.9063, Train Acc: 0.6750, Val Acc: 0.5510
319.2s 284 2025-11-25 15:48:58 | INFO | lstm_model:fit:461 | Early stopping at epoch 62 - Val Loss: 0.9317
319.5s 285 2025-11-25 15:48:58 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
323.7s 286 2025-11-25 15:49:02 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8180, Val Loss: 0.8300, Train Acc: 0.5700, Val Acc: 0.5045
326.9s 287 2025-11-25 15:49:05 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8186, Val Loss: 0.8138, Train Acc: 0.5620, Val Acc: 0.5433
335.0s 288 2025-11-25 15:49:14 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8229, Val Loss: 0.8222, Train Acc: 0.5510, Val Acc: 0.5191
345.1s 289 2025-11-25 15:49:24 | INFO | lstm_model:fit:461 | Early stopping at epoch 15 - Val Loss: 0.8207
354.4s 290 2025-11-25 15:49:33 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8107, Val Loss: 0.8141, Train Acc: 0.5760, Val Acc: 0.5377
354.4s 291 2025-11-25 15:49:33 | INFO | lstm_model:fit:461 | Early stopping at epoch 30 - Val Loss: 0.8141
354.8s 292 2025-11-25 15:49:33 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
359.3s 293 2025-11-25 15:49:38 | INFO | lstm_model:fit:461 | Early stopping at epoch 16 - Val Loss: 0.8222
363.0s 294 2025-11-25 15:49:42 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8201, Val Loss: 0.8269, Train Acc: 0.5220, Val Acc: 0.5062
395.1s 295 2025-11-25 15:50:14 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8127, Val Loss: 0.8274, Train Acc: 0.5630, Val Acc: 0.5041
418.2s 296 2025-11-25 15:50:37 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8226, Val Loss: 0.8178, Train Acc: 0.5280, Val Acc: 0.5478
428.9s 297 2025-11-25 15:50:47 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8101, Val Loss: 0.8215, Train Acc: 0.5720, Val Acc: 0.5079
432.3s 298 2025-11-25 15:50:51 | INFO | lstm_model:fit:461 | Early stopping at epoch 31 - Val Loss: 0.8229
438.5s 299 2025-11-25 15:50:57 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8220, Val Loss: 0.8224, Train Acc: 0.5230, Val Acc: 0.5191
447.7s 300 2025-11-25 15:51:06 | INFO | lstm_model:fit:461 | Early stopping at epoch 16 - Val Loss: 0.8205
448.1s 301 2025-11-25 15:51:07 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
497.2s 302 2025-11-25 15:51:56 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8226, Val Loss: 0.8222, Train Acc: 0.5120, Val Acc: 0.5191
501.7s 303 2025-11-25 15:52:00 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8211, Val Loss: 0.8223, Train Acc: 0.5220, Val Acc: 0.5191
520.5s 304 2025-11-25 15:52:19 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8220, Val Loss: 0.8204, Train Acc: 0.5150, Val Acc: 0.5221
545.4s 305 2025-11-25 15:52:44 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8214, Val Loss: 0.8222, Train Acc: 0.5170, Val Acc: 0.5191
549.3s 306 2025-11-25 15:52:48 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8222, Val Loss: 0.8207, Train Acc: 0.5420, Val Acc: 0.5062
572.2s 307 2025-11-25 15:53:11 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8209, Val Loss: 0.8221, Train Acc: 0.5270, Val Acc: 0.5191
585.9s 308 2025-11-25 15:53:24 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8213, Val Loss: 0.8204, Train Acc: 0.5010, Val Acc: 0.5221
593.5s 309 2025-11-25 15:53:32 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8210, Val Loss: 0.8224, Train Acc: 0.5160, Val Acc: 0.5191
607.3s 310 2025-11-25 15:53:46 | INFO | lstm_model:fit:461 | Early stopping at epoch 33 - Val Loss: 0.8222
611.9s 311 2025-11-25 15:53:51 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8212, Val Loss: 0.8202, Train Acc: 0.5240, Val Acc: 0.5062
616.6s 312 2025-11-25 15:53:55 | INFO | lstm_model:fit:461 | Early stopping at epoch 21 - Val Loss: 0.8201
617.9s 313 2025-11-25 15:53:56 | INFO | lstm_model:fit:461 | Early stopping at epoch 25 - Val Loss: 0.8205
618.2s 314 2025-11-25 15:53:57 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
618.2s 315 2025-11-25 15:53:57 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
624.0s 316 2025-11-25 15:54:03 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
630.5s 317 2025-11-25 15:54:09 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8205, Val Loss: 0.8221, Train Acc: 0.5430, Val Acc: 0.5191
630.5s 318 2025-11-25 15:54:09 | INFO | lstm_model:fit:461 | Early stopping at epoch 40 - Val Loss: 0.8221
688.9s 319 2025-11-25 15:55:07 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8229, Val Loss: 0.8186, Train Acc: 0.5370, Val Acc: 0.5478
705.8s 320 2025-11-25 15:55:24 | INFO | lstm_model:fit:461 | Early stopping at epoch 13 - Val Loss: 0.8194
706.2s 321 2025-11-25 15:55:25 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
733.8s 322 2025-11-25 15:55:52 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8227, Val Loss: 0.8178, Train Acc: 0.5410, Val Acc: 0.5478
757.6s 323 2025-11-25 15:56:16 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8215
790.6s 324 2025-11-25 15:56:49 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8216, Val Loss: 0.8212, Train Acc: 0.5300, Val Acc: 0.5221
805.3s 325 2025-11-25 15:57:04 | INFO | lstm_model:fit:461 | Early stopping at epoch 19 - Val Loss: 0.8171
805.6s 326 2025-11-25 15:57:04 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
843.9s 327 2025-11-25 15:57:42 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8223, Val Loss: 0.8221, Train Acc: 0.4870, Val Acc: 0.5191
857.2s 328 2025-11-25 15:57:56 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8212, Val Loss: 0.8208, Train Acc: 0.5210, Val Acc: 0.5221
863.7s 329 2025-11-25 15:58:02 | INFO | lstm_model:fit:461 | Early stopping at epoch 21 - Val Loss: 0.8204
864.1s 330 2025-11-25 15:58:03 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
864.1s 331 2025-11-25 15:58:03 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
877.3s 332 2025-11-25 15:58:16 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
883.8s 333 2025-11-25 15:58:22 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8209
907.6s 334 2025-11-25 15:58:46 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 0.8222
924.8s 335 2025-11-25 15:59:03 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8221, Val Loss: 0.8219, Train Acc: 0.5160, Val Acc: 0.5221
1007.1s 336 2025-11-25 16:00:26 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8205
1021.7s 337 2025-11-25 16:00:40 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8211, Val Loss: 0.8205, Train Acc: 0.5450, Val Acc: 0.5221
1036.7s 338 2025-11-25 16:00:55 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8212
1120.3s 339 2025-11-25 16:02:19 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8209, Val Loss: 0.8204, Train Acc: 0.5550, Val Acc: 0.5221
1129.8s 340 2025-11-25 16:02:28 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8204
1176.6s 341 2025-11-25 16:03:15 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8225, Val Loss: 0.8191, Train Acc: 0.5180, Val Acc: 0.5478
1180.7s 342 2025-11-25 16:03:19 | INFO | lstm_model:fit:461 | Early stopping at epoch 36 - Val Loss: 0.8206
1181.1s 343 2025-11-25 16:03:20 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
1181.1s 344 2025-11-25 16:03:20 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
1185.8s 345 2025-11-25 16:03:24 | INFO | lstm_model:fit:461 | Early stopping at epoch 11 - Val Loss: 0.8201
1186.0s 346 2025-11-25 16:03:25 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
1190.4s 347 2025-11-25 16:03:29 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8208
1207.8s 348 2025-11-25 16:03:46 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
1250.4s 349 2025-11-25 16:04:29 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8204
1250.5s 350 2025-11-25 16:04:29 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (28138, 6)
1250.5s 351 2025-11-25 16:04:29 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
1250.6s 352 [16:04:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
1250.6s 353 
1250.6s 354 E.g. tree_method = "hist", device = "cuda"
1250.6s 355 
1251.5s 356 [16:04:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
1251.5s 357 
1251.5s 358 E.g. tree_method = "hist", device = "cuda"
1251.5s 359 
1251.5s 360 2025-11-25 16:04:30 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
1251.8s 361 [16:04:30] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.
1251.8s 362 Potential solutions:
1251.8s 363 - Use a data structure that matches the device ordinal in the booster.
1251.8s 364 - Set the device for booster before call to inplace_predict.
1251.8s 365 
1251.8s 366 This warning will only be shown once.
1251.8s 367 
1251.9s 368 [32m[I 2025-11-25 16:04:30,950][0m Trial 2 finished with value: 1.7263565891472867 and parameters: {'learning_rate': 0.0649328066376619, 'max_depth': 4, 'n_estimators': 106, 'subsample': 0.8628755429341552, 'colsample_bytree': 0.9217775993487479, 'min_child_weight': 7, 'gamma': 0.004289564167448745, 'reg_alpha': 0.07218581571499577, 'reg_lambda': 1.6341798591879004}. Best is trial 2 with value: 1.7263565891472867.[0m
1251.9s 369 0%|                                                     | 0/5 [17:41<?, ?it/s]
Best trial: 2. Best value: 1.72636:   0%|                 | 0/5 [17:41<?, ?it/s]
Best trial: 2. Best value: 1.72636:  20%|â–ˆ    | 1/5 [17:41<1:10:46, 1061.65s/it]
Best trial: 2. Best value: 1.72636:  20%|â–| 1/5 [17:41<1:10:46, 1061.65s/it, 1062025-11-25 16:04:31 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
1304.5s 370 2025-11-25 16:05:23 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8282, Val Loss: 0.8193, Train Acc: 0.5540, Val Acc: 0.5159
1315.9s 371 2025-11-25 16:05:34 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8186, Val Loss: 0.8154, Train Acc: 0.5740, Val Acc: 0.5392
1327.2s 372 2025-11-25 16:05:46 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8093, Val Loss: 0.8164, Train Acc: 0.5900, Val Acc: 0.5473
1338.5s 373 2025-11-25 16:05:57 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8020, Val Loss: 0.8173, Train Acc: 0.6040, Val Acc: 0.5311
1345.4s 374 2025-11-25 16:06:04 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8206
1350.1s 375 2025-11-25 16:06:09 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.7801, Val Loss: 0.8333, Train Acc: 0.6510, Val Acc: 0.5548
1361.4s 376 2025-11-25 16:06:20 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.7505, Val Loss: 0.8673, Train Acc: 0.6690, Val Acc: 0.5589
1371.6s 377 2025-11-25 16:06:30 | INFO | lstm_model:fit:461 | Early stopping at epoch 69 - Val Loss: 0.8784
1372.1s 378 2025-11-25 16:06:31 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
1419.5s 379 2025-11-25 16:07:18 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8214
1432.0s 380 2025-11-25 16:07:31 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8189, Val Loss: 0.8306, Train Acc: 0.5230, Val Acc: 0.5073
1449.9s 381 2025-11-25 16:07:48 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 0.8278
1490.2s 382 2025-11-25 16:08:29 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8219, Val Loss: 0.8210, Train Acc: 0.5110, Val Acc: 0.5221
1500.2s 383 2025-11-25 16:08:39 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8204
1528.6s 384 2025-11-25 16:09:07 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8223, Val Loss: 0.8223, Train Acc: 0.5330, Val Acc: 0.5191
1538.0s 385 2025-11-25 16:09:17 | INFO | lstm_model:fit:461 | Early stopping at epoch 13 - Val Loss: 0.8225
1575.4s 386 2025-11-25 16:09:54 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 0.8206
1575.7s 387 2025-11-25 16:09:54 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
1575.7s 388 2025-11-25 16:09:54 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
1628.4s 389 2025-11-25 16:10:47 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8210
1636.6s 390 2025-11-25 16:10:55 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8227, Val Loss: 0.8170, Train Acc: 0.5220, Val Acc: 0.5478
1640.9s 391 2025-11-25 16:10:59 | INFO | lstm_model:fit:461 | Early stopping at epoch 11 - Val Loss: 0.8168
1641.2s 392 2025-11-25 16:11:00 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
1651.9s 393 2025-11-25 16:11:11 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8202
1652.2s 394 2025-11-25 16:11:11 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (28138, 6)
1652.2s 395 2025-11-25 16:11:11 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
1652.2s 396 [16:11:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
1652.2s 397 
1652.2s 398 E.g. tree_method = "hist", device = "cuda"
1652.2s 399 
1653.1s 400 [16:11:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
1653.1s 401 
1653.1s 402 E.g. tree_method = "hist", device = "cuda"
1653.1s 403 
1653.1s 404 2025-11-25 16:11:12 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
1653.6s 405 [32m[I 2025-11-25 16:11:12,659][0m Trial 1 finished with value: 1.6765601217656012 and parameters: {'learning_rate': 0.022788505353177297, 'max_depth': 3, 'n_estimators': 496, 'subsample': 0.9609052999619875, 'colsample_bytree': 0.6590220394650367, 'min_child_weight': 5, 'gamma': 0.16570468867784127, 'reg_alpha': 0.07373258924526459, 'reg_lambda': 1.5802477416518506}. Best is trial 2 with value: 1.7263565891472867.[0m
1738.4s 406 Best trial: 2. Best value: 1.72636:  20%|â–| 1/5 [24:23<1:10:46, 1061.65s/it, 106
Best trial: 2. Best value: 1.72636:  20%|â–| 1/5 [24:23<1:10:46, 1061.65s/it, 106
Best trial: 2. Best value: 1.72636:  40%|â–| 2/5 [24:23<33:40, 673.45s/it, 1061.6
Best trial: 2. Best value: 1.72636:  40%|â–| 2/5 [24:23<33:40, 673.45s/it, 1463.32025-11-25 16:12:37 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8206
1741.6s 407 2025-11-25 16:12:40 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8216, Val Loss: 0.8207, Train Acc: 0.5240, Val Acc: 0.5221
1765.9s 408 2025-11-25 16:13:04 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
1780.5s 409 2025-11-25 16:13:19 | INFO | lstm_model:fit:461 | Early stopping at epoch 19 - Val Loss: 0.8211
1780.9s 410 2025-11-25 16:13:19 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
1780.9s 411 2025-11-25 16:13:19 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
1834.8s 412 2025-11-25 16:14:13 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
1858.9s 413 2025-11-25 16:14:38 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8204
1940.7s 414 2025-11-25 16:15:59 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8213
1948.2s 415 2025-11-25 16:16:07 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8214
1989.1s 416 2025-11-25 16:16:48 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8204
1989.2s 417 2025-11-25 16:16:48 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (28138, 6)
1989.2s 418 2025-11-25 16:16:48 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
1989.3s 419 [16:16:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
1989.3s 420 
1989.3s 421 E.g. tree_method = "hist", device = "cuda"
1989.3s 422 
1990.0s 423 [16:16:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
1990.0s 424 
1990.0s 425 E.g. tree_method = "hist", device = "cuda"
1990.0s 426 
1990.0s 427 2025-11-25 16:16:49 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
1990.4s 428 [32m[I 2025-11-25 16:16:49,472][0m Trial 3 finished with value: 1.6315001870557426 and parameters: {'learning_rate': 0.0572003775155309, 'max_depth': 8, 'n_estimators': 201, 'subsample': 0.7407917483616102, 'colsample_bytree': 0.6550254969952741, 'min_child_weight': 4, 'gamma': 0.2815908096302641, 'reg_alpha': 0.015189779509419922, 'reg_lambda': 1.4273175382525474}. Best is trial 2 with value: 1.7263565891472867.[0m
2030.9s 429 Best trial: 2. Best value: 1.72636:  40%|â–| 2/5 [30:00<33:40, 673.45s/it, 1463.3
Best trial: 2. Best value: 1.72636:  40%|â–| 2/5 [30:00<33:40, 673.45s/it, 1463.3
Best trial: 2. Best value: 1.72636:  60%|â–Œ| 3/5 [30:00<17:19, 519.73s/it, 1463.3
Best trial: 2. Best value: 1.72636:  60%|â–Œ| 3/5 [30:00<17:19, 519.73s/it, 1800.12025-11-25 16:17:29 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8208
2067.2s 430 2025-11-25 16:18:06 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8209
2109.4s 431 2025-11-25 16:18:48 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8206
2164.4s 432 2025-11-25 16:19:43 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8205
2187.7s 433 2025-11-25 16:20:06 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8205
2261.1s 434 2025-11-25 16:21:20 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8206
2265.8s 435 2025-11-25 16:21:24 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8203
2265.9s 436 2025-11-25 16:21:25 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (28138, 6)
2265.9s 437 2025-11-25 16:21:25 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
2266.0s 438 [16:21:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
2266.0s 439 
2266.0s 440 E.g. tree_method = "hist", device = "cuda"
2266.0s 441 
2266.5s 442 [16:21:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
2266.5s 443 
2266.5s 444 E.g. tree_method = "hist", device = "cuda"
2266.5s 445 
2266.5s 446 2025-11-25 16:21:25 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
2266.8s 447 [32m[I 2025-11-25 16:21:25,890][0m Trial 4 finished with value: 1.9604377104377104 and parameters: {'learning_rate': 0.0011973894779193325, 'max_depth': 9, 'n_estimators': 217, 'subsample': 0.980227069919458, 'colsample_bytree': 0.919655477624138, 'min_child_weight': 1, 'gamma': 0.03496344585672595, 'reg_alpha': 0.008267371753433962, 'reg_lambda': 0.5034118985625824}. Best is trial 4 with value: 1.9604377104377104.[0m
2321.6s 448 Best trial: 2. Best value: 1.72636:  60%|â–Œ| 3/5 [34:36<17:19, 519.73s/it, 1800.1
Best trial: 4. Best value: 1.96044:  60%|â–Œ| 3/5 [34:36<17:19, 519.73s/it, 1800.1
Best trial: 4. Best value: 1.96044:  80%|â–Š| 4/5 [34:36<07:03, 423.68s/it, 1800.1
Best trial: 4. Best value: 1.96044:  80%|â–Š| 4/5 [34:36<07:03, 423.68s/it, 2076.52025-11-25 16:22:20 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8203
2321.7s 449 2025-11-25 16:22:20 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (28138, 6)
2321.7s 450 2025-11-25 16:22:20 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
2321.8s 451 [16:22:20] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
2321.8s 452 
2321.8s 453 E.g. tree_method = "hist", device = "cuda"
2321.8s 454 
2322.1s 455 [16:22:21] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
2322.1s 456 
2322.1s 457 E.g. tree_method = "hist", device = "cuda"
2322.1s 458 
2322.2s 459 2025-11-25 16:22:21 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
2322.6s 460 [32m[I 2025-11-25 16:22:21,733][0m Trial 0 finished with value: 1.9616842105263157 and parameters: {'learning_rate': 0.004076405612726199, 'max_depth': 10, 'n_estimators': 408, 'subsample': 0.9620422239724771, 'colsample_bytree': 0.9016978475481885, 'min_child_weight': 4, 'gamma': 0.34901425278762777, 'reg_alpha': 0.06454837369528385, 'reg_lambda': 1.7455572018133656}. Best is trial 0 with value: 1.9616842105263157.[0m
2322.6s 461 Best trial: 4. Best value: 1.96044:  80%|â–Š| 4/5 [35:32<07:03, 423.68s/it, 2076.5
Best trial: 0. Best value: 1.96168:  80%|â–Š| 4/5 [35:32<07:03, 423.68s/it, 2076.5
Best trial: 0. Best value: 1.96168: 100%|â–ˆ| 5/5 [35:32<00:00, 291.03s/it, 2076.5
Best trial: 0. Best value: 1.96168: 100%|â–ˆ| 5/5 [35:32<00:00, 291.03s/it, 2132.4
Best trial: 0. Best value: 1.96168: 100%|â–ˆ| 5/5 [35:32<00:00, 426.49s/it, 2132.4
2322.6s 462 2025-11-25 16:22:21 | INFO | walk_forward:optimize_hyperparameters:258 | Best trial: 0
2322.6s 463 2025-11-25 16:22:21 | INFO | walk_forward:optimize_hyperparameters:259 | Best value: 1.9617
2322.6s 464 2025-11-25 16:22:21 | INFO | walk_forward:optimize_hyperparameters:260 | Best params: {'learning_rate': 0.004076405612726199, 'max_depth': 10, 'n_estimators': 408, 'subsample': 0.9620422239724771, 'colsample_bytree': 0.9016978475481885, 'min_child_weight': 4, 'gamma': 0.34901425278762777, 'reg_alpha': 0.06454837369528385, 'reg_lambda': 1.7455572018133656}
2322.6s 465 2025-11-25 16:22:21 | INFO | walk_forward:run_walk_forward_optimization:313 | Training model with optimized parameters
2322.7s 466 2025-11-25 16:22:21 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
2363.4s 467 2025-11-25 16:23:02 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8230, Val Loss: 0.8195, Train Acc: 0.5880, Val Acc: 0.5251
2370.1s 468 2025-11-25 16:23:09 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8128, Val Loss: 0.8203, Train Acc: 0.5830, Val Acc: 0.5276
2376.8s 469 2025-11-25 16:23:15 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8103, Val Loss: 0.8241, Train Acc: 0.5730, Val Acc: 0.5316
2383.4s 470 2025-11-25 16:23:22 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.7999, Val Loss: 0.8295, Train Acc: 0.5970, Val Acc: 0.5321
2390.0s 471 2025-11-25 16:23:29 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.7823, Val Loss: 0.8093, Train Acc: 0.6010, Val Acc: 0.5737
2396.7s 472 2025-11-25 16:23:35 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.7582, Val Loss: 0.8065, Train Acc: 0.6260, Val Acc: 0.5912
2403.3s 473 2025-11-25 16:23:42 | INFO | lstm_model:fit:440 | Epoch 70/100 - Loss: 0.7433, Val Loss: 0.8102, Train Acc: 0.6910, Val Acc: 0.5978
2410.0s 474 2025-11-25 16:23:49 | INFO | lstm_model:fit:440 | Epoch 80/100 - Loss: 0.7380, Val Loss: 0.8208, Train Acc: 0.6840, Val Acc: 0.5996
2416.7s 475 2025-11-25 16:23:55 | INFO | lstm_model:fit:440 | Epoch 90/100 - Loss: 0.7315, Val Loss: 0.8146, Train Acc: 0.7000, Val Acc: 0.6049
2423.4s 476 2025-11-25 16:24:02 | INFO | lstm_model:fit:440 | Epoch 100/100 - Loss: 0.7313, Val Loss: 0.8139, Train Acc: 0.7060, Val Acc: 0.6076
2423.6s 477 2025-11-25 16:24:02 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
2484.3s 478 2025-11-25 16:25:03 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8224, Val Loss: 0.8230, Train Acc: 0.5360, Val Acc: 0.5102
2488.0s 479 2025-11-25 16:25:07 | INFO | lstm_model:fit:461 | Early stopping at epoch 13 - Val Loss: 0.8235
2563.8s 480 2025-11-25 16:26:22 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8228, Val Loss: 0.8190, Train Acc: 0.5310, Val Acc: 0.5431
2582.3s 481 2025-11-25 16:26:41 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8223, Val Loss: 0.8173, Train Acc: 0.5450, Val Acc: 0.5431
2587.9s 482 2025-11-25 16:26:46 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 0.8165
2678.3s 483 2025-11-25 16:28:17 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8217, Val Loss: 0.8211, Train Acc: 0.5060, Val Acc: 0.5198
2703.0s 484 2025-11-25 16:28:42 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8212, Val Loss: 0.8204, Train Acc: 0.5420, Val Acc: 0.5198
2728.2s 485 2025-11-25 16:29:07 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8211, Val Loss: 0.8204, Train Acc: 0.5380, Val Acc: 0.5198
2753.7s 486 2025-11-25 16:29:32 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8209, Val Loss: 0.8206, Train Acc: 0.5520, Val Acc: 0.5198
2756.2s 487 2025-11-25 16:29:35 | INFO | lstm_model:fit:461 | Early stopping at epoch 41 - Val Loss: 0.8205
2756.4s 488 2025-11-25 16:29:35 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
2858.2s 489 2025-11-25 16:31:17 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8217, Val Loss: 0.8213, Train Acc: 0.5000, Val Acc: 0.5360
2888.9s 490 2025-11-25 16:31:47 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8214, Val Loss: 0.8216, Train Acc: 0.5040, Val Acc: 0.5360
2919.4s 491 2025-11-25 16:32:18 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8210, Val Loss: 0.8210, Train Acc: 0.5610, Val Acc: 0.5360
2922.4s 492 2025-11-25 16:32:21 | INFO | lstm_model:fit:461 | Early stopping at epoch 31 - Val Loss: 0.8211
2922.7s 493 2025-11-25 16:32:21 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
2922.7s 494 2025-11-25 16:32:21 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
2997.5s 495 2025-11-25 16:33:36 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
3069.3s 496 2025-11-25 16:34:48 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8215
3141.3s 497 2025-11-25 16:36:00 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8213
3212.8s 498 2025-11-25 16:37:11 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8207
3284.3s 499 2025-11-25 16:38:23 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8207
3355.9s 500 2025-11-25 16:39:34 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8206
3356.4s 501 2025-11-25 16:39:35 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (35172, 6)
3356.4s 502 2025-11-25 16:39:35 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
3356.5s 503 /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [16:39:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
3356.5s 504 
3356.5s 505 E.g. tree_method = "hist", device = "cuda"
3356.5s 506 
3356.5s 507 warnings.warn(smsg, UserWarning)
3356.9s 508 2025-11-25 16:39:35 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
3357.9s 509 2025-11-25 16:39:36 | INFO | walk_forward:run_walk_forward_optimization:348 | OOS Balanced Accuracy: 0.4242
3357.9s 510 2025-11-25 16:39:36 | INFO | walk_forward:run_walk_forward_optimization:349 | OOS F1 Score: 0.6363
3357.9s 511 2025-11-25 16:39:37 | INFO | walk_forward:split:94 | Split 2: Train [2024-10-10 12:55:00 to 2025-06-10 12:50:00], Test [2025-06-10 12:55:00 to 2025-08-08 23:55:00]
3357.9s 512 2025-11-25 16:39:37 | INFO | walk_forward:run_walk_forward_optimization:291 |
3357.9s 513 ============================================================
3357.9s 514 2025-11-25 16:39:37 | INFO | walk_forward:run_walk_forward_optimization:292 | Walk-Forward Fold 2
3357.9s 515 2025-11-25 16:39:37 | INFO | walk_forward:run_walk_forward_optimization:293 | ============================================================
3358.0s 516 2025-11-25 16:39:37 | INFO | walk_forward:optimize_hyperparameters:240 | Starting hyperparameter optimization
3358.0s 517 [32m[I 2025-11-25 16:39:37,089][0m A new study created in memory with name: no-name-cb4ab3ea-30e7-4e1b-bc74-b228266203b2[0m
3358.1s 518 0%|                                                     | 0/5 [00:00<?, ?it/s]2025-11-25 16:39:37 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
3358.1s 519 2025-11-25 16:39:37 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
3358.1s 520 2025-11-25 16:39:37 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
3358.1s 521 2025-11-25 16:39:37 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
3393.5s 522 2025-11-25 16:40:12 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8235, Val Loss: 0.8180, Train Acc: 0.5530, Val Acc: 0.5245
3406.4s 523 2025-11-25 16:40:25 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8158, Val Loss: 0.8176, Train Acc: 0.5740, Val Acc: 0.5264
3422.7s 524 2025-11-25 16:40:41 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8099, Val Loss: 0.8180, Train Acc: 0.5970, Val Acc: 0.5216
3422.7s 525 2025-11-25 16:40:41 | INFO | lstm_model:fit:461 | Early stopping at epoch 30 - Val Loss: 0.8180
3423.1s 526 2025-11-25 16:40:42 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
3431.4s 527 2025-11-25 16:40:50 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8209, Val Loss: 0.8191, Train Acc: 0.5630, Val Acc: 0.5319
3437.1s 528 2025-11-25 16:40:56 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8209, Val Loss: 0.8207, Train Acc: 0.5360, Val Acc: 0.5295
3447.9s 529 2025-11-25 16:41:07 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8131, Val Loss: 0.8206, Train Acc: 0.5610, Val Acc: 0.5343
3449.9s 530 2025-11-25 16:41:09 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8192, Val Loss: 0.8180, Train Acc: 0.5420, Val Acc: 0.5225
3464.0s 531 2025-11-25 16:41:23 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8124, Val Loss: 0.8190, Train Acc: 0.5610, Val Acc: 0.5114
3466.9s 532 2025-11-25 16:41:26 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8099, Val Loss: 0.8181, Train Acc: 0.5690, Val Acc: 0.5327
3473.0s 533 2025-11-25 16:41:32 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8217, Val Loss: 0.8229, Train Acc: 0.5130, Val Acc: 0.5085
3474.6s 534 2025-11-25 16:41:33 | INFO | lstm_model:fit:461 | Early stopping at epoch 16 - Val Loss: 0.8187
3475.0s 535 2025-11-25 16:41:34 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
3486.5s 536 2025-11-25 16:41:45 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8043, Val Loss: 0.8148, Train Acc: 0.5840, Val Acc: 0.5544
3492.2s 537 2025-11-25 16:41:51 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8080, Val Loss: 0.8176, Train Acc: 0.5680, Val Acc: 0.5333
3494.3s 538 2025-11-25 16:41:53 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 0.8228
3502.2s 539 2025-11-25 16:42:01 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.7924, Val Loss: 0.8166, Train Acc: 0.5820, Val Acc: 0.5432
3510.9s 540 2025-11-25 16:42:09 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8054, Val Loss: 0.8166, Train Acc: 0.5920, Val Acc: 0.5424
3515.8s 541 2025-11-25 16:42:14 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.7834, Val Loss: 0.8179, Train Acc: 0.6190, Val Acc: 0.5591
3526.2s 542 2025-11-25 16:42:25 | INFO | lstm_model:fit:461 | Early stopping at epoch 66 - Val Loss: 0.8262
3526.5s 543 2025-11-25 16:42:25 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
3531.7s 544 2025-11-25 16:42:30 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.8006, Val Loss: 0.8152, Train Acc: 0.6050, Val Acc: 0.5401
3548.8s 545 2025-11-25 16:42:47 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.7892, Val Loss: 0.8159, Train Acc: 0.6100, Val Acc: 0.5610
3562.0s 546 2025-11-25 16:43:01 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8226, Val Loss: 0.8184, Train Acc: 0.5510, Val Acc: 0.5404
3568.1s 547 2025-11-25 16:43:07 | INFO | lstm_model:fit:440 | Epoch 70/100 - Loss: 0.7804, Val Loss: 0.8178, Train Acc: 0.6050, Val Acc: 0.5720
3570.7s 548 2025-11-25 16:43:09 | INFO | lstm_model:fit:461 | Early stopping at epoch 12 - Val Loss: 0.8183
3582.9s 549 2025-11-25 16:43:21 | INFO | lstm_model:fit:440 | Epoch 80/100 - Loss: 0.7708, Val Loss: 0.8193, Train Acc: 0.6210, Val Acc: 0.5747
3586.8s 550 2025-11-25 16:43:25 | INFO | lstm_model:fit:461 | Early stopping at epoch 83 - Val Loss: 0.8213
3587.2s 551 2025-11-25 16:43:26 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
3591.4s 552 2025-11-25 16:43:30 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8224, Val Loss: 0.8231, Train Acc: 0.5210, Val Acc: 0.5085
3611.0s 553 2025-11-25 16:43:50 | INFO | lstm_model:fit:461 | Early stopping at epoch 15 - Val Loss: 0.8227
3627.7s 554 2025-11-25 16:44:06 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8225, Val Loss: 0.8227, Train Acc: 0.5370, Val Acc: 0.5085
3653.7s 555 2025-11-25 16:44:32 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8223, Val Loss: 0.8203, Train Acc: 0.5140, Val Acc: 0.5304
3662.9s 556 2025-11-25 16:44:42 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8208, Val Loss: 0.8229, Train Acc: 0.5300, Val Acc: 0.5085
3677.5s 557 2025-11-25 16:44:56 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 0.8230
3694.2s 558 2025-11-25 16:45:13 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8218, Val Loss: 0.8227, Train Acc: 0.5310, Val Acc: 0.5085
3707.9s 559 2025-11-25 16:45:26 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8216, Val Loss: 0.8199, Train Acc: 0.5400, Val Acc: 0.5304
3719.2s 560 2025-11-25 16:45:38 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 0.8237
3750.2s 561 2025-11-25 16:46:09 | INFO | lstm_model:fit:461 | Early stopping at epoch 28 - Val Loss: 0.8200
3750.6s 562 2025-11-25 16:46:09 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
3756.2s 563 2025-11-25 16:46:15 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8228, Val Loss: 0.8181, Train Acc: 0.5220, Val Acc: 0.5404
3807.2s 564 2025-11-25 16:47:06 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8226, Val Loss: 0.8185, Train Acc: 0.5320, Val Acc: 0.5404
3826.9s 565 2025-11-25 16:47:25 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8218, Val Loss: 0.8196, Train Acc: 0.5400, Val Acc: 0.5404
3826.9s 566 2025-11-25 16:47:25 | INFO | lstm_model:fit:461 | Early stopping at epoch 20 - Val Loss: 0.8196
3853.8s 567 2025-11-25 16:47:52 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8218, Val Loss: 0.8196, Train Acc: 0.5510, Val Acc: 0.5436
3860.3s 568 2025-11-25 16:47:59 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8218, Val Loss: 0.8180, Train Acc: 0.5230, Val Acc: 0.5404
3870.8s 569 2025-11-25 16:48:09 | INFO | lstm_model:fit:461 | Early stopping at epoch 22 - Val Loss: 0.8186
3872.0s 570 2025-11-25 16:48:11 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8227, Val Loss: 0.8185, Train Acc: 0.5100, Val Acc: 0.5404
3918.9s 571 2025-11-25 16:48:57 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8213, Val Loss: 0.8190, Train Acc: 0.5180, Val Acc: 0.5436
3922.4s 572 2025-11-25 16:49:01 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8220, Val Loss: 0.8180, Train Acc: 0.5190, Val Acc: 0.5404
3953.2s 573 2025-11-25 16:49:32 | INFO | lstm_model:fit:461 | Early stopping at epoch 25 - Val Loss: 0.8191
3953.5s 574 2025-11-25 16:49:32 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
3953.5s 575 2025-11-25 16:49:32 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
3970.6s 576 2025-11-25 16:49:49 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8215, Val Loss: 0.8183, Train Acc: 0.5200, Val Acc: 0.5404
3979.5s 577 2025-11-25 16:49:58 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
4004.4s 578 2025-11-25 16:50:23 | INFO | lstm_model:fit:461 | Early stopping at epoch 37 - Val Loss: 0.8185
4039.5s 579 2025-11-25 16:50:58 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8221, Val Loss: 0.8203, Train Acc: 0.5400, Val Acc: 0.5304
4044.4s 580 2025-11-25 16:51:03 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8221, Val Loss: 0.8200, Train Acc: 0.5080, Val Acc: 0.5304
4113.6s 581 2025-11-25 16:52:12 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8212, Val Loss: 0.8201, Train Acc: 0.5110, Val Acc: 0.5304
4146.7s 582 2025-11-25 16:52:45 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8212
4177.3s 583 2025-11-25 16:53:16 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8217, Val Loss: 0.8199, Train Acc: 0.4960, Val Acc: 0.5304
4181.3s 584 2025-11-25 16:53:20 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8217, Val Loss: 0.8199, Train Acc: 0.5350, Val Acc: 0.5304
4181.9s 585 2025-11-25 16:53:20 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8222, Val Loss: 0.8200, Train Acc: 0.5430, Val Acc: 0.5304
4221.7s 586 2025-11-25 16:54:00 | INFO | lstm_model:fit:461 | Early stopping at epoch 36 - Val Loss: 0.8199
4222.0s 587 2025-11-25 16:54:01 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
4266.8s 588 2025-11-25 16:54:45 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8215, Val Loss: 0.8200, Train Acc: 0.5280, Val Acc: 0.5304
4297.6s 589 2025-11-25 16:55:16 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8212, Val Loss: 0.8204, Train Acc: 0.5390, Val Acc: 0.5304
4312.4s 590 2025-11-25 16:55:31 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8206
4337.2s 591 2025-11-25 16:55:56 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8213, Val Loss: 0.8204, Train Acc: 0.5280, Val Acc: 0.5304
4390.5s 592 2025-11-25 16:56:49 | INFO | lstm_model:fit:461 | Early stopping at epoch 38 - Val Loss: 0.8201
4390.8s 593 2025-11-25 16:56:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
4426.7s 594 2025-11-25 16:57:25 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8209, Val Loss: 0.8199, Train Acc: 0.5190, Val Acc: 0.5304
4429.8s 595 2025-11-25 16:57:28 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8222, Val Loss: 0.8197, Train Acc: 0.5240, Val Acc: 0.5436
4470.4s 596 2025-11-25 16:58:09 | INFO | lstm_model:fit:461 | Early stopping at epoch 44 - Val Loss: 0.8199
4470.8s 597 2025-11-25 16:58:09 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
4476.5s 598 2025-11-25 16:58:15 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8204
4517.9s 599 2025-11-25 16:58:56 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8216, Val Loss: 0.8190, Train Acc: 0.5200, Val Acc: 0.5436
4579.0s 600 2025-11-25 16:59:57 | INFO | lstm_model:fit:461 | Early stopping at epoch 27 - Val Loss: 0.8202
4579.3s 601 2025-11-25 16:59:58 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
4579.4s 602 2025-11-25 16:59:58 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
4590.7s 603 2025-11-25 17:00:09 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8220, Val Loss: 0.8193, Train Acc: 0.5410, Val Acc: 0.5436
4617.6s 604 2025-11-25 17:00:36 | INFO | lstm_model:fit:461 | Early stopping at epoch 13 - Val Loss: 0.8188
4617.9s 605 2025-11-25 17:00:36 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
4617.9s 606 2025-11-25 17:00:36 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
4639.1s 607 2025-11-25 17:00:58 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8203
4674.7s 608 2025-11-25 17:01:33 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8219, Val Loss: 0.8201, Train Acc: 0.5330, Val Acc: 0.5436
4683.7s 609 2025-11-25 17:01:42 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
4699.5s 610 2025-11-25 17:01:58 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
4796.8s 611 2025-11-25 17:03:35 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8204
4796.9s 612 2025-11-25 17:03:36 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (37388, 6)
4796.9s 613 2025-11-25 17:03:36 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
4797.0s 614 [17:03:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
4797.0s 615 
4797.0s 616 E.g. tree_method = "hist", device = "cuda"
4797.0s 617 
4797.8s 618 [17:03:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
4797.8s 619 
4797.8s 620 E.g. tree_method = "hist", device = "cuda"
4797.8s 621 
4797.8s 622 2025-11-25 17:03:36 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
4798.4s 623 [32m[I 2025-11-25 17:03:37,487][0m Trial 2 finished with value: 1.7295560747663552 and parameters: {'learning_rate': 0.01240630716492326, 'max_depth': 6, 'n_estimators': 346, 'subsample': 0.8427482402510785, 'colsample_bytree': 0.6205064845162532, 'min_child_weight': 1, 'gamma': 0.22740192260099779, 'reg_alpha': 0.0014176394521531078, 'reg_lambda': 1.7378696339425734}. Best is trial 2 with value: 1.7295560747663552.[0m
4798.5s 624 0%|                                                     | 0/5 [24:00<?, ?it/s]
Best trial: 2. Best value: 1.72956:   0%|                 | 0/5 [24:00<?, ?it/s]
Best trial: 2. Best value: 1.72956:  20%|â–ˆ    | 1/5 [24:00<1:36:01, 1440.40s/it]
Best trial: 2. Best value: 1.72956:  20%|â–| 1/5 [24:00<1:36:01, 1440.40s/it, 1442025-11-25 17:03:37 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
4804.1s 625 2025-11-25 17:03:43 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 0.8192
4804.6s 626 2025-11-25 17:03:43 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
4804.6s 627 2025-11-25 17:03:43 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
4834.0s 628 2025-11-25 17:04:13 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8211, Val Loss: 0.8197, Train Acc: 0.5320, Val Acc: 0.5176
4845.2s 629 2025-11-25 17:04:24 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 0.8182
4845.6s 630 2025-11-25 17:04:24 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
4869.7s 631 2025-11-25 17:04:48 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8214
4899.6s 632 2025-11-25 17:05:18 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8224, Val Loss: 0.8228, Train Acc: 0.5270, Val Acc: 0.5085
4920.9s 633 2025-11-25 17:05:39 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
4928.4s 634 2025-11-25 17:05:47 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8207, Val Loss: 0.8231, Train Acc: 0.5310, Val Acc: 0.5085
4951.0s 635 2025-11-25 17:06:09 | INFO | lstm_model:fit:461 | Early stopping at epoch 28 - Val Loss: 0.8232
4976.2s 636 2025-11-25 17:06:35 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8212
5018.9s 637 2025-11-25 17:07:17 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8229, Val Loss: 0.8204, Train Acc: 0.5030, Val Acc: 0.5404
5060.2s 638 2025-11-25 17:07:59 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8220, Val Loss: 0.8204, Train Acc: 0.5010, Val Acc: 0.5404
5069.3s 639 2025-11-25 17:08:08 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8207
5072.5s 640 2025-11-25 17:08:11 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 0.8201
5157.0s 641 2025-11-25 17:09:36 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8218, Val Loss: 0.8201, Train Acc: 0.5310, Val Acc: 0.5304
5195.4s 642 2025-11-25 17:10:14 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 0.8201
5195.8s 643 2025-11-25 17:10:14 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
5255.7s 644 2025-11-25 17:11:14 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8206
5261.0s 645 2025-11-25 17:11:20 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8207
5296.5s 646 2025-11-25 17:11:55 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8217, Val Loss: 0.8197, Train Acc: 0.5310, Val Acc: 0.5436
5339.1s 647 2025-11-25 17:12:38 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8212
5364.8s 648 2025-11-25 17:13:03 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8215, Val Loss: 0.8188, Train Acc: 0.5260, Val Acc: 0.5436
5385.4s 649 2025-11-25 17:13:24 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 0.8196
5385.7s 650 2025-11-25 17:13:24 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
5385.7s 651 2025-11-25 17:13:24 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
5415.6s 652 2025-11-25 17:13:54 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
5447.3s 653 2025-11-25 17:14:26 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8204
5558.5s 654 2025-11-25 17:16:17 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8205
5577.6s 655 2025-11-25 17:16:36 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8211
5643.7s 656 2025-11-25 17:17:42 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8203
5643.9s 657 2025-11-25 17:17:42 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (37388, 6)
5643.9s 658 2025-11-25 17:17:42 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
5643.9s 659 [17:17:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
5643.9s 660 
5643.9s 661 E.g. tree_method = "hist", device = "cuda"
5643.9s 662 
5644.7s 663 [17:17:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
5644.7s 664 
5644.7s 665 E.g. tree_method = "hist", device = "cuda"
5644.7s 666 
5644.7s 667 2025-11-25 17:17:43 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
5645.7s 668 [32m[I 2025-11-25 17:17:44,795][0m Trial 1 finished with value: 1.6941481695012972 and parameters: {'learning_rate': 0.044858194385545815, 'max_depth': 9, 'n_estimators': 460, 'subsample': 0.9740194015058371, 'colsample_bytree': 0.7953226347518827, 'min_child_weight': 3, 'gamma': 0.13037806814823616, 'reg_alpha': 0.015216714570295232, 'reg_lambda': 1.6135384838285491}. Best is trial 2 with value: 1.7295560747663552.[0m
5723.5s 669 Best trial: 2. Best value: 1.72956:  20%|â–| 1/5 [38:07<1:36:01, 1440.40s/it, 144
Best trial: 2. Best value: 1.72956:  20%|â–| 1/5 [38:07<1:36:01, 1440.40s/it, 144
Best trial: 2. Best value: 1.72956:  40%|â–| 2/5 [38:07<54:34, 1091.52s/it, 1440.
Best trial: 2. Best value: 1.72956:  40%|â–| 2/5 [38:07<54:34, 1091.52s/it, 2287.2025-11-25 17:19:02 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8208
5724.3s 670 2025-11-25 17:19:03 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8206
5763.7s 671 2025-11-25 17:19:42 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8204
5859.0s 672 2025-11-25 17:21:18 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8204
5928.7s 673 2025-11-25 17:22:27 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8203
5928.9s 674 2025-11-25 17:22:27 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (37388, 6)
5928.9s 675 2025-11-25 17:22:27 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
5928.9s 676 [17:22:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
5928.9s 677 
5928.9s 678 E.g. tree_method = "hist", device = "cuda"
5928.9s 679 
5929.6s 680 [17:22:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
5929.6s 681 
5929.6s 682 E.g. tree_method = "hist", device = "cuda"
5929.6s 683 
5929.6s 684 2025-11-25 17:22:28 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
5930.3s 685 [32m[I 2025-11-25 17:22:29,395][0m Trial 3 finished with value: 1.8372799028536733 and parameters: {'learning_rate': 0.009400884972719232, 'max_depth': 8, 'n_estimators': 391, 'subsample': 0.9584489947135707, 'colsample_bytree': 0.8684705499819891, 'min_child_weight': 2, 'gamma': 0.26151836057898337, 'reg_alpha': 0.009379928745143151, 'reg_lambda': 0.7569351813324499}. Best is trial 3 with value: 1.8372799028536733.[0m
5959.4s 686 Best trial: 2. Best value: 1.72956:  40%|â–| 2/5 [42:52<54:34, 1091.52s/it, 2287.
Best trial: 3. Best value: 1.83728:  40%|â–| 2/5 [42:52<54:34, 1091.52s/it, 2287.
Best trial: 3. Best value: 1.83728:  60%|â–Œ| 3/5 [42:52<24:06, 723.06s/it, 2287.7
Best trial: 3. Best value: 1.83728:  60%|â–Œ| 3/5 [42:52<24:06, 723.06s/it, 2572.32025-11-25 17:22:58 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8204
5980.1s 687 2025-11-25 17:23:19 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8204
6085.0s 688 2025-11-25 17:25:04 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8202
6085.1s 689 2025-11-25 17:25:04 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (37388, 6)
6085.1s 690 2025-11-25 17:25:04 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
6085.2s 691 [17:25:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
6085.2s 692 
6085.2s 693 E.g. tree_method = "hist", device = "cuda"
6085.2s 694 
6085.7s 695 [17:25:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
6085.7s 696 
6085.7s 697 E.g. tree_method = "hist", device = "cuda"
6085.7s 698 
6085.7s 699 2025-11-25 17:25:04 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
6086.1s 700 [32m[I 2025-11-25 17:25:05,247][0m Trial 4 finished with value: 1.6695229934304485 and parameters: {'learning_rate': 0.0035597656479343072, 'max_depth': 6, 'n_estimators': 384, 'subsample': 0.785211565856361, 'colsample_bytree': 0.7181492337399739, 'min_child_weight': 7, 'gamma': 0.4777284681877524, 'reg_alpha': 0.05301413965214607, 'reg_lambda': 1.5425365200221168}. Best is trial 3 with value: 1.8372799028536733.[0m
6086.5s 701 Best trial: 3. Best value: 1.83728:  60%|â–Œ| 3/5 [45:28<24:06, 723.06s/it, 2572.3
Best trial: 3. Best value: 1.83728:  60%|â–Œ| 3/5 [45:28<24:06, 723.06s/it, 2572.3
Best trial: 3. Best value: 1.83728:  80%|â–Š| 4/5 [45:28<08:19, 499.13s/it, 2572.3
Best trial: 3. Best value: 1.83728:  80%|â–Š| 4/5 [45:28<08:19, 499.13s/it, 2728.12025-11-25 17:25:05 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8203
6160.0s 702 2025-11-25 17:26:19 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8203
6160.2s 703 2025-11-25 17:26:19 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (37388, 6)
6160.2s 704 2025-11-25 17:26:19 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
6160.2s 705 [17:26:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
6160.2s 706 
6160.2s 707 E.g. tree_method = "hist", device = "cuda"
6160.2s 708 
6160.7s 709 [17:26:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
6160.7s 710 
6160.7s 711 E.g. tree_method = "hist", device = "cuda"
6160.7s 712 
6160.7s 713 2025-11-25 17:26:19 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
6161.2s 714 [32m[I 2025-11-25 17:26:20,264][0m Trial 0 finished with value: 1.6988160554432572 and parameters: {'learning_rate': 0.0016227711409747025, 'max_depth': 10, 'n_estimators': 282, 'subsample': 0.7350974420417798, 'colsample_bytree': 0.7063664695807711, 'min_child_weight': 4, 'gamma': 0.3395332457179735, 'reg_alpha': 0.042319913798670145, 'reg_lambda': 1.3371306201934576}. Best is trial 3 with value: 1.8372799028536733.[0m
6161.2s 715 Best trial: 3. Best value: 1.83728:  80%|â–Š| 4/5 [46:43<08:19, 499.13s/it, 2728.1
Best trial: 3. Best value: 1.83728:  80%|â–Š| 4/5 [46:43<08:19, 499.13s/it, 2728.1
Best trial: 3. Best value: 1.83728: 100%|â–ˆ| 5/5 [46:43<00:00, 346.19s/it, 2728.1
Best trial: 3. Best value: 1.83728: 100%|â–ˆ| 5/5 [46:43<00:00, 346.19s/it, 2803.1
Best trial: 3. Best value: 1.83728: 100%|â–ˆ| 5/5 [46:43<00:00, 560.63s/it, 2803.1
6161.2s 716 2025-11-25 17:26:20 | INFO | walk_forward:optimize_hyperparameters:258 | Best trial: 3
6161.2s 717 2025-11-25 17:26:20 | INFO | walk_forward:optimize_hyperparameters:259 | Best value: 1.8373
6161.2s 718 2025-11-25 17:26:20 | INFO | walk_forward:optimize_hyperparameters:260 | Best params: {'learning_rate': 0.009400884972719232, 'max_depth': 8, 'n_estimators': 391, 'subsample': 0.9584489947135707, 'colsample_bytree': 0.8684705499819891, 'min_child_weight': 2, 'gamma': 0.26151836057898337, 'reg_alpha': 0.009379928745143151, 'reg_lambda': 0.7569351813324499}
6161.2s 719 2025-11-25 17:26:20 | INFO | walk_forward:run_walk_forward_optimization:313 | Training model with optimized parameters
6161.2s 720 2025-11-25 17:26:20 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
6187.3s 721 2025-11-25 17:26:46 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8215, Val Loss: 0.8234, Train Acc: 0.5400, Val Acc: 0.5138
6196.2s 722 2025-11-25 17:26:55 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8137, Val Loss: 0.8221, Train Acc: 0.5650, Val Acc: 0.5160
6197.9s 723 2025-11-25 17:26:56 | INFO | lstm_model:fit:461 | Early stopping at epoch 22 - Val Loss: 0.8270
6198.1s 724 2025-11-25 17:26:57 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
6236.6s 725 2025-11-25 17:27:35 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8228, Val Loss: 0.8182, Train Acc: 0.5410, Val Acc: 0.5407
6241.6s 726 2025-11-25 17:27:40 | INFO | lstm_model:fit:461 | Early stopping at epoch 13 - Val Loss: 0.8180
6291.8s 727 2025-11-25 17:28:30 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8221, Val Loss: 0.8203, Train Acc: 0.5130, Val Acc: 0.5283
6316.8s 728 2025-11-25 17:28:55 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8216, Val Loss: 0.8203, Train Acc: 0.5220, Val Acc: 0.5283
6341.4s 729 2025-11-25 17:29:20 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8210, Val Loss: 0.8203, Train Acc: 0.5240, Val Acc: 0.5283
6341.4s 730 2025-11-25 17:29:20 | INFO | lstm_model:fit:461 | Early stopping at epoch 30 - Val Loss: 0.8203
6401.5s 731 2025-11-25 17:30:20 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8219, Val Loss: 0.8190, Train Acc: 0.5270, Val Acc: 0.5348
6434.2s 732 2025-11-25 17:30:53 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8214, Val Loss: 0.8189, Train Acc: 0.5480, Val Acc: 0.5348
6466.9s 733 2025-11-25 17:31:25 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8210, Val Loss: 0.8188, Train Acc: 0.5320, Val Acc: 0.5348
6473.5s 734 2025-11-25 17:31:32 | INFO | lstm_model:fit:461 | Early stopping at epoch 32 - Val Loss: 0.8188
6473.8s 735 2025-11-25 17:31:32 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
6544.2s 736 2025-11-25 17:32:43 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8216, Val Loss: 0.8169, Train Acc: 0.5330, Val Acc: 0.5230
6584.8s 737 2025-11-25 17:33:23 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8212, Val Loss: 0.8171, Train Acc: 0.5370, Val Acc: 0.5230
6596.9s 738 2025-11-25 17:33:35 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 0.8177
6597.2s 739 2025-11-25 17:33:36 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
6597.2s 740 2025-11-25 17:33:36 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
6625.1s 741 2025-11-25 17:34:04 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
6719.4s 742 2025-11-25 17:35:38 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8205
6813.0s 743 2025-11-25 17:37:12 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8201
6906.9s 744 2025-11-25 17:38:45 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8199
7000.2s 745 2025-11-25 17:40:19 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8198
7094.1s 746 2025-11-25 17:41:53 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8198
7094.6s 747 2025-11-25 17:41:53 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (46734, 6)
7094.6s 748 2025-11-25 17:41:53 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
7094.6s 749 /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [17:41:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
7094.6s 750 
7094.6s 751 E.g. tree_method = "hist", device = "cuda"
7094.6s 752 
7094.6s 753 warnings.warn(smsg, UserWarning)
7095.0s 754 /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [17:41:54] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
7095.0s 755 
7095.0s 756 E.g. tree_method = "hist", device = "cuda"
7095.0s 757 
7095.0s 758 warnings.warn(smsg, UserWarning)
7095.0s 759 2025-11-25 17:41:54 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
7095.9s 760 2025-11-25 17:41:54 | INFO | walk_forward:run_walk_forward_optimization:348 | OOS Balanced Accuracy: 0.4389
7095.9s 761 2025-11-25 17:41:54 | INFO | walk_forward:run_walk_forward_optimization:349 | OOS F1 Score: 0.6508
7095.9s 762 2025-11-25 17:41:55 | INFO | walk_forward:split:94 | Split 3: Train [2024-10-10 12:55:00 to 2025-08-08 23:55:00], Test [2025-08-11 01:00:00 to 2025-10-10 12:50:00]
7095.9s 763 2025-11-25 17:41:55 | INFO | walk_forward:run_walk_forward_optimization:291 |
7095.9s 764 ============================================================
7095.9s 765 2025-11-25 17:41:55 | INFO | walk_forward:run_walk_forward_optimization:292 | Walk-Forward Fold 3
7095.9s 766 2025-11-25 17:41:55 | INFO | walk_forward:run_walk_forward_optimization:293 | ============================================================
7096.0s 767 2025-11-25 17:41:55 | INFO | walk_forward:optimize_hyperparameters:240 | Starting hyperparameter optimization
7096.0s 768 [32m[I 2025-11-25 17:41:55,095][0m A new study created in memory with name: no-name-3fbc8af5-5cc9-453a-9d49-6211234d1476[0m
7096.1s 769 0%|                                                     | 0/5 [00:00<?, ?it/s]2025-11-25 17:41:55 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
7096.1s 770 2025-11-25 17:41:55 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
7096.1s 771 2025-11-25 17:41:55 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
7096.1s 772 2025-11-25 17:41:55 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
7126.3s 773 2025-11-25 17:42:25 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8242, Val Loss: 0.8205, Train Acc: 0.4990, Val Acc: 0.5135
7145.0s 774 2025-11-25 17:42:44 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8220, Val Loss: 0.8239, Train Acc: 0.5240, Val Acc: 0.5135
7147.1s 775 2025-11-25 17:42:46 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8193, Val Loss: 0.8233, Train Acc: 0.5350, Val Acc: 0.5128
7164.5s 776 2025-11-25 17:43:03 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8207, Val Loss: 0.8213, Train Acc: 0.5550, Val Acc: 0.5172
7166.3s 777 2025-11-25 17:43:05 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8109, Val Loss: 0.8248, Train Acc: 0.5730, Val Acc: 0.5168
7168.5s 778 2025-11-25 17:43:07 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8148, Val Loss: 0.8217, Train Acc: 0.5570, Val Acc: 0.5121
7185.4s 779 2025-11-25 17:43:24 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8030, Val Loss: 0.8230, Train Acc: 0.5950, Val Acc: 0.5387
7187.6s 780 2025-11-25 17:43:26 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8227, Val Loss: 0.8226, Train Acc: 0.4940, Val Acc: 0.4891
7191.8s 781 2025-11-25 17:43:30 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8129, Val Loss: 0.8216, Train Acc: 0.5630, Val Acc: 0.5176
7201.1s 782 2025-11-25 17:43:40 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8155, Val Loss: 0.8208, Train Acc: 0.5510, Val Acc: 0.5090
7204.5s 783 2025-11-25 17:43:43 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.7925, Val Loss: 0.8179, Train Acc: 0.6370, Val Acc: 0.5404
7215.0s 784 2025-11-25 17:43:54 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8089, Val Loss: 0.8250, Train Acc: 0.5740, Val Acc: 0.5206
7223.6s 785 2025-11-25 17:44:02 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.7807, Val Loss: 0.8189, Train Acc: 0.6450, Val Acc: 0.5551
7237.3s 786 2025-11-25 17:44:16 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8093, Val Loss: 0.8252, Train Acc: 0.5900, Val Acc: 0.5214
7238.5s 787 2025-11-25 17:44:17 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.8068, Val Loss: 0.8222, Train Acc: 0.5600, Val Acc: 0.5251
7238.9s 788 2025-11-25 17:44:18 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8146, Val Loss: 0.8232, Train Acc: 0.5650, Val Acc: 0.5162
7242.8s 789 2025-11-25 17:44:21 | INFO | lstm_model:fit:440 | Epoch 70/100 - Loss: 0.7733, Val Loss: 0.8187, Train Acc: 0.6600, Val Acc: 0.5581
7261.5s 790 2025-11-25 17:44:40 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.8029, Val Loss: 0.8284, Train Acc: 0.5700, Val Acc: 0.5292
7261.9s 791 2025-11-25 17:44:40 | INFO | lstm_model:fit:440 | Epoch 80/100 - Loss: 0.7653, Val Loss: 0.8182, Train Acc: 0.6430, Val Acc: 0.5646
7273.9s 792 2025-11-25 17:44:53 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.7992, Val Loss: 0.8268, Train Acc: 0.5770, Val Acc: 0.5438
7281.1s 793 2025-11-25 17:45:00 | INFO | lstm_model:fit:440 | Epoch 90/100 - Loss: 0.7616, Val Loss: 0.8199, Train Acc: 0.6290, Val Acc: 0.5699
7284.7s 794 2025-11-25 17:45:03 | INFO | lstm_model:fit:440 | Epoch 70/100 - Loss: 0.8021, Val Loss: 0.8254, Train Acc: 0.5810, Val Acc: 0.5378
7291.3s 795 2025-11-25 17:45:10 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8092, Val Loss: 0.8217, Train Acc: 0.5620, Val Acc: 0.5196
7299.9s 796 2025-11-25 17:45:18 | INFO | lstm_model:fit:440 | Epoch 100/100 - Loss: 0.7592, Val Loss: 0.8199, Train Acc: 0.6490, Val Acc: 0.5688
7300.3s 797 2025-11-25 17:45:19 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
7306.6s 798 2025-11-25 17:45:25 | INFO | lstm_model:fit:440 | Epoch 80/100 - Loss: 0.8018, Val Loss: 0.8233, Train Acc: 0.5780, Val Acc: 0.5385
7306.7s 799 2025-11-25 17:45:25 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.7927, Val Loss: 0.8278, Train Acc: 0.6040, Val Acc: 0.5503
7321.8s 800 2025-11-25 17:45:40 | INFO | lstm_model:fit:461 | Early stopping at epoch 87 - Val Loss: 0.8239
7322.2s 801 2025-11-25 17:45:41 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
7333.2s 802 2025-11-25 17:45:52 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.7932, Val Loss: 0.8187, Train Acc: 0.6130, Val Acc: 0.5538
7334.4s 803 2025-11-25 17:45:53 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.7785, Val Loss: 0.8162, Train Acc: 0.6210, Val Acc: 0.5505
7349.1s 804 2025-11-25 17:46:08 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8227, Val Loss: 0.8198, Train Acc: 0.5390, Val Acc: 0.5414
7356.5s 805 2025-11-25 17:46:15 | INFO | lstm_model:fit:461 | Early stopping at epoch 12 - Val Loss: 0.8188
7362.4s 806 2025-11-25 17:46:21 | INFO | lstm_model:fit:440 | Epoch 70/100 - Loss: 0.7700, Val Loss: 0.8169, Train Acc: 0.6360, Val Acc: 0.5527
7374.3s 807 2025-11-25 17:46:33 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.7745, Val Loss: 0.8152, Train Acc: 0.6170, Val Acc: 0.5659
7386.6s 808 2025-11-25 17:46:45 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8229, Val Loss: 0.8184, Train Acc: 0.5380, Val Acc: 0.5414
7393.7s 809 2025-11-25 17:46:52 | INFO | lstm_model:fit:440 | Epoch 80/100 - Loss: 0.7641, Val Loss: 0.8220, Train Acc: 0.6230, Val Acc: 0.5629
7395.5s 810 2025-11-25 17:46:54 | INFO | lstm_model:fit:461 | Early stopping at epoch 12 - Val Loss: 0.8183
7415.6s 811 2025-11-25 17:47:14 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.7499, Val Loss: 0.8425, Train Acc: 0.6980, Val Acc: 0.5629
7418.1s 812 2025-11-25 17:47:17 | INFO | lstm_model:fit:440 | Epoch 90/100 - Loss: 0.7548, Val Loss: 0.8292, Train Acc: 0.6580, Val Acc: 0.5656
7425.8s 813 2025-11-25 17:47:24 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8219, Val Loss: 0.8208, Train Acc: 0.5120, Val Acc: 0.5246
7430.2s 814 2025-11-25 17:47:29 | INFO | lstm_model:fit:461 | Early stopping at epoch 94 - Val Loss: 0.8363
7430.7s 815 2025-11-25 17:47:29 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
7453.8s 816 2025-11-25 17:47:52 | INFO | lstm_model:fit:440 | Epoch 70/100 - Loss: 0.7376, Val Loss: 0.8184, Train Acc: 0.6560, Val Acc: 0.5814
7465.5s 817 2025-11-25 17:48:04 | INFO | lstm_model:fit:461 | Early stopping at epoch 73 - Val Loss: 0.8266
7465.9s 818 2025-11-25 17:48:04 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
7480.8s 819 2025-11-25 17:48:19 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8212, Val Loss: 0.8206, Train Acc: 0.5320, Val Acc: 0.5246
7492.2s 820 2025-11-25 17:48:31 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8218, Val Loss: 0.8208, Train Acc: 0.5220, Val Acc: 0.5246
7529.9s 821 2025-11-25 17:49:08 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8232, Val Loss: 0.8182, Train Acc: 0.4830, Val Acc: 0.5414
7534.9s 822 2025-11-25 17:49:13 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8208, Val Loss: 0.8207, Train Acc: 0.5350, Val Acc: 0.5246
7559.0s 823 2025-11-25 17:49:38 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8214, Val Loss: 0.8206, Train Acc: 0.5230, Val Acc: 0.5246
7588.0s 824 2025-11-25 17:50:07 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8205, Val Loss: 0.8206, Train Acc: 0.5250, Val Acc: 0.5246
7599.2s 825 2025-11-25 17:50:18 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8227, Val Loss: 0.8186, Train Acc: 0.5260, Val Acc: 0.5414
7604.7s 826 2025-11-25 17:50:23 | INFO | lstm_model:fit:461 | Early stopping at epoch 27 - Val Loss: 0.8209
7606.1s 827 2025-11-25 17:50:25 | INFO | lstm_model:fit:461 | Early stopping at epoch 21 - Val Loss: 0.8185
7614.5s 828 2025-11-25 17:50:33 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8229, Val Loss: 0.8191, Train Acc: 0.4990, Val Acc: 0.5414
7638.7s 829 2025-11-25 17:50:57 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.8205, Val Loss: 0.8206, Train Acc: 0.5170, Val Acc: 0.5246
7650.6s 830 2025-11-25 17:51:09 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 0.8207
7665.6s 831 2025-11-25 17:51:24 | INFO | lstm_model:fit:461 | Early stopping at epoch 55 - Val Loss: 0.8206
7722.0s 832 2025-11-25 17:52:21 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8220, Val Loss: 0.8190, Train Acc: 0.5150, Val Acc: 0.5358
7736.5s 833 2025-11-25 17:52:35 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8219, Val Loss: 0.8206, Train Acc: 0.5190, Val Acc: 0.5246
7756.2s 834 2025-11-25 17:52:55 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8220, Val Loss: 0.8194, Train Acc: 0.5250, Val Acc: 0.5358
7799.0s 835 2025-11-25 17:53:38 | INFO | lstm_model:fit:461 | Early stopping at epoch 16 - Val Loss: 0.8196
7799.4s 836 2025-11-25 17:53:38 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
7807.7s 837 2025-11-25 17:53:46 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8217, Val Loss: 0.8189, Train Acc: 0.5280, Val Acc: 0.5358
7830.1s 838 2025-11-25 17:54:09 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8214, Val Loss: 0.8219, Train Acc: 0.4720, Val Acc: 0.4731
7831.8s 839 2025-11-25 17:54:10 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 0.8186
7832.2s 840 2025-11-25 17:54:11 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
7862.0s 841 2025-11-25 17:54:41 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8220, Val Loss: 0.8209, Train Acc: 0.5320, Val Acc: 0.5246
7904.9s 842 2025-11-25 17:55:23 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8215, Val Loss: 0.8173, Train Acc: 0.5530, Val Acc: 0.5246
7916.3s 843 2025-11-25 17:55:35 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8210, Val Loss: 0.8208, Train Acc: 0.5240, Val Acc: 0.5246
7957.2s 844 2025-11-25 17:56:16 | INFO | lstm_model:fit:461 | Early stopping at epoch 34 - Val Loss: 0.8207
7970.1s 845 2025-11-25 17:56:29 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8217, Val Loss: 0.8171, Train Acc: 0.5470, Val Acc: 0.5246
7991.4s 846 2025-11-25 17:56:50 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8212, Val Loss: 0.8168, Train Acc: 0.5120, Val Acc: 0.5246
7991.5s 847 2025-11-25 17:56:50 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8213, Val Loss: 0.8209, Train Acc: 0.5330, Val Acc: 0.5246
8017.8s 848 2025-11-25 17:57:16 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 0.8168
8017.9s 849 2025-11-25 17:57:16 | INFO | lstm_model:fit:461 | Early stopping at epoch 22 - Val Loss: 0.8206
8018.2s 850 2025-11-25 17:57:17 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
8018.2s 851 2025-11-25 17:57:17 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
8031.5s 852 2025-11-25 17:57:30 | INFO | lstm_model:fit:461 | Early stopping at epoch 16 - Val Loss: 0.8168
8031.9s 853 2025-11-25 17:57:31 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
8032.0s 854 2025-11-25 17:57:31 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
8034.9s 855 2025-11-25 17:57:34 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
8067.7s 856 2025-11-25 17:58:06 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
8096.9s 857 2025-11-25 17:58:35 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8222, Val Loss: 0.8186, Train Acc: 0.5220, Val Acc: 0.5358
8175.2s 858 2025-11-25 17:59:54 | INFO | lstm_model:fit:461 | Early stopping at epoch 16 - Val Loss: 0.8187
8175.7s 859 2025-11-25 17:59:54 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
8239.0s 860 2025-11-25 18:00:58 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8206
8300.2s 861 2025-11-25 18:01:59 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8217, Val Loss: 0.8187, Train Acc: 0.5510, Val Acc: 0.5358
8326.0s 862 2025-11-25 18:02:25 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8207
8383.2s 863 2025-11-25 18:03:22 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8215, Val Loss: 0.8169, Train Acc: 0.5590, Val Acc: 0.5246
8443.9s 864 2025-11-25 18:04:22 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8200
8491.9s 865 2025-11-25 18:05:11 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8215, Val Loss: 0.8190, Train Acc: 0.5210, Val Acc: 0.5358
8548.3s 866 2025-11-25 18:06:07 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8210, Val Loss: 0.8178, Train Acc: 0.5190, Val Acc: 0.5246
8568.0s 867 2025-11-25 18:06:27 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 0.8194
8568.4s 868 2025-11-25 18:06:27 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
8576.5s 869 2025-11-25 18:06:35 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8201
8647.1s 870 2025-11-25 18:07:46 | INFO | lstm_model:fit:461 | Early stopping at epoch 26 - Val Loss: 0.8169
8647.5s 871 2025-11-25 18:07:46 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
8647.5s 872 2025-11-25 18:07:46 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
8649.1s 873 2025-11-25 18:07:48 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8200
8694.3s 874 2025-11-25 18:08:33 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
8827.7s 875 2025-11-25 18:10:46 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8199
8846.4s 876 2025-11-25 18:11:05 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8199
8934.0s 877 2025-11-25 18:12:33 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8217, Val Loss: 0.8169, Train Acc: 0.5220, Val Acc: 0.5246
9047.9s 878 2025-11-25 18:14:26 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8198
9048.0s 879 2025-11-25 18:14:27 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (46926, 6)
9048.0s 880 2025-11-25 18:14:27 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
9048.1s 881 [18:14:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
9048.1s 882 
9048.1s 883 E.g. tree_method = "hist", device = "cuda"
9048.1s 884 
9048.8s 885 [18:14:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
9048.8s 886 
9048.8s 887 E.g. tree_method = "hist", device = "cuda"
9048.8s 888 
9048.8s 889 2025-11-25 18:14:27 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
9049.5s 890 [32m[I 2025-11-25 18:14:28,585][0m Trial 2 finished with value: 1.655273879583522 and parameters: {'learning_rate': 0.006835256921076721, 'max_depth': 4, 'n_estimators': 311, 'subsample': 0.9179774428421892, 'colsample_bytree': 0.6243247559387922, 'min_child_weight': 3, 'gamma': 0.06234364605220527, 'reg_alpha': 0.013558714838122245, 'reg_lambda': 1.7317792238437748}. Best is trial 2 with value: 1.655273879583522.[0m
9049.6s 891 0%|                                                     | 0/5 [32:33<?, ?it/s]
Best trial: 2. Best value: 1.65527:   0%|                 | 0/5 [32:33<?, ?it/s]
Best trial: 2. Best value: 1.65527:  20%|â–ˆ    | 1/5 [32:33<2:10:13, 1953.49s/it]
Best trial: 2. Best value: 1.65527:  20%|â–| 1/5 [32:33<2:10:13, 1953.49s/it, 1952025-11-25 18:14:28 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
9074.3s 892 2025-11-25 18:14:53 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8199
9074.8s 893 2025-11-25 18:14:53 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8225, Val Loss: 0.8220, Train Acc: 0.5250, Val Acc: 0.5154
9086.2s 894 2025-11-25 18:15:05 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8207
9092.5s 895 2025-11-25 18:15:11 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8153, Val Loss: 0.8220, Train Acc: 0.5630, Val Acc: 0.5135
9099.7s 896 2025-11-25 18:15:18 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 0.8251
9100.1s 897 2025-11-25 18:15:19 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
9143.8s 898 2025-11-25 18:16:02 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8231, Val Loss: 0.8182, Train Acc: 0.5300, Val Acc: 0.5414
9167.6s 899 2025-11-25 18:16:26 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8212, Val Loss: 0.8171, Train Acc: 0.5260, Val Acc: 0.5246
9178.7s 900 2025-11-25 18:16:37 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8221, Val Loss: 0.8183, Train Acc: 0.5260, Val Acc: 0.5414
9201.9s 901 2025-11-25 18:17:01 | INFO | lstm_model:fit:461 | Early stopping at epoch 26 - Val Loss: 0.8195
9272.5s 902 2025-11-25 18:18:11 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8221, Val Loss: 0.8211, Train Acc: 0.5230, Val Acc: 0.5246
9317.4s 903 2025-11-25 18:18:56 | INFO | lstm_model:fit:461 | Early stopping at epoch 26 - Val Loss: 0.8167
9317.8s 904 2025-11-25 18:18:56 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
9317.8s 905 2025-11-25 18:18:56 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
9319.1s 906 2025-11-25 18:18:58 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 0.8210
9336.2s 907 2025-11-25 18:19:15 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8199
9336.5s 908 2025-11-25 18:19:15 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (46926, 6)
9336.5s 909 2025-11-25 18:19:15 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
9336.6s 910 [18:19:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
9336.6s 911 
9336.6s 912 E.g. tree_method = "hist", device = "cuda"
9336.6s 913 
9337.4s 914 [18:19:16] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
9337.4s 915 
9337.4s 916 E.g. tree_method = "hist", device = "cuda"
9337.4s 917 
9337.4s 918 2025-11-25 18:19:16 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
9338.2s 919 [32m[I 2025-11-25 18:19:17,344][0m Trial 3 finished with value: 1.7673979712196273 and parameters: {'learning_rate': 0.0018491891185741457, 'max_depth': 7, 'n_estimators': 220, 'subsample': 0.7286452778512917, 'colsample_bytree': 0.7314826007145745, 'min_child_weight': 3, 'gamma': 0.2241588331478992, 'reg_alpha': 0.07667044806527866, 'reg_lambda': 0.6585202324275642}. Best is trial 3 with value: 1.7673979712196273.[0m
9391.9s 920 Best trial: 2. Best value: 1.65527:  20%|â–| 1/5 [37:22<2:10:13, 1953.49s/it, 195
Best trial: 3. Best value: 1.7674:  20%|â–| 1/5 [37:22<2:10:13, 1953.49s/it, 1953
Best trial: 3. Best value: 1.7674:  40%|â–| 2/5 [37:22<48:42, 974.24s/it, 1953.49
Best trial: 3. Best value: 1.7674:  40%|â–| 2/5 [37:22<48:42, 974.24s/it, 2242.252025-11-25 18:20:10 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8221, Val Loss: 0.8187, Train Acc: 0.5390, Val Acc: 0.5358
9415.8s 921 2025-11-25 18:20:34 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8202
9447.9s 922 2025-11-25 18:21:06 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
9448.0s 923 2025-11-25 18:21:07 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8213, Val Loss: 0.8185, Train Acc: 0.5350, Val Acc: 0.5358
9509.1s 924 2025-11-25 18:22:08 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8211, Val Loss: 0.8187, Train Acc: 0.5380, Val Acc: 0.5358
9509.1s 925 2025-11-25 18:22:08 | INFO | lstm_model:fit:461 | Early stopping at epoch 30 - Val Loss: 0.8187
9509.4s 926 2025-11-25 18:22:08 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
9595.7s 927 2025-11-25 18:23:34 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8216, Val Loss: 0.8168, Train Acc: 0.5460, Val Acc: 0.5246
9630.4s 928 2025-11-25 18:24:09 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8199
9668.8s 929 2025-11-25 18:24:47 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8213, Val Loss: 0.8169, Train Acc: 0.5150, Val Acc: 0.5246
9668.8s 930 2025-11-25 18:24:47 | INFO | lstm_model:fit:461 | Early stopping at epoch 20 - Val Loss: 0.8169
9669.1s 931 2025-11-25 18:24:48 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
9669.1s 932 2025-11-25 18:24:48 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
9679.5s 933 2025-11-25 18:24:58 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
9784.0s 934 2025-11-25 18:26:43 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8205
9839.1s 935 2025-11-25 18:27:38 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8198
9852.7s 936 2025-11-25 18:27:51 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8206
10021.4s 937 2025-11-25 18:30:40 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8201
10047.0s 938 2025-11-25 18:31:06 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8199
10047.2s 939 2025-11-25 18:31:06 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (46926, 6)
10047.2s 940 2025-11-25 18:31:06 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
10047.3s 941 [18:31:06] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
10047.3s 942 
10047.3s 943 E.g. tree_method = "hist", device = "cuda"
10047.3s 944 
10048.0s 945 [18:31:07] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
10048.0s 946 
10048.0s 947 E.g. tree_method = "hist", device = "cuda"
10048.0s 948 
10048.0s 949 2025-11-25 18:31:07 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
10048.8s 950 [32m[I 2025-11-25 18:31:07,877][0m Trial 1 finished with value: 1.8936852491366551 and parameters: {'learning_rate': 0.00988622356666093, 'max_depth': 7, 'n_estimators': 366, 'subsample': 0.6711575334724114, 'colsample_bytree': 0.6015465256801901, 'min_child_weight': 4, 'gamma': 0.1765579844119718, 'reg_alpha': 0.0712451070202372, 'reg_lambda': 0.9318313863975304}. Best is trial 1 with value: 1.8936852491366551.[0m
10083.5s 951 Best trial: 3. Best value: 1.7674:  40%|â–| 2/5 [49:12<48:42, 974.24s/it, 2242.25
Best trial: 1. Best value: 1.89369:  40%|â–| 2/5 [49:12<48:42, 974.24s/it, 2242.2
Best trial: 1. Best value: 1.89369:  60%|â–Œ| 3/5 [49:12<28:27, 853.82s/it, 2242.2
Best trial: 1. Best value: 1.89369:  60%|â–Œ| 3/5 [49:12<28:27, 853.82s/it, 2952.72025-11-25 18:31:42 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8199
10160.8s 952 2025-11-25 18:32:59 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8200
10244.8s 953 2025-11-25 18:34:23 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8200
10294.8s 954 2025-11-25 18:35:13 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8198
10406.4s 955 2025-11-25 18:37:05 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8198
10427.9s 956 2025-11-25 18:37:26 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8197
10428.0s 957 2025-11-25 18:37:27 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (46926, 6)
10428.0s 958 2025-11-25 18:37:27 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
10428.1s 959 [18:37:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
10428.1s 960 
10428.1s 961 E.g. tree_method = "hist", device = "cuda"
10428.1s 962 
10428.6s 963 [18:37:27] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
10428.6s 964 
10428.6s 965 E.g. tree_method = "hist", device = "cuda"
10428.6s 966 
10428.6s 967 2025-11-25 18:37:27 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
10429.0s 968 [32m[I 2025-11-25 18:37:28,081][0m Trial 4 finished with value: 1.7911015940994528 and parameters: {'learning_rate': 0.01882828620177215, 'max_depth': 4, 'n_estimators': 200, 'subsample': 0.9129993697610223, 'colsample_bytree': 0.8914358712799606, 'min_child_weight': 5, 'gamma': 0.1854139022133212, 'reg_alpha': 0.001622551827198915, 'reg_lambda': 1.885215912762746}. Best is trial 1 with value: 1.8936852491366551.[0m
10508.3s 969 Best trial: 1. Best value: 1.89369:  60%|â–Œ| 3/5 [55:32<28:27, 853.82s/it, 2952.7
Best trial: 1. Best value: 1.89369:  60%|â–Œ| 3/5 [55:32<28:27, 853.82s/it, 2952.7
Best trial: 1. Best value: 1.89369:  80%|â–Š| 4/5 [55:32<11:06, 666.84s/it, 2952.7
Best trial: 1. Best value: 1.89369:  80%|â–Š| 4/5 [55:32<11:06, 666.84s/it, 3332.92025-11-25 18:38:47 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8197
10508.4s 970 2025-11-25 18:38:47 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (46926, 6)
10508.4s 971 2025-11-25 18:38:47 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
10508.4s 972 [18:38:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
10508.4s 973 
10508.4s 974 E.g. tree_method = "hist", device = "cuda"
10508.4s 975 
10508.8s 976 [18:38:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
10508.8s 977 
10508.8s 978 E.g. tree_method = "hist", device = "cuda"
10508.8s 979 
10508.8s 980 2025-11-25 18:38:47 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
10509.9s 981 [32m[I 2025-11-25 18:38:48,941][0m Trial 0 finished with value: 1.8322066634476097 and parameters: {'learning_rate': 0.08956556228008376, 'max_depth': 10, 'n_estimators': 495, 'subsample': 0.8723014339214354, 'colsample_bytree': 0.8488610950203151, 'min_child_weight': 4, 'gamma': 0.1806945645372124, 'reg_alpha': 0.014293957925527935, 'reg_lambda': 0.7928475083633433}. Best is trial 1 with value: 1.8936852491366551.[0m
10509.9s 982 Best trial: 1. Best value: 1.89369:  80%|â–Š| 4/5 [56:53<11:06, 666.84s/it, 3332.9
Best trial: 1. Best value: 1.89369:  80%|â–Š| 4/5 [56:53<11:06, 666.84s/it, 3332.9
Best trial: 1. Best value: 1.89369: 100%|â–ˆ| 5/5 [56:53<00:00, 455.53s/it, 3332.9
Best trial: 1. Best value: 1.89369: 100%|â–ˆ| 5/5 [56:53<00:00, 455.53s/it, 3413.8
Best trial: 1. Best value: 1.89369: 100%|â–ˆ| 5/5 [56:53<00:00, 682.77s/it, 3413.8
10509.9s 983 2025-11-25 18:38:48 | INFO | walk_forward:optimize_hyperparameters:258 | Best trial: 1
10509.9s 984 2025-11-25 18:38:48 | INFO | walk_forward:optimize_hyperparameters:259 | Best value: 1.8937
10509.9s 985 2025-11-25 18:38:48 | INFO | walk_forward:optimize_hyperparameters:260 | Best params: {'learning_rate': 0.00988622356666093, 'max_depth': 7, 'n_estimators': 366, 'subsample': 0.6711575334724114, 'colsample_bytree': 0.6015465256801901, 'min_child_weight': 4, 'gamma': 0.1765579844119718, 'reg_alpha': 0.0712451070202372, 'reg_lambda': 0.9318313863975304}
10509.9s 986 2025-11-25 18:38:48 | INFO | walk_forward:run_walk_forward_optimization:313 | Training model with optimized parameters
10509.9s 987 2025-11-25 18:38:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
10531.0s 988 2025-11-25 18:39:10 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8213, Val Loss: 0.8237, Train Acc: 0.5350, Val Acc: 0.5148
10542.0s 989 2025-11-25 18:39:21 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8133, Val Loss: 0.8248, Train Acc: 0.5820, Val Acc: 0.5141
10553.1s 990 2025-11-25 18:39:32 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8096, Val Loss: 0.8235, Train Acc: 0.5700, Val Acc: 0.5247
10564.2s 991 2025-11-25 18:39:43 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8035, Val Loss: 0.8207, Train Acc: 0.5720, Val Acc: 0.5378
10575.2s 992 2025-11-25 18:39:54 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.7820, Val Loss: 0.8110, Train Acc: 0.6360, Val Acc: 0.5686
10586.2s 993 2025-11-25 18:40:05 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.7648, Val Loss: 0.8028, Train Acc: 0.6740, Val Acc: 0.5904
10597.4s 994 2025-11-25 18:40:16 | INFO | lstm_model:fit:440 | Epoch 70/100 - Loss: 0.7541, Val Loss: 0.7985, Train Acc: 0.6760, Val Acc: 0.5996
10608.5s 995 2025-11-25 18:40:27 | INFO | lstm_model:fit:440 | Epoch 80/100 - Loss: 0.7460, Val Loss: 0.8013, Train Acc: 0.6530, Val Acc: 0.6026
10619.5s 996 2025-11-25 18:40:38 | INFO | lstm_model:fit:440 | Epoch 90/100 - Loss: 0.7418, Val Loss: 0.8018, Train Acc: 0.7140, Val Acc: 0.6042
10630.5s 997 2025-11-25 18:40:49 | INFO | lstm_model:fit:440 | Epoch 100/100 - Loss: 0.7405, Val Loss: 0.8024, Train Acc: 0.7220, Val Acc: 0.6047
10630.9s 998 2025-11-25 18:40:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
10664.7s 999 2025-11-25 18:41:23 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8225, Val Loss: 0.8201, Train Acc: 0.5050, Val Acc: 0.5318
10686.1s 1000 2025-11-25 18:41:45 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8220, Val Loss: 0.8190, Train Acc: 0.5230, Val Acc: 0.5318
10699.1s 1001 2025-11-25 18:41:58 | INFO | lstm_model:fit:461 | Early stopping at epoch 26 - Val Loss: 0.8189
10744.9s 1002 2025-11-25 18:42:43 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8219, Val Loss: 0.8206, Train Acc: 0.5350, Val Acc: 0.5364
10776.1s 1003 2025-11-25 18:43:15 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8213, Val Loss: 0.8194, Train Acc: 0.5480, Val Acc: 0.5364
10804.6s 1004 2025-11-25 18:43:43 | INFO | lstm_model:fit:461 | Early stopping at epoch 29 - Val Loss: 0.8192
10861.6s 1005 2025-11-25 18:44:40 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8215, Val Loss: 0.8172, Train Acc: 0.5310, Val Acc: 0.5207
10903.2s 1006 2025-11-25 18:45:22 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8211, Val Loss: 0.8171, Train Acc: 0.5140, Val Acc: 0.5207
10911.4s 1007 2025-11-25 18:45:30 | INFO | lstm_model:fit:461 | Early stopping at epoch 22 - Val Loss: 0.8176
10911.7s 1008 2025-11-25 18:45:30 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
10980.3s 1009 2025-11-25 18:46:39 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8209, Val Loss: 0.8216, Train Acc: 0.5390, Val Acc: 0.5009
10990.4s 1010 2025-11-25 18:46:49 | INFO | lstm_model:fit:461 | Early stopping at epoch 12 - Val Loss: 0.8232
10990.7s 1011 2025-11-25 18:46:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
10990.7s 1012 2025-11-25 18:46:49 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
11006.3s 1013 2025-11-25 18:47:05 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
11125.9s 1014 2025-11-25 18:49:04 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.8206
11245.5s 1015 2025-11-25 18:51:04 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.8205
11364.0s 1016 2025-11-25 18:53:03 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.8203
11482.9s 1017 2025-11-25 18:55:01 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.8203
11602.5s 1018 2025-11-25 18:57:01 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.8202
11603.0s 1019 2025-11-25 18:57:02 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (58657, 6)
11603.0s 1020 2025-11-25 18:57:02 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
11603.1s 1021 /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [18:57:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
11603.1s 1022 
11603.1s 1023 E.g. tree_method = "hist", device = "cuda"
11603.1s 1024 
11603.1s 1025 warnings.warn(smsg, UserWarning)
11603.5s 1026 2025-11-25 18:57:02 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
11604.3s 1027 2025-11-25 18:57:03 | INFO | walk_forward:run_walk_forward_optimization:348 | OOS Balanced Accuracy: 0.4235
11604.3s 1028 2025-11-25 18:57:03 | INFO | walk_forward:run_walk_forward_optimization:349 | OOS F1 Score: 0.6351
11604.4s 1029 2025-11-25 18:57:03 | INFO | walk_forward:run_walk_forward_optimization:372 |
11604.4s 1030 Completed 3 Walk-Forward folds
11604.4s 1031 2025-11-25 18:57:03 | INFO | walk_forward:aggregate_results:402 |
11604.4s 1032 ============================================================
11604.4s 1033 2025-11-25 18:57:03 | INFO | walk_forward:aggregate_results:403 | Walk-Forward Optimization Summary
11604.4s 1034 2025-11-25 18:57:03 | INFO | walk_forward:aggregate_results:404 | ============================================================
11604.4s 1035 2025-11-25 18:57:03 | INFO | walk_forward:aggregate_results:405 | Total Folds: 3
11604.4s 1036 2025-11-25 18:57:03 | INFO | walk_forward:aggregate_results:406 | Avg Balanced Accuracy: 0.4289 Â± 0.0087
11604.4s 1037 2025-11-25 18:57:03 | INFO | walk_forward:aggregate_results:408 | Avg F1 Score: 0.6407 Â± 0.0087
11604.4s 1038 2025-11-25 18:57:03 | INFO | walk_forward:aggregate_results:410 | ============================================================
11604.4s 1039 2025-11-25 18:57:03 | INFO | main:train_model:445 | WFO summary saved to /kaggle/working/results/XAU_USD_wfo_summary.csv
11604.4s 1040 2025-11-25 18:57:03 | INFO | lstm_model:save_model:609 | LSTM model saved to /kaggle/working/models/XAU_USD_model_lstm_base.pth
11604.4s 1041 2025-11-25 18:57:03 | INFO | hybrid_ensemble:save_model:426 | Hybrid Ensemble saved to /kaggle/working/models/XAU_USD_model_*
11604.4s 1042 2025-11-25 18:57:03 | INFO | main:train_model:462 | Model saved to /kaggle/working/models/XAU_USD_model_*
11604.4s 1043 2025-11-25 18:57:03 | INFO | main:train_model:477 | Feature schema saved to /kaggle/working/models/XAU_USD_feature_schema.json
11604.4s 1044 2025-11-25 18:57:03 | INFO | main:generate_predictions:494 | ============================================================
11604.4s 1045 2025-11-25 18:57:03 | INFO | main:generate_predictions:495 | STEP 5: PREDICTION GENERATION
11604.4s 1046 2025-11-25 18:57:03 | INFO | main:generate_predictions:496 | ============================================================
11604.5s 1047 2025-11-25 18:57:03 | INFO | main:generate_predictions:586 |
11604.5s 1048 Latest Signal (2025-11-25 16:50:00):
11604.5s 1049 2025-11-25 18:57:03 | INFO | main:generate_predictions:587 |   Close: 4121.82000
11604.5s 1050 2025-11-25 18:57:03 | INFO | main:generate_predictions:588 |   Signal: HOLD
11604.5s 1051 2025-11-25 18:57:03 | INFO | main:generate_predictions:589 |   Buy Confidence: 67.54%
11604.5s 1052 2025-11-25 18:57:03 | INFO | main:generate_predictions:590 |   Sell Confidence: 30.66%
11604.5s 1053 2025-11-25 18:57:03 | INFO | main:generate_predictions:591 |   Hold Confidence: 1.80%
11604.5s 1054 2025-11-25 18:57:03 | INFO | main:generate_predictions:594 |
11604.5s 1055 Fuzzy Quality Score: 30.5/100
11604.5s 1056 2025-11-25 18:57:03 | INFO | main:generate_predictions:595 |     - Confidence: 24.0/40
11604.5s 1057 2025-11-25 18:57:03 | INFO | main:generate_predictions:596 |     - Trend Alignment: 0.0/25
11604.5s 1058 2025-11-25 18:57:03 | INFO | main:generate_predictions:597 |     - Volatility Regime: 2.0/20
11604.5s 1059 2025-11-25 18:57:03 | INFO | main:generate_predictions:598 |     - Momentum Confirm: 4.5/15
11604.5s 1060 2025-11-25 18:57:03 | INFO | main:generate_predictions:599 |   Position Size: 0% of base
11604.5s 1061 2025-11-25 18:57:03 | INFO | main:generate_predictions:607 |
11604.5s 1062 Signal Quality Summary:
11604.5s 1063 2025-11-25 18:57:03 | INFO | main:generate_predictions:608 |     Total Signals: 35
11604.5s 1064 2025-11-25 18:57:03 | INFO | main:generate_predictions:609 |     High Quality (â‰¥60): 23 (66%)
11604.5s 1065 2025-11-25 18:57:03 | INFO | main:generate_predictions:614 | Predictions saved to /kaggle/working/results/XAU_USD_predictions.csv
11604.5s 1066 2025-11-25 18:57:03 | INFO | main:run_full_pipeline:667 | ============================================================
11604.5s 1067 2025-11-25 18:57:03 | INFO | main:run_full_pipeline:668 | PIPELINE COMPLETED SUCCESSFULLY in 3:10:14.841670
11604.5s 1068 2025-11-25 18:57:03 | INFO | main:run_full_pipeline:669 | ============================================================
11604.5s 1069 2025-11-25 18:57:03 | SUCCESS | main:main:701 | âœ“ XAU_USD training completed successfully
11604.5s 1070 2025-11-25 18:57:03 | INFO | main:main:702 |
11604.5s 1071 Latest XAU_USD Predictions:
11604.5s 1072 2025-11-25 18:57:03 | INFO | main:main:703 |              timestamp    close  ...  quality_momentum  signal
11604.5s 1073 95 2025-11-25 16:30:00  4128.76  ...               4.5    HOLD
11604.5s 1074 96 2025-11-25 16:35:00  4122.64  ...               4.5    HOLD
11604.5s 1075 97 2025-11-25 16:40:00  4119.80  ...               4.5    HOLD
11604.5s 1076 98 2025-11-25 16:45:00  4114.97  ...               4.5    HOLD
11604.5s 1077 99 2025-11-25 16:50:00  4121.82  ...               4.5    HOLD
11604.5s 1078 
11604.5s 1079 [5 rows x 13 columns]
11604.5s 1080 2025-11-25 18:57:03 | INFO | main:main:686 |
11604.5s 1081 ================================================================================
11604.5s 1082 2025-11-25 18:57:03 | INFO | main:main:687 | STARTING TRAINING FOR USD_CHF
11604.5s 1083 2025-11-25 18:57:03 | INFO | main:main:688 | ================================================================================
11604.5s 1084 
11604.5s 1085 2025-11-25 18:57:03 | INFO | kaggle_loader:__init__:36 | FX Data Directory: /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data
11604.5s 1086 2025-11-25 18:57:03 | INFO | kaggle_loader:__init__:37 | Macro Events Directory: /kaggle/input/macros-and-ohlc/data/kaggle_dataset/macro_events
11604.5s 1087 2025-11-25 18:57:03 | INFO | news_loader:__init__:38 | Kaggle News Dataset: miguelaenlle/massive-stock-news-analysis-db-for-nlpbacktests
11604.5s 1088 2025-11-25 18:57:03 | INFO | news_loader:__init__:39 | Kaggle News Data Directory: /kaggle/input/massive-stock-news-analysis-db-for-nlpbacktests
11604.5s 1089 2025-11-25 18:57:03 | INFO | main:__init__:98 | Using Kaggle dataset
11604.5s 1090 2025-11-25 18:57:03 | INFO | sentiment_features:__init__:39 | Loading sentiment model: ProsusAI/finbert
11605.4s 1091 2025-11-25 18:57:04 | SUCCESS | sentiment_features:__init__:50 | âœ“ Sentiment model loaded successfully
11605.4s 1092 2025-11-25 18:57:04 | SUCCESS | main:__init__:117 | âœ“ Sentiment features enabled
11605.4s 1093 2025-11-25 18:57:04 | INFO | main:__init__:130 | Pipeline initialized for USD_CHF
11605.4s 1094 2025-11-25 18:57:04 | INFO | main:run_full_pipeline:630 | ============================================================
11605.4s 1095 2025-11-25 18:57:04 | INFO | main:run_full_pipeline:631 | FOREX CLASSIFIER PIPELINE - FULL EXECUTION
11605.4s 1096 2025-11-25 18:57:04 | INFO | main:run_full_pipeline:632 | Currency Pair: USD_CHF
11605.4s 1097 2025-11-25 18:57:04 | INFO | main:run_full_pipeline:633 | ============================================================
11605.4s 1098 2025-11-25 18:57:04 | INFO | main:fetch_data:141 | ============================================================
11605.4s 1099 2025-11-25 18:57:04 | INFO | main:fetch_data:142 | STEP 1: DATA ACQUISITION
11605.4s 1100 2025-11-25 18:57:04 | INFO | main:fetch_data:143 | ============================================================
11605.4s 1101 2025-11-25 18:57:04 | INFO | main:fetch_data:148 | Loading data for USD_CHF from Kaggle dataset
11605.4s 1102 2025-11-25 18:57:04 | INFO | kaggle_loader:load_symbol_data:74 | Loading USDCHF data from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data/USDCHF_M5.parquet
11605.5s 1103 2025-11-25 18:57:04 | INFO | kaggle_loader:load_symbol_data:77 | Loaded 80,000 candles for USDCHF
11605.5s 1104 2025-11-25 18:57:04 | INFO | kaggle_loader:load_symbol_data:78 | Date range: 2024-10-29 22:20:00 to 2025-11-25 17:20:00
11605.5s 1105 2025-11-25 18:57:04 | INFO | main:fetch_data:154 | Loaded 80,000 M5 candles
11605.5s 1106 2025-11-25 18:57:04 | INFO | kaggle_loader:load_symbol_data:74 | Loading USDCHF data from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data/USDCHF_H1.parquet
11605.5s 1107 2025-11-25 18:57:04 | INFO | kaggle_loader:load_symbol_data:77 | Loaded 7,000 candles for USDCHF
11605.5s 1108 2025-11-25 18:57:04 | INFO | kaggle_loader:load_symbol_data:78 | Date range: 2024-10-10 02:00:00 to 2025-11-25 17:00:00
11605.5s 1109 2025-11-25 18:57:04 | INFO | main:fetch_data:163 | Loaded 7,000 H1 candles
11605.5s 1110 2025-11-25 18:57:04 | INFO | kaggle_loader:load_symbol_data:74 | Loading USDCHF data from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data/USDCHF_H4.parquet
11605.5s 1111 2025-11-25 18:57:04 | INFO | kaggle_loader:load_symbol_data:77 | Loaded 2,000 candles for USDCHF
11605.5s 1112 2025-11-25 18:57:04 | INFO | kaggle_loader:load_symbol_data:78 | Date range: 2024-08-13 12:00:00 to 2025-11-25 16:00:00
11605.5s 1113 2025-11-25 18:57:04 | INFO | main:fetch_data:163 | Loaded 2,000 H4 candles
11605.5s 1114 2025-11-25 18:57:04 | INFO | kaggle_loader:load_macro_events:153 | Loading macro events for USDCHF from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/macro_events/USDCHF_events.parquet
11605.5s 1115 2025-11-25 18:57:04 | INFO | kaggle_loader:load_macro_events:156 | Loaded 90 events for USDCHF
11605.5s 1116 2025-11-25 18:57:04 | INFO | kaggle_loader:load_macro_events:157 | Date range: 2024-10-18 17:29:28.981847 to 2025-10-17 17:29:28.981847
11605.5s 1117 2025-11-25 18:57:04 | SUCCESS | main:fetch_data:171 | âœ“ Loaded 90 macro events
11605.5s 1118 2025-11-25 18:57:04 | WARNING | news_loader:_download_and_unzip_data:53 | News dataset not found at /kaggle/input/massive-stock-news-analysis-db-for-nlpbacktests/analyst_ratings_processed.csv
11605.5s 1119 2025-11-25 18:57:04 | WARNING | news_loader:_download_and_unzip_data:54 | News sentiment features will be disabled. To enable, attach 'massive-stock-news-analysis-db-for-nlpbacktests' as input.
11605.5s 1120 2025-11-25 18:57:04 | INFO | news_loader:load_historical_news:105 | News dataset unavailable - returning empty DataFrame
11605.5s 1121 2025-11-25 18:57:04 | INFO | main:fetch_data:199 | Fetched 80000 primary price bars
11605.5s 1122 2025-11-25 18:57:04 | INFO | main:engineer_features:205 | ============================================================
11605.5s 1123 2025-11-25 18:57:04 | INFO | main:engineer_features:206 | STEP 2: FEATURE ENGINEERING
11605.5s 1124 2025-11-25 18:57:04 | INFO | main:engineer_features:207 | ============================================================
11605.5s 1125 2025-11-25 18:57:04 | INFO | main:engineer_features:213 | Calculating base technical features on primary timeframe...
11605.6s 1126 2025-11-25 18:57:04 | SUCCESS | main:engineer_features:219 | âœ“ Calculated 67 base features.
11605.6s 1127 2025-11-25 18:57:04 | INFO | technical_features:add_multi_timeframe_features:259 | Adding multi-timeframe features and regime classification...
11605.7s 1128 2025-11-25 18:57:04 | INFO | technical_features:add_multi_timeframe_features:263 | Calculating features for H1 timeframe...
11605.7s 1129 2025-11-25 18:57:04 | SUCCESS | technical_features:add_multi_timeframe_features:289 | âœ“ Merged H1 features.
11605.7s 1130 2025-11-25 18:57:04 | INFO | technical_features:add_multi_timeframe_features:263 | Calculating features for H4 timeframe...
11605.8s 1131 2025-11-25 18:57:04 | SUCCESS | technical_features:add_multi_timeframe_features:289 | âœ“ Merged H4 features.
11605.8s 1132 2025-11-25 18:57:04 | INFO | main:engineer_features:276 | Dropped 0 rows with NaNs after feature engineering.
11605.8s 1133 2025-11-25 18:57:04 | INFO | main:engineer_features:278 | âœ“ 86 total features created, 79800 samples ready.
11605.8s 1134 2025-11-25 18:57:04 | INFO | main:create_target:295 | ============================================================
11605.8s 1135 2025-11-25 18:57:04 | INFO | main:create_target:296 | STEP 3: TARGET CREATION
11605.8s 1136 2025-11-25 18:57:04 | INFO | main:create_target:297 | ============================================================
11605.8s 1137 2025-11-25 18:57:04 | INFO | main:create_target:314 | Using pip multiplier for USD_CHF: 10000
11605.8s 1138 2025-11-25 18:57:04 | INFO | main:create_target:325 | Using fixed threshold: 4.0 pips
11605.8s 1139 2025-11-25 18:57:04 | INFO | main:create_target:381 | Target class distribution:
11605.8s 1140 2025-11-25 18:57:04 | INFO | main:create_target:385 |   Buy: 15163 (19.0%)
11605.8s 1141 2025-11-25 18:57:04 | INFO | main:create_target:385 |   Sell: 15457 (19.4%)
11605.8s 1142 2025-11-25 18:57:04 | INFO | main:create_target:385 |   Hold: 49174 (61.6%)
11605.8s 1143 2025-11-25 18:57:04 | INFO | main:train_model:399 | ============================================================
11605.8s 1144 2025-11-25 18:57:04 | INFO | main:train_model:400 | STEP 4: MODEL TRAINING
11605.8s 1145 2025-11-25 18:57:04 | INFO | main:train_model:401 | ============================================================
11605.8s 1146 2025-11-25 18:57:04 | INFO | main:train_model:417 | Using 81 features for training
11605.8s 1147 2025-11-25 18:57:04 | INFO | walk_forward:run_walk_forward_optimization:285 | Starting Walk-Forward Optimization
11605.8s 1148 2025-11-25 18:57:04 | INFO | walk_forward:split:94 | Split 1: Train [2024-10-30 15:00:00 to 2025-04-30 14:55:00], Test [2025-04-30 15:00:00 to 2025-06-30 14:55:00]
11605.8s 1149 2025-11-25 18:57:04 | INFO | walk_forward:run_walk_forward_optimization:291 |
11605.8s 1150 ============================================================
11605.8s 1151 2025-11-25 18:57:04 | INFO | walk_forward:run_walk_forward_optimization:292 | Walk-Forward Fold 1
11605.8s 1152 2025-11-25 18:57:04 | INFO | walk_forward:run_walk_forward_optimization:293 | ============================================================
11605.9s 1153 2025-11-25 18:57:04 | INFO | walk_forward:optimize_hyperparameters:240 | Starting hyperparameter optimization
11605.9s 1154 [32m[I 2025-11-25 18:57:04,970][0m A new study created in memory with name: no-name-a862771c-63a5-44c4-bd6e-6b0e14b03b42[0m
11605.9s 1155 0%|                                                     | 0/5 [00:00<?, ?it/s]2025-11-25 18:57:05 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
11605.9s 1156 2025-11-25 18:57:05 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
11605.9s 1157 2025-11-25 18:57:05 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
11606.0s 1158 2025-11-25 18:57:05 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
11627.6s 1159 2025-11-25 18:57:26 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8974, Val Loss: 0.9246, Train Acc: 0.6510, Val Acc: 0.6378
11636.2s 1160 2025-11-25 18:57:35 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 0.9317
11636.4s 1161 2025-11-25 18:57:35 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
11660.4s 1162 2025-11-25 18:57:59 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9005, Val Loss: 0.9211, Train Acc: 0.6590, Val Acc: 0.6362
11668.9s 1163 2025-11-25 18:58:07 | INFO | lstm_model:fit:461 | Early stopping at epoch 15 - Val Loss: 0.9277
11668.9s 1164 2025-11-25 18:58:07 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9033, Val Loss: 0.9322, Train Acc: 0.6670, Val Acc: 0.6364
11669.2s 1165 2025-11-25 18:58:08 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
11674.3s 1166 2025-11-25 18:58:13 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9089, Val Loss: 0.9028, Train Acc: 0.6420, Val Acc: 0.6636
11676.4s 1167 2025-11-25 18:58:15 | INFO | lstm_model:fit:461 | Early stopping at epoch 15 - Val Loss: 0.9292
11676.7s 1168 2025-11-25 18:58:15 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
11695.2s 1169 2025-11-25 18:58:34 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9094, Val Loss: 0.9017, Train Acc: 0.6430, Val Acc: 0.6683
11695.8s 1170 2025-11-25 18:58:34 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9004, Val Loss: 0.9358, Train Acc: 0.6430, Val Acc: 0.6348
11702.8s 1171 2025-11-25 18:58:41 | INFO | lstm_model:fit:461 | Early stopping at epoch 15 - Val Loss: 0.9221
11703.1s 1172 2025-11-25 18:58:42 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
11703.7s 1173 2025-11-25 18:58:42 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 0.8919
11748.3s 1174 2025-11-25 18:59:27 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9002, Val Loss: 0.9396, Train Acc: 0.6530, Val Acc: 0.6188
11753.1s 1175 2025-11-25 18:59:32 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9080, Val Loss: 0.8890, Train Acc: 0.6490, Val Acc: 0.6650
11774.6s 1176 2025-11-25 18:59:53 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9098, Val Loss: 0.8879, Train Acc: 0.6360, Val Acc: 0.6646
11782.6s 1177 2025-11-25 19:00:01 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9002, Val Loss: 0.8990, Train Acc: 0.6520, Val Acc: 0.6658
11783.1s 1178 2025-11-25 19:00:02 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8989, Val Loss: 0.9413, Train Acc: 0.6360, Val Acc: 0.6186
11809.6s 1179 2025-11-25 19:00:28 | INFO | lstm_model:fit:461 | Early stopping at epoch 29 - Val Loss: 0.9041
11815.1s 1180 2025-11-25 19:00:34 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8996, Val Loss: 0.9012, Train Acc: 0.6440, Val Acc: 0.6642
11818.0s 1181 2025-11-25 19:00:37 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8966, Val Loss: 0.9362, Train Acc: 0.6590, Val Acc: 0.6182
11827.2s 1182 2025-11-25 19:00:46 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 0.9037
11832.1s 1183 2025-11-25 19:00:51 | INFO | lstm_model:fit:461 | Early stopping at epoch 34 - Val Loss: 0.9333
11841.2s 1184 2025-11-25 19:01:00 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9079, Val Loss: 0.8875, Train Acc: 0.6490, Val Acc: 0.6667
11866.4s 1185 2025-11-25 19:01:25 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9048, Val Loss: 0.9118, Train Acc: 0.6590, Val Acc: 0.6640
11892.3s 1186 2025-11-25 19:01:51 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9102, Val Loss: 0.8702, Train Acc: 0.6430, Val Acc: 0.6822
11892.4s 1187 2025-11-25 19:01:51 | INFO | lstm_model:fit:461 | Early stopping at epoch 26 - Val Loss: 0.8960
11906.0s 1188 2025-11-25 19:02:05 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9034, Val Loss: 0.9384, Train Acc: 0.6390, Val Acc: 0.6193
11938.0s 1189 2025-11-25 19:02:37 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9059, Val Loss: 0.8737, Train Acc: 0.6760, Val Acc: 0.6826
11949.2s 1190 2025-11-25 19:02:48 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8983, Val Loss: 0.9330, Train Acc: 0.6190, Val Acc: 0.6174
11966.1s 1191 2025-11-25 19:03:05 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9021, Val Loss: 0.9330, Train Acc: 0.6220, Val Acc: 0.6156
11984.2s 1192 2025-11-25 19:03:23 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9061, Val Loss: 0.8750, Train Acc: 0.6560, Val Acc: 0.6826
11992.8s 1193 2025-11-25 19:03:31 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8959, Val Loss: 0.9351, Train Acc: 0.6530, Val Acc: 0.6188
11993.1s 1194 2025-11-25 19:03:32 | INFO | lstm_model:fit:461 | Early stopping at epoch 32 - Val Loss: 0.8713
11993.5s 1195 2025-11-25 19:03:32 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
12022.2s 1196 2025-11-25 19:04:01 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8978, Val Loss: 0.9320, Train Acc: 0.6410, Val Acc: 0.6166
12030.5s 1197 2025-11-25 19:04:09 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8962, Val Loss: 0.9383, Train Acc: 0.6730, Val Acc: 0.6186
12034.6s 1198 2025-11-25 19:04:13 | INFO | lstm_model:fit:461 | Early stopping at epoch 41 - Val Loss: 0.9311
12065.8s 1199 2025-11-25 19:04:44 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9008, Val Loss: 0.9385, Train Acc: 0.6420, Val Acc: 0.6021
12066.3s 1200 2025-11-25 19:04:45 | INFO | lstm_model:fit:461 | Early stopping at epoch 29 - Val Loss: 0.9369
12083.4s 1201 2025-11-25 19:05:02 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9016, Val Loss: 0.9605, Train Acc: 0.6720, Val Acc: 0.6190
12120.4s 1202 2025-11-25 19:05:39 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8994, Val Loss: 0.9408, Train Acc: 0.6470, Val Acc: 0.6021
12131.9s 1203 2025-11-25 19:05:51 | INFO | lstm_model:fit:461 | Early stopping at epoch 22 - Val Loss: 0.9350
12132.3s 1204 2025-11-25 19:05:51 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
12132.4s 1205 2025-11-25 19:05:51 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
12140.3s 1206 2025-11-25 19:05:59 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8986, Val Loss: 0.9394, Train Acc: 0.6460, Val Acc: 0.6188
12142.0s 1207 2025-11-25 19:06:01 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9090, Val Loss: 0.8724, Train Acc: 0.6330, Val Acc: 0.6826
12145.6s 1208 2025-11-25 19:06:04 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
12179.1s 1209 2025-11-25 19:06:38 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 0.8715
12179.4s 1210 2025-11-25 19:06:38 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
12209.8s 1211 2025-11-25 19:07:08 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8975, Val Loss: 0.9322, Train Acc: 0.6500, Val Acc: 0.6158
12216.9s 1212 2025-11-25 19:07:15 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9091, Val Loss: 0.8691, Train Acc: 0.6580, Val Acc: 0.6818
12251.9s 1213 2025-11-25 19:07:50 | INFO | lstm_model:fit:461 | Early stopping at epoch 15 - Val Loss: 0.8697
12252.2s 1214 2025-11-25 19:07:51 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
12278.7s 1215 2025-11-25 19:08:17 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8959, Val Loss: 0.9308, Train Acc: 0.6040, Val Acc: 0.6160
12280.0s 1216 2025-11-25 19:08:19 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9055
12303.2s 1217 2025-11-25 19:08:42 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9010, Val Loss: 0.9384, Train Acc: 0.6630, Val Acc: 0.6023
12342.2s 1218 2025-11-25 19:09:21 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.8935, Val Loss: 0.9364, Train Acc: 0.6690, Val Acc: 0.6186
12342.2s 1219 2025-11-25 19:09:21 | INFO | lstm_model:fit:461 | Early stopping at epoch 50 - Val Loss: 0.9364
12374.1s 1220 2025-11-25 19:09:53 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8999, Val Loss: 0.9405, Train Acc: 0.6490, Val Acc: 0.6021
12412.3s 1221 2025-11-25 19:10:31 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9032
12443.9s 1222 2025-11-25 19:11:02 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9017, Val Loss: 0.9395, Train Acc: 0.6600, Val Acc: 0.6021
12444.5s 1223 2025-11-25 19:11:03 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8978, Val Loss: 0.9392, Train Acc: 0.6490, Val Acc: 0.6021
12493.7s 1224 2025-11-25 19:11:52 | INFO | lstm_model:fit:461 | Early stopping at epoch 37 - Val Loss: 0.9375
12494.0s 1225 2025-11-25 19:11:53 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
12494.0s 1226 2025-11-25 19:11:53 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
12530.9s 1227 2025-11-25 19:12:29 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8992, Val Loss: 0.9375, Train Acc: 0.6600, Val Acc: 0.6021
12545.8s 1228 2025-11-25 19:12:44 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9040
12548.2s 1229 2025-11-25 19:12:47 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
12597.4s 1230 2025-11-25 19:13:36 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9083, Val Loss: 0.8696, Train Acc: 0.6640, Val Acc: 0.6826
12628.5s 1231 2025-11-25 19:14:07 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8982, Val Loss: 0.9381, Train Acc: 0.6550, Val Acc: 0.6021
12677.4s 1232 2025-11-25 19:14:56 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9033
12693.7s 1233 2025-11-25 19:15:12 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 0.8774
12694.1s 1234 2025-11-25 19:15:13 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
12709.7s 1235 2025-11-25 19:15:28 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9049
12733.0s 1236 2025-11-25 19:15:52 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8977, Val Loss: 0.9354, Train Acc: 0.6450, Val Acc: 0.6021
12763.3s 1237 2025-11-25 19:16:22 | INFO | lstm_model:fit:461 | Early stopping at epoch 43 - Val Loss: 0.9352
12763.6s 1238 2025-11-25 19:16:22 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
12763.6s 1239 2025-11-25 19:16:22 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
12802.8s 1240 2025-11-25 19:17:01 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9030
12803.0s 1241 2025-11-25 19:17:02 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (29489, 6)
12803.0s 1242 2025-11-25 19:17:02 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
12803.1s 1243 [19:17:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
12803.1s 1244 
12803.1s 1245 E.g. tree_method = "hist", device = "cuda"
12803.1s 1246 
12803.9s 1247 [19:17:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
12803.9s 1248 
12803.9s 1249 E.g. tree_method = "hist", device = "cuda"
12803.9s 1250 
12803.9s 1251 2025-11-25 19:17:02 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
12804.4s 1252 [32m[I 2025-11-25 19:17:03,448][0m Trial 3 finished with value: 0.9653425753132499 and parameters: {'learning_rate': 0.03378901354407841, 'max_depth': 4, 'n_estimators': 263, 'subsample': 0.6633104459987039, 'colsample_bytree': 0.8531447398193139, 'min_child_weight': 5, 'gamma': 0.0965971678332736, 'reg_alpha': 0.061669340074151084, 'reg_lambda': 1.738157571032385}. Best is trial 3 with value: 0.9653425753132499.[0m
12804.5s 1253 0%|                                                     | 0/5 [19:58<?, ?it/s]
Best trial: 3. Best value: 0.965343:   0%|                | 0/5 [19:58<?, ?it/s]
Best trial: 3. Best value: 0.965343:  20%|â–Š   | 1/5 [19:58<1:19:53, 1198.48s/it]
Best trial: 3. Best value: 0.965343:  20%|â–| 1/5 [19:58<1:19:53, 1198.48s/it, 112025-11-25 19:17:03 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
12819.7s 1254 2025-11-25 19:17:18 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8980, Val Loss: 0.9182, Train Acc: 0.6380, Val Acc: 0.6360
12830.2s 1255 2025-11-25 19:17:29 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8876, Val Loss: 0.9304, Train Acc: 0.6760, Val Acc: 0.6360
12830.2s 1256 2025-11-25 19:17:29 | INFO | lstm_model:fit:461 | Early stopping at epoch 20 - Val Loss: 0.9304
12830.6s 1257 2025-11-25 19:17:29 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
12856.6s 1258 2025-11-25 19:17:55 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9106, Val Loss: 0.8987, Train Acc: 0.6350, Val Acc: 0.6626
12864.2s 1259 2025-11-25 19:18:03 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9041
12867.5s 1260 2025-11-25 19:18:06 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
12879.1s 1261 2025-11-25 19:18:18 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9057, Val Loss: 0.8866, Train Acc: 0.6270, Val Acc: 0.6677
12902.1s 1262 2025-11-25 19:18:41 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9012, Val Loss: 0.9009, Train Acc: 0.6260, Val Acc: 0.6679
12915.4s 1263 2025-11-25 19:18:54 | INFO | lstm_model:fit:461 | Early stopping at epoch 36 - Val Loss: 0.9181
12954.5s 1264 2025-11-25 19:19:33 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9019, Val Loss: 0.9332, Train Acc: 0.6320, Val Acc: 0.6162
12987.6s 1265 2025-11-25 19:20:06 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8981, Val Loss: 0.9321, Train Acc: 0.6650, Val Acc: 0.6168
13020.6s 1266 2025-11-25 19:20:39 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8965, Val Loss: 0.9313, Train Acc: 0.6420, Val Acc: 0.6168
13025.0s 1267 2025-11-25 19:20:44 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9034
13032.1s 1268 2025-11-25 19:20:51 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9037, Val Loss: 0.9380, Train Acc: 0.6570, Val Acc: 0.6021
13054.3s 1269 2025-11-25 19:21:13 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8946, Val Loss: 0.9367, Train Acc: 0.6470, Val Acc: 0.6186
13054.3s 1270 2025-11-25 19:21:13 | INFO | lstm_model:fit:461 | Early stopping at epoch 40 - Val Loss: 0.9367
13103.7s 1271 2025-11-25 19:22:02 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9086, Val Loss: 0.8716, Train Acc: 0.6350, Val Acc: 0.6820
13118.0s 1272 2025-11-25 19:22:17 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9047
13121.4s 1273 2025-11-25 19:22:20 | INFO | lstm_model:fit:461 | Early stopping at epoch 14 - Val Loss: 0.8708
13121.8s 1274 2025-11-25 19:22:20 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
13178.5s 1275 2025-11-25 19:23:17 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8996, Val Loss: 0.9386, Train Acc: 0.6580, Val Acc: 0.6021
13181.8s 1276 2025-11-25 19:23:20 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9001, Val Loss: 0.9461, Train Acc: 0.6490, Val Acc: 0.6021
13182.1s 1277 2025-11-25 19:23:21 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9047
13235.8s 1278 2025-11-25 19:24:14 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8997, Val Loss: 0.9360, Train Acc: 0.6510, Val Acc: 0.6021
13246.5s 1279 2025-11-25 19:24:25 | INFO | lstm_model:fit:461 | Early stopping at epoch 22 - Val Loss: 0.9371
13246.8s 1280 2025-11-25 19:24:25 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
13246.8s 1281 2025-11-25 19:24:25 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
13251.7s 1282 2025-11-25 19:24:30 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
13326.9s 1283 2025-11-25 19:25:45 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8981, Val Loss: 0.9369, Train Acc: 0.6470, Val Acc: 0.6019
13337.7s 1284 2025-11-25 19:25:56 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9037
13337.9s 1285 2025-11-25 19:25:57 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (29489, 6)
13337.9s 1286 2025-11-25 19:25:57 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
13338.0s 1287 [19:25:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
13338.0s 1288 
13338.0s 1289 E.g. tree_method = "hist", device = "cuda"
13338.0s 1290 
13338.8s 1291 [19:25:57] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
13338.8s 1292 
13338.8s 1293 E.g. tree_method = "hist", device = "cuda"
13338.8s 1294 
13338.8s 1295 2025-11-25 19:25:57 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
13339.6s 1296 [32m[I 2025-11-25 19:25:58,671][0m Trial 2 finished with value: 0.9721776350989834 and parameters: {'learning_rate': 0.010666116981114556, 'max_depth': 7, 'n_estimators': 456, 'subsample': 0.6744931500070732, 'colsample_bytree': 0.6367706873934047, 'min_child_weight': 4, 'gamma': 0.14722294832231952, 'reg_alpha': 0.08410162012392486, 'reg_lambda': 1.3001972949404283}. Best is trial 2 with value: 0.9721776350989834.[0m
13352.0s 1297 Best trial: 3. Best value: 0.965343:  20%|â–| 1/5 [28:53<1:19:53, 1198.48s/it, 11
Best trial: 2. Best value: 0.972178:  20%|â–| 1/5 [28:53<1:19:53, 1198.48s/it, 11
Best trial: 2. Best value: 0.972178:  40%|â–| 2/5 [28:53<40:24, 808.33s/it, 1198.
Best trial: 2. Best value: 0.972178:  40%|â–| 2/5 [28:53<40:24, 808.33s/it, 1733.2025-11-25 19:26:11 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9036
13374.0s 1298 2025-11-25 19:26:33 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9049
13403.1s 1299 2025-11-25 19:27:02 | INFO | lstm_model:fit:461 | Early stopping at epoch 38 - Val Loss: 0.9384
13403.4s 1300 2025-11-25 19:27:02 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
13403.4s 1301 2025-11-25 19:27:02 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
13475.0s 1302 2025-11-25 19:28:14 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9037
13479.3s 1303 2025-11-25 19:28:18 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9039
13573.7s 1304 2025-11-25 19:29:52 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9042
13581.3s 1305 2025-11-25 19:30:00 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
13607.7s 1306 2025-11-25 19:30:26 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9031
13686.1s 1307 2025-11-25 19:31:45 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9035
13743.1s 1308 2025-11-25 19:32:42 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9030
13743.3s 1309 2025-11-25 19:32:42 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (29489, 6)
13743.3s 1310 2025-11-25 19:32:42 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
13743.3s 1311 [19:32:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
13743.3s 1312 
13743.3s 1313 E.g. tree_method = "hist", device = "cuda"
13743.3s 1314 
13744.1s 1315 [19:32:43] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
13744.1s 1316 
13744.1s 1317 E.g. tree_method = "hist", device = "cuda"
13744.1s 1318 
13744.1s 1319 2025-11-25 19:32:43 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
13744.9s 1320 [32m[I 2025-11-25 19:32:43,949][0m Trial 0 finished with value: 0.9435802794621672 and parameters: {'learning_rate': 0.048863931468305435, 'max_depth': 9, 'n_estimators': 355, 'subsample': 0.7990727220811791, 'colsample_bytree': 0.9954821910645036, 'min_child_weight': 4, 'gamma': 0.46399527807043167, 'reg_alpha': 0.053398895203606425, 'reg_lambda': 1.7775019760810113}. Best is trial 2 with value: 0.9721776350989834.[0m
13771.0s 1321 Best trial: 2. Best value: 0.972178:  40%|â–| 2/5 [35:38<40:24, 808.33s/it, 1733.
Best trial: 2. Best value: 0.972178:  40%|â–| 2/5 [35:38<40:24, 808.33s/it, 1733.
Best trial: 2. Best value: 0.972178:  60%|â–Œ| 3/5 [35:38<20:48, 624.29s/it, 1733.
Best trial: 2. Best value: 0.972178:  60%|â–Œ| 3/5 [35:38<20:48, 624.29s/it, 2138.2025-11-25 19:33:10 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9059
13785.4s 1322 2025-11-25 19:33:24 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9021
13785.6s 1323 2025-11-25 19:33:24 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (29489, 6)
13785.6s 1324 2025-11-25 19:33:24 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
13785.6s 1325 [19:33:24] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
13785.6s 1326 
13785.6s 1327 E.g. tree_method = "hist", device = "cuda"
13785.6s 1328 
13786.3s 1329 [19:33:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
13786.3s 1330 
13786.3s 1331 E.g. tree_method = "hist", device = "cuda"
13786.3s 1332 
13786.3s 1333 2025-11-25 19:33:25 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
13786.5s 1334 [32m[I 2025-11-25 19:33:25,595][0m Trial 4 finished with value: 0.9512969825304394 and parameters: {'learning_rate': 0.07113751574994015, 'max_depth': 3, 'n_estimators': 131, 'subsample': 0.7615697721761028, 'colsample_bytree': 0.9996545067283019, 'min_child_weight': 3, 'gamma': 0.01665213419287881, 'reg_alpha': 0.033496019742210136, 'reg_lambda': 0.5737111846810645}. Best is trial 2 with value: 0.9721776350989834.[0m
13837.5s 1335 Best trial: 2. Best value: 0.972178:  60%|â–Œ| 3/5 [36:20<20:48, 624.29s/it, 2138.
Best trial: 2. Best value: 0.972178:  60%|â–Œ| 3/5 [36:20<20:48, 624.29s/it, 2138.
Best trial: 2. Best value: 0.972178:  80%|â–Š| 4/5 [36:20<06:34, 394.27s/it, 2138.
Best trial: 2. Best value: 0.972178:  80%|â–Š| 4/5 [36:20<06:34, 394.27s/it, 2180.2025-11-25 19:34:16 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9051
13896.3s 1336 2025-11-25 19:35:15 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9031
13955.3s 1337 2025-11-25 19:36:14 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9031
14014.5s 1338 2025-11-25 19:37:13 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9042
14014.6s 1339 2025-11-25 19:37:13 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (29489, 6)
14014.6s 1340 2025-11-25 19:37:13 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
14014.6s 1341 [19:37:13] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
14014.6s 1342 
14014.6s 1343 E.g. tree_method = "hist", device = "cuda"
14014.6s 1344 
14015.0s 1345 [19:37:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
14015.0s 1346 
14015.0s 1347 E.g. tree_method = "hist", device = "cuda"
14015.0s 1348 
14015.0s 1349 2025-11-25 19:37:14 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
14015.7s 1350 [32m[I 2025-11-25 19:37:14,761][0m Trial 1 finished with value: 0.9554376657824933 and parameters: {'learning_rate': 0.01006728856901475, 'max_depth': 10, 'n_estimators': 423, 'subsample': 0.8218614445091748, 'colsample_bytree': 0.9445702909232416, 'min_child_weight': 5, 'gamma': 0.10818091239792865, 'reg_alpha': 0.016238519660987584, 'reg_lambda': 1.4774545120629914}. Best is trial 2 with value: 0.9721776350989834.[0m
14015.7s 1351 Best trial: 2. Best value: 0.972178:  80%|â–Š| 4/5 [40:09<06:34, 394.27s/it, 2180.
Best trial: 2. Best value: 0.972178:  80%|â–Š| 4/5 [40:09<06:34, 394.27s/it, 2180.
Best trial: 2. Best value: 0.972178: 100%|â–ˆ| 5/5 [40:09<00:00, 334.73s/it, 2180.
Best trial: 2. Best value: 0.972178: 100%|â–ˆ| 5/5 [40:09<00:00, 334.73s/it, 2409.
Best trial: 2. Best value: 0.972178: 100%|â–ˆ| 5/5 [40:09<00:00, 481.96s/it, 2409.
14015.7s 1352 2025-11-25 19:37:14 | INFO | walk_forward:optimize_hyperparameters:258 | Best trial: 2
14015.7s 1353 2025-11-25 19:37:14 | INFO | walk_forward:optimize_hyperparameters:259 | Best value: 0.9722
14015.7s 1354 2025-11-25 19:37:14 | INFO | walk_forward:optimize_hyperparameters:260 | Best params: {'learning_rate': 0.010666116981114556, 'max_depth': 7, 'n_estimators': 456, 'subsample': 0.6744931500070732, 'colsample_bytree': 0.6367706873934047, 'min_child_weight': 4, 'gamma': 0.14722294832231952, 'reg_alpha': 0.08410162012392486, 'reg_lambda': 1.3001972949404283}
14015.7s 1355 2025-11-25 19:37:14 | INFO | walk_forward:run_walk_forward_optimization:313 | Training model with optimized parameters
14015.7s 1356 2025-11-25 19:37:14 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
14035.3s 1357 2025-11-25 19:37:34 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9126, Val Loss: 0.9001, Train Acc: 0.6570, Val Acc: 0.6607
14040.3s 1358 2025-11-25 19:37:39 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 0.9062
14040.5s 1359 2025-11-25 19:37:39 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
14069.4s 1360 2025-11-25 19:38:08 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.8993, Val Loss: 0.9164, Train Acc: 0.6630, Val Acc: 0.6333
14082.6s 1361 2025-11-25 19:38:21 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8943, Val Loss: 0.9143, Train Acc: 0.6540, Val Acc: 0.6348
14095.8s 1362 2025-11-25 19:38:34 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8928, Val Loss: 0.9126, Train Acc: 0.6710, Val Acc: 0.6338
14103.8s 1363 2025-11-25 19:38:42 | INFO | lstm_model:fit:461 | Early stopping at epoch 36 - Val Loss: 0.9126
14141.6s 1364 2025-11-25 19:39:20 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9031, Val Loss: 0.8927, Train Acc: 0.6660, Val Acc: 0.6622
14161.2s 1365 2025-11-25 19:39:40 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9002, Val Loss: 0.8940, Train Acc: 0.6410, Val Acc: 0.6620
14173.2s 1366 2025-11-25 19:39:52 | INFO | lstm_model:fit:461 | Early stopping at epoch 26 - Val Loss: 0.9001
14219.3s 1367 2025-11-25 19:40:38 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9012, Val Loss: 0.9224, Train Acc: 0.6460, Val Acc: 0.6210
14245.4s 1368 2025-11-25 19:41:04 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8998, Val Loss: 0.9217, Train Acc: 0.6610, Val Acc: 0.6210
14248.1s 1369 2025-11-25 19:41:07 | INFO | lstm_model:fit:461 | Early stopping at epoch 21 - Val Loss: 0.9189
14248.3s 1370 2025-11-25 19:41:07 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
14302.7s 1371 2025-11-25 19:42:01 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9054, Val Loss: 1.0895, Train Acc: 0.6470, Val Acc: 0.4090
14305.9s 1372 2025-11-25 19:42:04 | INFO | lstm_model:fit:461 | Early stopping at epoch 11 - Val Loss: 1.0900
14306.1s 1373 2025-11-25 19:42:05 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
14306.1s 1374 2025-11-25 19:42:05 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
14327.6s 1375 2025-11-25 19:42:26 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
14405.1s 1376 2025-11-25 19:43:44 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9309
14480.4s 1377 2025-11-25 19:44:59 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9296
14555.3s 1378 2025-11-25 19:46:14 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9288
14630.6s 1379 2025-11-25 19:47:29 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9288
14705.6s 1380 2025-11-25 19:48:44 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9281
14706.1s 1381 2025-11-25 19:48:45 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (36861, 6)
14706.1s 1382 2025-11-25 19:48:45 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
14706.1s 1383 /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [19:48:45] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
14706.1s 1384 
14706.1s 1385 E.g. tree_method = "hist", device = "cuda"
14706.1s 1386 
14706.1s 1387 warnings.warn(smsg, UserWarning)
14706.6s 1388 2025-11-25 19:48:45 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
14707.8s 1389 2025-11-25 19:48:46 | INFO | walk_forward:run_walk_forward_optimization:348 | OOS Balanced Accuracy: 0.4917
14707.8s 1390 2025-11-25 19:48:46 | INFO | walk_forward:run_walk_forward_optimization:349 | OOS F1 Score: 0.5243
14707.8s 1391 2025-11-25 19:48:46 | INFO | walk_forward:split:94 | Split 2: Train [2024-10-30 15:00:00 to 2025-06-30 14:55:00], Test [2025-06-30 15:00:00 to 2025-08-29 23:55:00]
14707.8s 1392 2025-11-25 19:48:46 | INFO | walk_forward:run_walk_forward_optimization:291 |
14707.8s 1393 ============================================================
14707.8s 1394 2025-11-25 19:48:46 | INFO | walk_forward:run_walk_forward_optimization:292 | Walk-Forward Fold 2
14707.8s 1395 2025-11-25 19:48:46 | INFO | walk_forward:run_walk_forward_optimization:293 | ============================================================
14707.9s 1396 2025-11-25 19:48:47 | INFO | walk_forward:optimize_hyperparameters:240 | Starting hyperparameter optimization
14707.9s 1397 [32m[I 2025-11-25 19:48:47,008][0m A new study created in memory with name: no-name-9d41bdc5-8a28-44d2-af28-b7cfcc3744a1[0m
14708.0s 1398 0%|                                                     | 0/5 [00:00<?, ?it/s]2025-11-25 19:48:47 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
14708.0s 1399 2025-11-25 19:48:47 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
14708.0s 1400 2025-11-25 19:48:47 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
14708.0s 1401 2025-11-25 19:48:47 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
14736.1s 1402 2025-11-25 19:49:15 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9113, Val Loss: 0.8937, Train Acc: 0.6390, Val Acc: 0.6600
14745.1s 1403 2025-11-25 19:49:24 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9119, Val Loss: 0.8978, Train Acc: 0.6210, Val Acc: 0.6600
14753.0s 1404 2025-11-25 19:49:32 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8976, Val Loss: 0.9062, Train Acc: 0.6450, Val Acc: 0.6625
14759.0s 1405 2025-11-25 19:49:38 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 0.9071
14759.3s 1406 2025-11-25 19:49:38 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
14763.3s 1407 2025-11-25 19:49:42 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9104, Val Loss: 0.9014, Train Acc: 0.6320, Val Acc: 0.6594
14769.3s 1408 2025-11-25 19:49:48 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8875, Val Loss: 0.9297, Train Acc: 0.6560, Val Acc: 0.6622
14776.1s 1409 2025-11-25 19:49:55 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9102, Val Loss: 0.8929, Train Acc: 0.6610, Val Acc: 0.6613
14785.7s 1410 2025-11-25 19:50:04 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8693, Val Loss: 0.9375, Train Acc: 0.6520, Val Acc: 0.6399
14789.3s 1411 2025-11-25 19:50:08 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9013, Val Loss: 0.9109, Train Acc: 0.6640, Val Acc: 0.6602
14790.6s 1412 2025-11-25 19:50:09 | INFO | lstm_model:fit:461 | Early stopping at epoch 43 - Val Loss: 0.9408
14791.0s 1413 2025-11-25 19:50:10 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
14809.0s 1414 2025-11-25 19:50:28 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9002, Val Loss: 0.9250, Train Acc: 0.6380, Val Acc: 0.6228
14814.5s 1415 2025-11-25 19:50:33 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8894, Val Loss: 0.9069, Train Acc: 0.6200, Val Acc: 0.6591
14814.6s 1416 2025-11-25 19:50:33 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8957, Val Loss: 0.9140, Train Acc: 0.6510, Val Acc: 0.6593
14832.4s 1417 2025-11-25 19:50:51 | INFO | lstm_model:fit:461 | Early stopping at epoch 36 - Val Loss: 0.9207
14832.9s 1418 2025-11-25 19:50:51 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
14833.0s 1419 2025-11-25 19:50:52 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9033, Val Loss: 0.9263, Train Acc: 0.6950, Val Acc: 0.6241
14847.7s 1420 2025-11-25 19:51:06 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8998, Val Loss: 0.9240, Train Acc: 0.6270, Val Acc: 0.6248
14849.6s 1421 2025-11-25 19:51:08 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8822, Val Loss: 0.9116, Train Acc: 0.6440, Val Acc: 0.6507
14864.1s 1422 2025-11-25 19:51:23 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8985, Val Loss: 0.9236, Train Acc: 0.6760, Val Acc: 0.6255
14876.9s 1423 2025-11-25 19:51:36 | INFO | lstm_model:fit:461 | Early stopping at epoch 38 - Val Loss: 0.9196
14877.4s 1424 2025-11-25 19:51:36 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
14887.2s 1425 2025-11-25 19:51:46 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8996, Val Loss: 0.9243, Train Acc: 0.6560, Val Acc: 0.6254
14895.5s 1426 2025-11-25 19:51:54 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8976, Val Loss: 0.9275, Train Acc: 0.6640, Val Acc: 0.6251
14911.5s 1427 2025-11-25 19:52:10 | INFO | lstm_model:fit:461 | Early stopping at epoch 35 - Val Loss: 0.9219
14918.8s 1428 2025-11-25 19:52:17 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9018, Val Loss: 0.9242, Train Acc: 0.6570, Val Acc: 0.6275
14923.1s 1429 2025-11-25 19:52:22 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8968, Val Loss: 0.9221, Train Acc: 0.6640, Val Acc: 0.6263
14960.3s 1430 2025-11-25 19:52:59 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.8958, Val Loss: 0.9220, Train Acc: 0.6470, Val Acc: 0.6273
14970.4s 1431 2025-11-25 19:53:09 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9080, Val Loss: 0.9168, Train Acc: 0.6300, Val Acc: 0.6301
14973.9s 1432 2025-11-25 19:53:12 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8983, Val Loss: 0.9231, Train Acc: 0.6330, Val Acc: 0.6275
14986.7s 1433 2025-11-25 19:53:25 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9014, Val Loss: 0.9241, Train Acc: 0.6440, Val Acc: 0.6286
14997.4s 1434 2025-11-25 19:53:36 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.8947, Val Loss: 0.9216, Train Acc: 0.6660, Val Acc: 0.6264
14997.8s 1435 2025-11-25 19:53:36 | INFO | lstm_model:fit:461 | Early stopping at epoch 16 - Val Loss: 0.9148
15024.4s 1436 2025-11-25 19:54:03 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8967, Val Loss: 0.9231, Train Acc: 0.6360, Val Acc: 0.6270
15031.4s 1437 2025-11-25 19:54:10 | INFO | lstm_model:fit:440 | Epoch 70/100 - Loss: 0.8943, Val Loss: 0.9217, Train Acc: 0.6450, Val Acc: 0.6255
15064.4s 1438 2025-11-25 19:54:43 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8986, Val Loss: 0.9242, Train Acc: 0.6560, Val Acc: 0.6225
15068.0s 1439 2025-11-25 19:54:47 | INFO | lstm_model:fit:440 | Epoch 80/100 - Loss: 0.8933, Val Loss: 0.9213, Train Acc: 0.6590, Val Acc: 0.6258
15073.0s 1440 2025-11-25 19:54:52 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9096, Val Loss: 0.9332, Train Acc: 0.6440, Val Acc: 0.5966
15078.9s 1441 2025-11-25 19:54:58 | INFO | lstm_model:fit:461 | Early stopping at epoch 83 - Val Loss: 0.9216
15081.1s 1442 2025-11-25 19:55:00 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8967, Val Loss: 0.9225, Train Acc: 0.6280, Val Acc: 0.6266
15097.1s 1443 2025-11-25 19:55:16 | INFO | lstm_model:fit:461 | Early stopping at epoch 14 - Val Loss: 0.9294
15097.3s 1444 2025-11-25 19:55:16 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
15123.5s 1445 2025-11-25 19:55:42 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.8947, Val Loss: 0.9229, Train Acc: 0.6400, Val Acc: 0.6266
15132.7s 1446 2025-11-25 19:55:51 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8982, Val Loss: 0.9226, Train Acc: 0.6420, Val Acc: 0.6272
15146.5s 1447 2025-11-25 19:56:05 | INFO | lstm_model:fit:461 | Early stopping at epoch 54 - Val Loss: 0.9223
15146.7s 1448 2025-11-25 19:56:05 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9098, Val Loss: 0.9176, Train Acc: 0.6160, Val Acc: 0.6310
15188.8s 1449 2025-11-25 19:56:47 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9129, Val Loss: 1.0880, Train Acc: 0.6270, Val Acc: 0.4122
15196.9s 1450 2025-11-25 19:56:55 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8964, Val Loss: 0.9238, Train Acc: 0.6660, Val Acc: 0.6287
15203.9s 1451 2025-11-25 19:57:02 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9054, Val Loss: 0.9141, Train Acc: 0.6250, Val Acc: 0.6309
15258.8s 1452 2025-11-25 19:57:57 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9048, Val Loss: 0.9153, Train Acc: 0.6410, Val Acc: 0.6304
15262.6s 1453 2025-11-25 19:58:01 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9123, Val Loss: 1.0872, Train Acc: 0.6470, Val Acc: 0.4118
15274.9s 1454 2025-11-25 19:58:14 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9079, Val Loss: 0.9155, Train Acc: 0.6260, Val Acc: 0.6303
15278.1s 1455 2025-11-25 19:58:17 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.8950, Val Loss: 0.9222, Train Acc: 0.6580, Val Acc: 0.6270
15286.6s 1456 2025-11-25 19:58:25 | INFO | lstm_model:fit:461 | Early stopping at epoch 51 - Val Loss: 0.9212
15307.6s 1457 2025-11-25 19:58:46 | INFO | lstm_model:fit:461 | Early stopping at epoch 26 - Val Loss: 1.0925
15308.0s 1458 2025-11-25 19:58:47 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
15308.0s 1459 2025-11-25 19:58:47 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
15313.3s 1460 2025-11-25 19:58:52 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.9046, Val Loss: 0.9144, Train Acc: 0.6540, Val Acc: 0.6306
15321.3s 1461 2025-11-25 19:59:00 | INFO | lstm_model:fit:461 | Early stopping at epoch 42 - Val Loss: 0.9145
15324.7s 1462 2025-11-25 19:59:03 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
15338.9s 1463 2025-11-25 19:59:17 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9060, Val Loss: 0.9142, Train Acc: 0.6380, Val Acc: 0.6309
15412.2s 1464 2025-11-25 20:00:31 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9100, Val Loss: 0.9329, Train Acc: 0.6460, Val Acc: 0.5971
15422.8s 1465 2025-11-25 20:00:41 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9050, Val Loss: 0.9142, Train Acc: 0.6500, Val Acc: 0.6298
15443.5s 1466 2025-11-25 20:01:02 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9129, Val Loss: 0.9153, Train Acc: 0.6360, Val Acc: 0.6303
15483.7s 1467 2025-11-25 20:01:42 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9083, Val Loss: 0.9296, Train Acc: 0.6330, Val Acc: 0.5995
15499.9s 1468 2025-11-25 20:01:59 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9393
15505.1s 1469 2025-11-25 20:02:04 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 0.9298
15505.5s 1470 2025-11-25 20:02:04 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
15506.8s 1471 2025-11-25 20:02:05 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.9039, Val Loss: 0.9146, Train Acc: 0.6640, Val Acc: 0.6304
15506.8s 1472 2025-11-25 20:02:05 | INFO | lstm_model:fit:461 | Early stopping at epoch 40 - Val Loss: 0.9146
15535.3s 1473 2025-11-25 20:02:34 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9064, Val Loss: 0.9152, Train Acc: 0.6140, Val Acc: 0.6310
15619.3s 1474 2025-11-25 20:03:58 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9155, Val Loss: 1.0982, Train Acc: 0.6110, Val Acc: 0.4058
15648.9s 1475 2025-11-25 20:04:27 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9057, Val Loss: 0.9139, Train Acc: 0.6500, Val Acc: 0.6306
15670.8s 1476 2025-11-25 20:04:49 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9092, Val Loss: 0.9354, Train Acc: 0.6210, Val Acc: 0.5977
15675.5s 1477 2025-11-25 20:04:54 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9386
15711.1s 1478 2025-11-25 20:05:29 | INFO | lstm_model:fit:461 | Early stopping at epoch 35 - Val Loss: 0.9188
15711.5s 1479 2025-11-25 20:05:30 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9120, Val Loss: 1.0883, Train Acc: 0.6150, Val Acc: 0.3992
15777.4s 1480 2025-11-25 20:06:36 | INFO | lstm_model:fit:461 | Early stopping at epoch 27 - Val Loss: 1.0886
15777.8s 1481 2025-11-25 20:06:36 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
15777.8s 1482 2025-11-25 20:06:36 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
15782.6s 1483 2025-11-25 20:06:41 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9087, Val Loss: 0.9329, Train Acc: 0.6620, Val Acc: 0.5994
15790.0s 1484 2025-11-25 20:06:49 | INFO | lstm_model:fit:461 | Early stopping at epoch 21 - Val Loss: 0.9312
15790.4s 1485 2025-11-25 20:06:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
15796.5s 1486 2025-11-25 20:06:55 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
15856.7s 1487 2025-11-25 20:07:55 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9389
15880.9s 1488 2025-11-25 20:08:19 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9083, Val Loss: 0.9303, Train Acc: 0.6070, Val Acc: 0.5980
15944.8s 1489 2025-11-25 20:09:23 | INFO | lstm_model:fit:461 | Early stopping at epoch 14 - Val Loss: 0.9315
15945.2s 1490 2025-11-25 20:09:24 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
15985.0s 1491 2025-11-25 20:10:04 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9146, Val Loss: 1.0941, Train Acc: 0.6230, Val Acc: 0.4078
16022.0s 1492 2025-11-25 20:10:41 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9399
16036.4s 1493 2025-11-25 20:10:55 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9371
16126.5s 1494 2025-11-25 20:12:25 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9126, Val Loss: 1.0851, Train Acc: 0.6480, Val Acc: 0.4130
16191.2s 1495 2025-11-25 20:13:30 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9127, Val Loss: 1.0852, Train Acc: 0.6190, Val Acc: 0.4052
16196.8s 1496 2025-11-25 20:13:35 | INFO | lstm_model:fit:461 | Early stopping at epoch 25 - Val Loss: 1.0856
16197.2s 1497 2025-11-25 20:13:36 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
16197.3s 1498 2025-11-25 20:13:36 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
16213.6s 1499 2025-11-25 20:13:52 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9373
16213.9s 1500 2025-11-25 20:13:52 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (39396, 6)
16213.9s 1501 2025-11-25 20:13:52 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
16214.0s 1502 [20:13:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
16214.0s 1503 
16214.0s 1504 E.g. tree_method = "hist", device = "cuda"
16214.0s 1505 
16214.9s 1506 [20:13:53] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
16214.9s 1507 
16214.9s 1508 E.g. tree_method = "hist", device = "cuda"
16214.9s 1509 
16214.9s 1510 2025-11-25 20:13:53 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
16215.4s 1511 [32m[I 2025-11-25 20:13:54,519][0m Trial 0 finished with value: 1.2212449255751014 and parameters: {'learning_rate': 0.0018222102085353562, 'max_depth': 3, 'n_estimators': 323, 'subsample': 0.7612941412078716, 'colsample_bytree': 0.722710265597965, 'min_child_weight': 3, 'gamma': 0.20427542670557375, 'reg_alpha': 0.03721637731535744, 'reg_lambda': 1.5472037321170875}. Best is trial 0 with value: 1.2212449255751014.[0m
16215.5s 1512 0%|                                                     | 0/5 [25:07<?, ?it/s]
Best trial: 0. Best value: 1.22124:   0%|                 | 0/5 [25:07<?, ?it/s]
Best trial: 0. Best value: 1.22124:  20%|â–ˆ    | 1/5 [25:07<1:40:30, 1507.51s/it]
Best trial: 0. Best value: 1.22124:  20%|â–| 1/5 [25:07<1:40:30, 1507.51s/it, 1502025-11-25 20:13:54 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
16232.4s 1513 2025-11-25 20:14:11 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9389
16250.1s 1514 2025-11-25 20:14:29 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
16252.3s 1515 2025-11-25 20:14:31 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9134, Val Loss: 0.8931, Train Acc: 0.6190, Val Acc: 0.6594
16266.1s 1516 2025-11-25 20:14:45 | INFO | lstm_model:fit:461 | Early stopping at epoch 19 - Val Loss: 0.9176
16266.4s 1517 2025-11-25 20:14:45 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
16324.6s 1518 2025-11-25 20:15:43 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9033, Val Loss: 0.9382, Train Acc: 0.6200, Val Acc: 0.6284
16342.8s 1519 2025-11-25 20:16:01 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9122, Val Loss: 1.0891, Train Acc: 0.6460, Val Acc: 0.4058
16354.1s 1520 2025-11-25 20:16:13 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8987, Val Loss: 0.9228, Train Acc: 0.6440, Val Acc: 0.6275
16383.3s 1521 2025-11-25 20:16:42 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8965, Val Loss: 0.9232, Train Acc: 0.6410, Val Acc: 0.6272
16413.4s 1522 2025-11-25 20:17:12 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8953, Val Loss: 0.9236, Train Acc: 0.6430, Val Acc: 0.6275
16425.5s 1523 2025-11-25 20:17:24 | INFO | lstm_model:fit:461 | Early stopping at epoch 44 - Val Loss: 0.9225
16440.3s 1524 2025-11-25 20:17:39 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9381
16504.0s 1525 2025-11-25 20:18:43 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9086, Val Loss: 0.9163, Train Acc: 0.6380, Val Acc: 0.6307
16531.0s 1526 2025-11-25 20:19:10 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9111, Val Loss: 1.0845, Train Acc: 0.6620, Val Acc: 0.4050
16548.2s 1527 2025-11-25 20:19:27 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9054, Val Loss: 0.9226, Train Acc: 0.6200, Val Acc: 0.6312
16561.3s 1528 2025-11-25 20:19:40 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9392
16592.1s 1529 2025-11-25 20:20:11 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9053, Val Loss: 0.9179, Train Acc: 0.6390, Val Acc: 0.6295
16596.4s 1530 2025-11-25 20:20:15 | INFO | lstm_model:fit:461 | Early stopping at epoch 31 - Val Loss: 0.9169
16642.3s 1531 2025-11-25 20:21:01 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9382
16655.2s 1532 2025-11-25 20:21:14 | INFO | lstm_model:fit:461 | Early stopping at epoch 37 - Val Loss: 1.0906
16655.7s 1533 2025-11-25 20:21:14 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
16655.7s 1534 2025-11-25 20:21:14 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
16694.5s 1535 2025-11-25 20:21:53 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9094, Val Loss: 0.9336, Train Acc: 0.6290, Val Acc: 0.5983
16697.5s 1536 2025-11-25 20:21:56 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
16736.0s 1537 2025-11-25 20:22:34 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 0.9307
16736.3s 1538 2025-11-25 20:22:35 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
16850.2s 1539 2025-11-25 20:24:29 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9129, Val Loss: 1.0859, Train Acc: 0.6430, Val Acc: 0.4096
16850.2s 1540 2025-11-25 20:24:29 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9371
16850.5s 1541 2025-11-25 20:24:29 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (39396, 6)
16850.5s 1542 2025-11-25 20:24:29 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
16850.6s 1543 [20:24:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
16850.6s 1544 
16850.6s 1545 E.g. tree_method = "hist", device = "cuda"
16850.6s 1546 
16851.4s 1547 [20:24:30] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
16851.4s 1548 
16851.4s 1549 E.g. tree_method = "hist", device = "cuda"
16851.4s 1550 
16851.4s 1551 2025-11-25 20:24:30 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
16851.9s 1552 [32m[I 2025-11-25 20:24:31,013][0m Trial 1 finished with value: 1.3060173261531258 and parameters: {'learning_rate': 0.004468097268348271, 'max_depth': 5, 'n_estimators': 204, 'subsample': 0.8005158998734186, 'colsample_bytree': 0.9065224094512724, 'min_child_weight': 2, 'gamma': 0.22414773415137468, 'reg_alpha': 0.04810191631064986, 'reg_lambda': 0.6071472040813488}. Best is trial 1 with value: 1.3060173261531258.[0m
16854.9s 1553 Best trial: 0. Best value: 1.22124:  20%|â–| 1/5 [35:44<1:40:30, 1507.51s/it, 150
Best trial: 1. Best value: 1.30602:  20%|â–| 1/5 [35:44<1:40:30, 1507.51s/it, 150
Best trial: 1. Best value: 1.30602:  40%|â–| 2/5 [35:44<49:45, 995.15s/it, 1507.5
Best trial: 1. Best value: 1.30602:  40%|â–| 2/5 [35:44<49:45, 995.15s/it, 2144.02025-11-25 20:24:34 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9379
16898.9s 1554 2025-11-25 20:25:17 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 1.0968
16899.2s 1555 2025-11-25 20:25:18 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
16899.2s 1556 2025-11-25 20:25:18 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
16940.4s 1557 2025-11-25 20:25:59 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
17006.5s 1558 2025-11-25 20:27:05 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9405
17018.8s 1559 2025-11-25 20:27:17 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9375
17087.8s 1560 2025-11-25 20:28:26 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9403
17197.7s 1561 2025-11-25 20:30:16 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9370
17234.5s 1562 2025-11-25 20:30:53 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9386
17293.4s 1563 2025-11-25 20:31:52 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9388
17375.2s 1564 2025-11-25 20:33:14 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9369
17375.4s 1565 2025-11-25 20:33:14 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (39396, 6)
17375.4s 1566 2025-11-25 20:33:14 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
17375.4s 1567 [20:33:14] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
17375.4s 1568 
17375.4s 1569 E.g. tree_method = "hist", device = "cuda"
17375.4s 1570 
17376.2s 1571 [20:33:15] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
17376.2s 1572 
17376.2s 1573 E.g. tree_method = "hist", device = "cuda"
17376.2s 1574 
17376.2s 1575 2025-11-25 20:33:15 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
17377.1s 1576 [32m[I 2025-11-25 20:33:16,216][0m Trial 2 finished with value: 1.455497382198953 and parameters: {'learning_rate': 0.09379961559595208, 'max_depth': 7, 'n_estimators': 448, 'subsample': 0.8878958538650237, 'colsample_bytree': 0.6197406533375355, 'min_child_weight': 3, 'gamma': 0.3294821781030607, 'reg_alpha': 0.04859722427173416, 'reg_lambda': 1.6489764765445436}. Best is trial 2 with value: 1.455497382198953.[0m
17379.1s 1577 Best trial: 1. Best value: 1.30602:  40%|â–| 2/5 [44:29<49:45, 995.15s/it, 2144.0
Best trial: 2. Best value: 1.4555:  40%|â–| 2/5 [44:29<49:45, 995.15s/it, 2144.01
Best trial: 2. Best value: 1.4555:  60%|â–Œ| 3/5 [44:29<26:01, 780.56s/it, 2144.01
Best trial: 2. Best value: 1.4555:  60%|â–Œ| 3/5 [44:29<26:01, 780.56s/it, 2669.212025-11-25 20:33:18 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9378
17471.8s 1578 2025-11-25 20:34:50 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9374
17491.9s 1579 2025-11-25 20:35:11 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9375
17604.5s 1580 2025-11-25 20:37:03 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9380
17604.6s 1581 2025-11-25 20:37:03 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (39396, 6)
17604.6s 1582 2025-11-25 20:37:03 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
17604.6s 1583 [20:37:03] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
17604.6s 1584 
17604.6s 1585 E.g. tree_method = "hist", device = "cuda"
17604.6s 1586 
17605.3s 1587 [20:37:04] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
17605.3s 1588 
17605.3s 1589 E.g. tree_method = "hist", device = "cuda"
17605.3s 1590 
17605.3s 1591 2025-11-25 20:37:04 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
17605.4s 1592 2025-11-25 20:37:04 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9376
17605.7s 1593 [32m[I 2025-11-25 20:37:04,837][0m Trial 4 finished with value: 1.3494751908396947 and parameters: {'learning_rate': 0.00951450126792297, 'max_depth': 9, 'n_estimators': 112, 'subsample': 0.9340546084414358, 'colsample_bytree': 0.8060626849284698, 'min_child_weight': 7, 'gamma': 0.2846998809901052, 'reg_alpha': 0.027504481083768864, 'reg_lambda': 1.7823690700319044}. Best is trial 2 with value: 1.455497382198953.[0m
17683.3s 1594 Best trial: 2. Best value: 1.4555:  60%|â–Œ| 3/5 [48:17<26:01, 780.56s/it, 2669.21
Best trial: 2. Best value: 1.4555:  60%|â–Œ| 3/5 [48:17<26:01, 780.56s/it, 2669.21
Best trial: 2. Best value: 1.4555:  80%|â–Š| 4/5 [48:17<09:22, 562.66s/it, 2669.21
Best trial: 2. Best value: 1.4555:  80%|â–Š| 4/5 [48:17<09:22, 562.66s/it, 2897.832025-11-25 20:38:22 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9373
17683.5s 1595 2025-11-25 20:38:22 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (39396, 6)
17683.5s 1596 2025-11-25 20:38:22 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
17683.5s 1597 [20:38:22] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
17683.5s 1598 
17683.5s 1599 E.g. tree_method = "hist", device = "cuda"
17683.5s 1600 
17684.0s 1601 [20:38:23] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
17684.0s 1602 
17684.0s 1603 E.g. tree_method = "hist", device = "cuda"
17684.0s 1604 
17684.0s 1605 2025-11-25 20:38:23 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
17684.5s 1606 [32m[I 2025-11-25 20:38:23,576][0m Trial 3 finished with value: 1.4199017199017199 and parameters: {'learning_rate': 0.03397859468280142, 'max_depth': 7, 'n_estimators': 330, 'subsample': 0.6714009537363742, 'colsample_bytree': 0.6000632266846898, 'min_child_weight': 1, 'gamma': 0.0055250368506671865, 'reg_alpha': 0.07662945942653254, 'reg_lambda': 0.8247768462656415}. Best is trial 2 with value: 1.455497382198953.[0m
17684.5s 1607 Best trial: 2. Best value: 1.4555:  80%|â–Š| 4/5 [49:36<09:22, 562.66s/it, 2897.83
Best trial: 2. Best value: 1.4555:  80%|â–Š| 4/5 [49:36<09:22, 562.66s/it, 2897.83
Best trial: 2. Best value: 1.4555: 100%|â–ˆ| 5/5 [49:36<00:00, 388.16s/it, 2897.83
Best trial: 2. Best value: 1.4555: 100%|â–ˆ| 5/5 [49:36<00:00, 388.16s/it, 2976.57
Best trial: 2. Best value: 1.4555: 100%|â–ˆ| 5/5 [49:36<00:00, 595.31s/it, 2976.57
17684.5s 1608 2025-11-25 20:38:23 | INFO | walk_forward:optimize_hyperparameters:258 | Best trial: 2
17684.5s 1609 2025-11-25 20:38:23 | INFO | walk_forward:optimize_hyperparameters:259 | Best value: 1.4555
17684.5s 1610 2025-11-25 20:38:23 | INFO | walk_forward:optimize_hyperparameters:260 | Best params: {'learning_rate': 0.09379961559595208, 'max_depth': 7, 'n_estimators': 448, 'subsample': 0.8878958538650237, 'colsample_bytree': 0.6197406533375355, 'min_child_weight': 3, 'gamma': 0.3294821781030607, 'reg_alpha': 0.04859722427173416, 'reg_lambda': 1.6489764765445436}
17684.5s 1611 2025-11-25 20:38:23 | INFO | walk_forward:run_walk_forward_optimization:313 | Training model with optimized parameters
17684.5s 1612 2025-11-25 20:38:23 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
17703.3s 1613 2025-11-25 20:38:42 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9126, Val Loss: 0.9003, Train Acc: 0.6320, Val Acc: 0.6562
17712.7s 1614 2025-11-25 20:38:51 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8976, Val Loss: 0.9372, Train Acc: 0.6620, Val Acc: 0.6527
17715.5s 1615 2025-11-25 20:38:54 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 0.9671
17715.7s 1616 2025-11-25 20:38:54 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
17748.0s 1617 2025-11-25 20:39:27 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9018, Val Loss: 0.8992, Train Acc: 0.6630, Val Acc: 0.6543
17765.9s 1618 2025-11-25 20:39:44 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8991, Val Loss: 0.9005, Train Acc: 0.6320, Val Acc: 0.6543
17765.9s 1619 2025-11-25 20:39:44 | INFO | lstm_model:fit:461 | Early stopping at epoch 20 - Val Loss: 0.9005
17810.0s 1620 2025-11-25 20:40:29 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9019, Val Loss: 0.9622, Train Acc: 0.6490, Val Acc: 0.5557
17812.7s 1621 2025-11-25 20:40:31 | INFO | lstm_model:fit:461 | Early stopping at epoch 11 - Val Loss: 0.9620
17867.6s 1622 2025-11-25 20:41:26 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9147, Val Loss: 1.0767, Train Acc: 0.6360, Val Acc: 0.4284
17902.7s 1623 2025-11-25 20:42:01 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9120, Val Loss: 1.0762, Train Acc: 0.6250, Val Acc: 0.4327
17938.0s 1624 2025-11-25 20:42:37 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9109, Val Loss: 1.0755, Train Acc: 0.6590, Val Acc: 0.4226
17972.9s 1625 2025-11-25 20:43:11 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.9111, Val Loss: 1.0744, Train Acc: 0.6060, Val Acc: 0.4310
18008.1s 1626 2025-11-25 20:43:47 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.9098, Val Loss: 1.0759, Train Acc: 0.6270, Val Acc: 0.4164
18025.5s 1627 2025-11-25 20:44:04 | INFO | lstm_model:fit:461 | Early stopping at epoch 55 - Val Loss: 1.0740
18025.8s 1628 2025-11-25 20:44:04 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
18090.1s 1629 2025-11-25 20:45:09 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9458, Val Loss: 1.0152, Train Acc: 0.6100, Val Acc: 0.5408
18103.0s 1630 2025-11-25 20:45:22 | INFO | lstm_model:fit:461 | Early stopping at epoch 13 - Val Loss: 1.0118
18103.4s 1631 2025-11-25 20:45:22 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
18103.4s 1632 2025-11-25 20:45:22 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
18123.1s 1633 2025-11-25 20:45:42 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
18231.1s 1634 2025-11-25 20:47:30 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9537
18346.9s 1635 2025-11-25 20:49:25 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9540
18458.1s 1636 2025-11-25 20:51:17 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9542
18566.5s 1637 2025-11-25 20:53:05 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9533
18670.0s 1638 2025-11-25 20:54:49 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9527
18670.5s 1639 2025-11-25 20:54:49 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (49245, 6)
18670.5s 1640 2025-11-25 20:54:49 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
18670.6s 1641 /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [20:54:49] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
18670.6s 1642 
18670.6s 1643 E.g. tree_method = "hist", device = "cuda"
18670.6s 1644 
18670.6s 1645 warnings.warn(smsg, UserWarning)
18671.1s 1646 /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [20:54:50] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
18671.1s 1647 
18671.1s 1648 E.g. tree_method = "hist", device = "cuda"
18671.1s 1649 
18671.1s 1650 warnings.warn(smsg, UserWarning)
18671.1s 1651 2025-11-25 20:54:50 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
18672.2s 1652 2025-11-25 20:54:51 | INFO | walk_forward:run_walk_forward_optimization:348 | OOS Balanced Accuracy: 0.4284
18672.2s 1653 2025-11-25 20:54:51 | INFO | walk_forward:run_walk_forward_optimization:349 | OOS F1 Score: 0.6077
18672.3s 1654 2025-11-25 20:54:51 | INFO | walk_forward:split:94 | Split 3: Train [2024-10-30 15:00:00 to 2025-08-29 23:55:00], Test [2025-09-01 00:00:00 to 2025-10-30 14:55:00]
18672.3s 1655 2025-11-25 20:54:51 | INFO | walk_forward:run_walk_forward_optimization:291 |
18672.3s 1656 ============================================================
18672.3s 1657 2025-11-25 20:54:51 | INFO | walk_forward:run_walk_forward_optimization:292 | Walk-Forward Fold 3
18672.3s 1658 2025-11-25 20:54:51 | INFO | walk_forward:run_walk_forward_optimization:293 | ============================================================
18672.4s 1659 2025-11-25 20:54:51 | INFO | walk_forward:optimize_hyperparameters:240 | Starting hyperparameter optimization
18672.4s 1660 [32m[I 2025-11-25 20:54:51,437][0m A new study created in memory with name: no-name-c4c36297-96de-4b06-ab97-2d14f1f87c7f[0m
18672.5s 1661 0%|                                                     | 0/5 [00:00<?, ?it/s]2025-11-25 20:54:51 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
18672.5s 1662 2025-11-25 20:54:51 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
18672.5s 1663 2025-11-25 20:54:51 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
18672.5s 1664 2025-11-25 20:54:51 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
18706.0s 1665 2025-11-25 20:55:24 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9116, Val Loss: 0.9022, Train Acc: 0.6670, Val Acc: 0.6528
18728.6s 1666 2025-11-25 20:55:47 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9037, Val Loss: 0.9018, Train Acc: 0.6550, Val Acc: 0.6556
18744.4s 1667 2025-11-25 20:56:03 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9099, Val Loss: 0.9052, Train Acc: 0.6310, Val Acc: 0.6546
18753.7s 1668 2025-11-25 20:56:12 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8907, Val Loss: 0.9522, Train Acc: 0.6490, Val Acc: 0.6378
18761.3s 1669 2025-11-25 20:56:20 | INFO | lstm_model:fit:461 | Early stopping at epoch 33 - Val Loss: 0.9432
18761.8s 1670 2025-11-25 20:56:20 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
18771.2s 1671 2025-11-25 20:56:30 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9071, Val Loss: 0.9016, Train Acc: 0.6480, Val Acc: 0.6549
18771.8s 1672 2025-11-25 20:56:30 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9122, Val Loss: 0.8996, Train Acc: 0.6300, Val Acc: 0.6550
18789.8s 1673 2025-11-25 20:56:48 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9156, Val Loss: 0.9037, Train Acc: 0.6710, Val Acc: 0.6550
18799.6s 1674 2025-11-25 20:56:58 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8935, Val Loss: 0.9224, Train Acc: 0.6570, Val Acc: 0.6474
18813.1s 1675 2025-11-25 20:57:12 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8978, Val Loss: 0.9300, Train Acc: 0.6610, Val Acc: 0.6457
18816.7s 1676 2025-11-25 20:57:15 | INFO | lstm_model:fit:461 | Early stopping at epoch 36 - Val Loss: 0.9506
18817.2s 1677 2025-11-25 20:57:16 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
18823.0s 1678 2025-11-25 20:57:21 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9056, Val Loss: 0.9013, Train Acc: 0.6730, Val Acc: 0.6539
18840.4s 1679 2025-11-25 20:57:39 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8991, Val Loss: 0.9339, Train Acc: 0.6420, Val Acc: 0.6494
18843.9s 1680 2025-11-25 20:57:43 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8850, Val Loss: 0.9413, Train Acc: 0.6390, Val Acc: 0.6506
18849.8s 1681 2025-11-25 20:57:48 | INFO | lstm_model:fit:461 | Early stopping at epoch 32 - Val Loss: 0.9627
18850.4s 1682 2025-11-25 20:57:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
18855.5s 1683 2025-11-25 20:57:54 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 0.9221
18856.0s 1684 2025-11-25 20:57:55 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
18866.6s 1685 2025-11-25 20:58:05 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8996, Val Loss: 0.8983, Train Acc: 0.6480, Val Acc: 0.6539
18903.8s 1686 2025-11-25 20:58:42 | INFO | lstm_model:fit:461 | Early stopping at epoch 29 - Val Loss: 0.8988
18909.8s 1687 2025-11-25 20:58:48 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9037, Val Loss: 0.8984, Train Acc: 0.6260, Val Acc: 0.6534
18955.4s 1688 2025-11-25 20:59:34 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9014, Val Loss: 0.9024, Train Acc: 0.6500, Val Acc: 0.6537
18992.6s 1689 2025-11-25 21:00:11 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9012, Val Loss: 0.9703, Train Acc: 0.6500, Val Acc: 0.5442
19005.2s 1690 2025-11-25 21:00:24 | INFO | lstm_model:fit:461 | Early stopping at epoch 12 - Val Loss: 0.9696
19008.2s 1691 2025-11-25 21:00:27 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8985, Val Loss: 0.8985, Train Acc: 0.6470, Val Acc: 0.6534
19021.5s 1692 2025-11-25 21:00:40 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9024, Val Loss: 0.8984, Train Acc: 0.6320, Val Acc: 0.6537
19038.2s 1693 2025-11-25 21:00:57 | INFO | lstm_model:fit:461 | Early stopping at epoch 36 - Val Loss: 0.8993
19041.0s 1694 2025-11-25 21:01:00 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9026, Val Loss: 0.9068, Train Acc: 0.6400, Val Acc: 0.6538
19081.0s 1695 2025-11-25 21:01:39 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8987, Val Loss: 0.8990, Train Acc: 0.6450, Val Acc: 0.6535
19109.2s 1696 2025-11-25 21:02:08 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9143, Val Loss: 1.0811, Train Acc: 0.6150, Val Acc: 0.4299
19134.6s 1697 2025-11-25 21:02:33 | INFO | lstm_model:fit:461 | Early stopping at epoch 27 - Val Loss: 0.8997
19136.5s 1698 2025-11-25 21:02:35 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8990, Val Loss: 0.9006, Train Acc: 0.6560, Val Acc: 0.6540
19160.2s 1699 2025-11-25 21:02:59 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 0.8983
19162.4s 1700 2025-11-25 21:03:01 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9028, Val Loss: 0.9694, Train Acc: 0.6310, Val Acc: 0.5443
19169.7s 1701 2025-11-25 21:03:08 | INFO | lstm_model:fit:461 | Early stopping at epoch 11 - Val Loss: 0.9708
19184.6s 1702 2025-11-25 21:03:23 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9130, Val Loss: 1.0864, Train Acc: 0.6270, Val Acc: 0.4314
19244.2s 1703 2025-11-25 21:04:23 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9119, Val Loss: 1.0868, Train Acc: 0.6120, Val Acc: 0.4260
19277.4s 1704 2025-11-25 21:04:56 | INFO | lstm_model:fit:461 | Early stopping at epoch 34 - Val Loss: 1.0830
19277.9s 1705 2025-11-25 21:04:56 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
19330.1s 1706 2025-11-25 21:05:49 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9153, Val Loss: 1.0874, Train Acc: 0.6210, Val Acc: 0.4287
19363.8s 1707 2025-11-25 21:06:22 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9014, Val Loss: 0.9639, Train Acc: 0.6410, Val Acc: 0.5502
19375.4s 1708 2025-11-25 21:06:34 | INFO | lstm_model:fit:461 | Early stopping at epoch 11 - Val Loss: 0.9724
19398.5s 1709 2025-11-25 21:06:57 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9020, Val Loss: 0.9638, Train Acc: 0.6550, Val Acc: 0.5466
19400.4s 1710 2025-11-25 21:06:59 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9483, Val Loss: 1.0097, Train Acc: 0.6160, Val Acc: 0.5595
19431.3s 1711 2025-11-25 21:07:30 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9132, Val Loss: 1.0806, Train Acc: 0.6510, Val Acc: 0.4211
19433.6s 1712 2025-11-25 21:07:32 | INFO | lstm_model:fit:461 | Early stopping at epoch 13 - Val Loss: 0.9655
19441.6s 1713 2025-11-25 21:07:40 | INFO | lstm_model:fit:461 | Early stopping at epoch 21 - Val Loss: 1.0795
19442.2s 1714 2025-11-25 21:07:41 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
19482.4s 1715 2025-11-25 21:08:21 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9464, Val Loss: 1.0091, Train Acc: 0.5740, Val Acc: 0.5591
19510.1s 1716 2025-11-25 21:08:49 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 1.0088
19510.8s 1717 2025-11-25 21:08:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
19510.9s 1718 2025-11-25 21:08:49 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
19532.1s 1719 2025-11-25 21:09:11 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
19625.1s 1720 2025-11-25 21:10:44 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9463, Val Loss: 1.0173, Train Acc: 0.5830, Val Acc: 0.5454
19653.9s 1721 2025-11-25 21:11:12 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9147, Val Loss: 1.0801, Train Acc: 0.6240, Val Acc: 0.4265
19743.8s 1722 2025-11-25 21:12:42 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9452, Val Loss: 1.0084, Train Acc: 0.5720, Val Acc: 0.5591
19750.4s 1723 2025-11-25 21:12:49 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9155, Val Loss: 1.0829, Train Acc: 0.6340, Val Acc: 0.4282
19766.9s 1724 2025-11-25 21:13:05 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9543
19804.7s 1725 2025-11-25 21:13:43 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9127, Val Loss: 1.0917, Train Acc: 0.6190, Val Acc: 0.4304
19861.4s 1726 2025-11-25 21:14:40 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9455, Val Loss: 1.0075, Train Acc: 0.6000, Val Acc: 0.5579
19873.2s 1727 2025-11-25 21:14:52 | INFO | lstm_model:fit:461 | Early stopping at epoch 31 - Val Loss: 1.0109
19873.7s 1728 2025-11-25 21:14:52 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
19873.8s 1729 2025-11-25 21:14:52 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
19926.5s 1730 2025-11-25 21:15:45 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
19929.6s 1731 2025-11-25 21:15:48 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9134, Val Loss: 1.0838, Train Acc: 0.6150, Val Acc: 0.4207
19943.5s 1732 2025-11-25 21:16:02 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9130, Val Loss: 1.0850, Train Acc: 0.6310, Val Acc: 0.4182
19974.1s 1733 2025-11-25 21:16:32 | INFO | lstm_model:fit:461 | Early stopping at epoch 33 - Val Loss: 1.0834
19974.4s 1734 2025-11-25 21:16:33 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
20000.1s 1735 2025-11-25 21:16:59 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9542
20013.1s 1736 2025-11-25 21:17:11 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 1.0819
20013.4s 1737 2025-11-25 21:17:12 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
20212.8s 1738 2025-11-25 21:20:31 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9547
20223.3s 1739 2025-11-25 21:20:42 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9528
20315.1s 1740 2025-11-25 21:22:14 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9479, Val Loss: 1.0059, Train Acc: 0.5790, Val Acc: 0.5557
20378.1s 1741 2025-11-25 21:23:17 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9472, Val Loss: 1.0104, Train Acc: 0.5980, Val Acc: 0.5572
20455.6s 1742 2025-11-25 21:24:34 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9533
20495.2s 1743 2025-11-25 21:25:14 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9538
20501.9s 1744 2025-11-25 21:25:20 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9452, Val Loss: 1.0116, Train Acc: 0.5920, Val Acc: 0.5569
20577.0s 1745 2025-11-25 21:26:35 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 1.0151
20577.4s 1746 2025-11-25 21:26:36 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
20577.4s 1747 2025-11-25 21:26:36 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
20626.3s 1748 2025-11-25 21:27:25 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9462, Val Loss: 1.0071, Train Acc: 0.6030, Val Acc: 0.5556
20689.1s 1749 2025-11-25 21:28:27 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9525
20689.2s 1750 2025-11-25 21:28:28 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (49620, 6)
20689.2s 1751 2025-11-25 21:28:28 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
20689.3s 1752 [21:28:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
20689.3s 1753 
20689.3s 1754 E.g. tree_method = "hist", device = "cuda"
20689.3s 1755 
20690.2s 1756 [21:28:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
20690.2s 1757 
20690.2s 1758 E.g. tree_method = "hist", device = "cuda"
20690.2s 1759 
20690.2s 1760 2025-11-25 21:28:29 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
20690.9s 1761 [32m[I 2025-11-25 21:28:29,991][0m Trial 0 finished with value: 2.148223350253807 and parameters: {'learning_rate': 0.010508165685523718, 'max_depth': 5, 'n_estimators': 182, 'subsample': 0.6337793516847141, 'colsample_bytree': 0.7238129134298208, 'min_child_weight': 5, 'gamma': 0.07571357791891153, 'reg_alpha': 0.07440314419855902, 'reg_lambda': 1.8559871837043076}. Best is trial 0 with value: 2.148223350253807.[0m
20691.1s 1762 0%|                                                     | 0/5 [33:38<?, ?it/s]
Best trial: 0. Best value: 2.14822:   0%|                 | 0/5 [33:38<?, ?it/s]
Best trial: 0. Best value: 2.14822:  20%|â–ˆ    | 1/5 [33:38<2:14:34, 2018.56s/it]
Best trial: 0. Best value: 2.14822:  20%|â–| 1/5 [33:38<2:14:34, 2018.56s/it, 2012025-11-25 21:28:30 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
20696.7s 1763 2025-11-25 21:28:35 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 1.0096
20697.2s 1764 2025-11-25 21:28:36 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
20697.3s 1765 2025-11-25 21:28:36 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
20732.3s 1766 2025-11-25 21:29:11 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
20744.0s 1767 2025-11-25 21:29:23 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9085, Val Loss: 0.9121, Train Acc: 0.6350, Val Acc: 0.6546
20765.1s 1768 2025-11-25 21:29:44 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8944, Val Loss: 0.9144, Train Acc: 0.6540, Val Acc: 0.6478
20765.1s 1769 2025-11-25 21:29:44 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9528
20779.4s 1770 2025-11-25 21:29:58 | INFO | lstm_model:fit:461 | Early stopping at epoch 27 - Val Loss: 0.9217
20779.9s 1771 2025-11-25 21:29:59 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
20791.8s 1772 2025-11-25 21:30:10 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
20853.9s 1773 2025-11-25 21:31:12 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9037, Val Loss: 0.9031, Train Acc: 0.6520, Val Acc: 0.6538
20894.1s 1774 2025-11-25 21:31:53 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9003, Val Loss: 0.8999, Train Acc: 0.6440, Val Acc: 0.6538
20906.0s 1775 2025-11-25 21:32:05 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 0.9001
21000.5s 1776 2025-11-25 21:33:39 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9023, Val Loss: 0.9670, Train Acc: 0.6380, Val Acc: 0.5450
21035.2s 1777 2025-11-25 21:34:14 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9525
21035.9s 1778 2025-11-25 21:34:14 | INFO | lstm_model:fit:461 | Early stopping at epoch 16 - Val Loss: 0.9674
21127.4s 1779 2025-11-25 21:35:46 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9553
21154.7s 1780 2025-11-25 21:36:13 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9147, Val Loss: 1.0799, Train Acc: 0.6270, Val Acc: 0.4271
21232.5s 1781 2025-11-25 21:37:31 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9138, Val Loss: 1.0847, Train Acc: 0.6480, Val Acc: 0.4287
21308.6s 1782 2025-11-25 21:38:47 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9530
21308.8s 1783 2025-11-25 21:38:47 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (49620, 6)
21308.8s 1784 2025-11-25 21:38:47 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
21308.9s 1785 [21:38:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
21308.9s 1786 
21308.9s 1787 E.g. tree_method = "hist", device = "cuda"
21308.9s 1788 
21309.8s 1789 [21:38:48] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
21309.8s 1790 
21309.8s 1791 E.g. tree_method = "hist", device = "cuda"
21309.8s 1792 
21309.8s 1793 2025-11-25 21:38:48 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
21310.1s 1794 2025-11-25 21:38:49 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9125, Val Loss: 1.0793, Train Acc: 0.6220, Val Acc: 0.4254
21310.8s 1795 [32m[I 2025-11-25 21:38:49,932][0m Trial 1 finished with value: 2.118149824032177 and parameters: {'learning_rate': 0.0014635326554529669, 'max_depth': 6, 'n_estimators': 388, 'subsample': 0.7466330655514034, 'colsample_bytree': 0.7242962439601273, 'min_child_weight': 5, 'gamma': 0.2700146880398591, 'reg_alpha': 0.09247309467250119, 'reg_lambda': 1.7576885697370208}. Best is trial 0 with value: 2.148223350253807.[0m
21364.1s 1796 Best trial: 0. Best value: 2.14822:  20%|â–| 1/5 [43:58<2:14:34, 2018.56s/it, 201
Best trial: 0. Best value: 2.14822:  20%|â–| 1/5 [43:58<2:14:34, 2018.56s/it, 201
Best trial: 0. Best value: 2.14822:  40%|â–| 2/5 [43:58<59:47, 1195.84s/it, 2018.
Best trial: 0. Best value: 2.14822:  40%|â–| 2/5 [43:58<59:47, 1195.84s/it, 2638.2025-11-25 21:39:43 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9558
21376.2s 1797 2025-11-25 21:39:55 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.9118, Val Loss: 1.0799, Train Acc: 0.6180, Val Acc: 0.4281
21442.1s 1798 2025-11-25 21:41:01 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.9115, Val Loss: 1.0788, Train Acc: 0.6200, Val Acc: 0.4327
21451.8s 1799 2025-11-25 21:41:10 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9530
21507.2s 1800 2025-11-25 21:42:06 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.9107, Val Loss: 1.0818, Train Acc: 0.6260, Val Acc: 0.4227
21572.2s 1801 2025-11-25 21:43:11 | INFO | lstm_model:fit:440 | Epoch 70/100 - Loss: 0.9105, Val Loss: 1.0803, Train Acc: 0.6570, Val Acc: 0.4237
21604.7s 1802 2025-11-25 21:43:43 | INFO | lstm_model:fit:461 | Early stopping at epoch 75 - Val Loss: 1.0800
21605.1s 1803 2025-11-25 21:43:44 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
21674.4s 1804 2025-11-25 21:44:53 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9534
21721.8s 1805 2025-11-25 21:45:40 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9535
21728.7s 1806 2025-11-25 21:45:47 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9472, Val Loss: 1.0093, Train Acc: 0.5620, Val Acc: 0.5585
21778.3s 1807 2025-11-25 21:46:37 | INFO | lstm_model:fit:461 | Early stopping at epoch 16 - Val Loss: 1.0071
21778.7s 1808 2025-11-25 21:46:37 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
21778.7s 1809 2025-11-25 21:46:37 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
21818.0s 1810 2025-11-25 21:47:16 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
21899.3s 1811 2025-11-25 21:48:38 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9526
22014.1s 1812 2025-11-25 21:50:33 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9546
22078.3s 1813 2025-11-25 21:51:37 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9528
22136.2s 1814 2025-11-25 21:52:35 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9532
22136.3s 1815 2025-11-25 21:52:35 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (49620, 6)
22136.3s 1816 2025-11-25 21:52:35 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
22136.4s 1817 [21:52:35] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
22136.4s 1818 
22136.4s 1819 E.g. tree_method = "hist", device = "cuda"
22136.4s 1820 
22137.2s 1821 [21:52:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
22137.2s 1822 
22137.2s 1823 E.g. tree_method = "hist", device = "cuda"
22137.2s 1824 
22137.2s 1825 2025-11-25 21:52:36 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
22138.8s 1826 [32m[I 2025-11-25 21:52:37,851][0m Trial 3 finished with value: 2.1474245115452932 and parameters: {'learning_rate': 0.06447009867347635, 'max_depth': 10, 'n_estimators': 395, 'subsample': 0.7067545888196191, 'colsample_bytree': 0.8745423469482687, 'min_child_weight': 5, 'gamma': 0.31039192815915806, 'reg_alpha': 0.07501996606832188, 'reg_lambda': 1.0386195878142608}. Best is trial 0 with value: 2.148223350253807.[0m
22193.4s 1827 Best trial: 0. Best value: 2.14822:  40%|â–| 2/5 [57:46<59:47, 1195.84s/it, 2638.
Best trial: 0. Best value: 2.14822:  40%|â–| 2/5 [57:46<59:47, 1195.84s/it, 2638.
Best trial: 0. Best value: 2.14822:  60%|â–Œ| 3/5 [57:46<34:15, 1027.84s/it, 2638.
Best trial: 0. Best value: 2.14822:  60%|â–Œ| 3/5 [57:46<34:15, 1027.84s/it, 3466.2025-11-25 21:53:32 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9540
22291.1s 1828 2025-11-25 21:55:10 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9526
22343.9s 1829 2025-11-25 21:56:02 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9528
22472.7s 1830 2025-11-25 21:58:11 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9532
22472.8s 1831 2025-11-25 21:58:11 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (49620, 6)
22472.8s 1832 2025-11-25 21:58:11 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
22472.9s 1833 [21:58:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
22472.9s 1834 
22472.9s 1835 E.g. tree_method = "hist", device = "cuda"
22472.9s 1836 
22473.5s 1837 [21:58:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
22473.5s 1838 
22473.5s 1839 E.g. tree_method = "hist", device = "cuda"
22473.5s 1840 
22473.5s 1841 2025-11-25 21:58:12 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
22474.6s 1842 [32m[I 2025-11-25 21:58:13,665][0m Trial 2 finished with value: 2.18786944230275 and parameters: {'learning_rate': 0.011816702763273903, 'max_depth': 7, 'n_estimators': 457, 'subsample': 0.6196791037799824, 'colsample_bytree': 0.8676509878366863, 'min_child_weight': 3, 'gamma': 0.22666773270062585, 'reg_alpha': 0.07255263472030558, 'reg_lambda': 0.5816962287501196}. Best is trial 2 with value: 2.18786944230275.[0m
22488.2s 1843 Best trial: 0. Best value: 2.14822:  60%|â–Œ| 3/5 [1:03:22<34:15, 1027.84s/it, 346
Best trial: 2. Best value: 2.18787:  60%|â–Œ| 3/5 [1:03:22<34:15, 1027.84s/it, 346
Best trial: 2. Best value: 2.18787:  80%|â–Š| 4/5 [1:03:22<12:34, 754.64s/it, 3466
Best trial: 2. Best value: 2.18787:  80%|â–Š| 4/5 [1:03:22<12:34, 754.64s/it, 38022025-11-25 21:58:27 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9534
22592.7s 1844 2025-11-25 22:00:11 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9530
22592.8s 1845 2025-11-25 22:00:11 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (49620, 6)
22592.8s 1846 2025-11-25 22:00:11 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
22592.9s 1847 [22:00:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
22592.9s 1848 
22592.9s 1849 E.g. tree_method = "hist", device = "cuda"
22592.9s 1850 
22593.4s 1851 [22:00:12] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
22593.4s 1852 
22593.4s 1853 E.g. tree_method = "hist", device = "cuda"
22593.4s 1854 
22593.4s 1855 2025-11-25 22:00:12 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
22593.9s 1856 [32m[I 2025-11-25 22:00:13,045][0m Trial 4 finished with value: 2.1275844679778113 and parameters: {'learning_rate': 0.002925068013263939, 'max_depth': 5, 'n_estimators': 391, 'subsample': 0.9263048936826358, 'colsample_bytree': 0.9315893007870518, 'min_child_weight': 2, 'gamma': 0.2047865558594798, 'reg_alpha': 0.054834940776696234, 'reg_lambda': 0.8565083631772125}. Best is trial 2 with value: 2.18786944230275.[0m
22593.9s 1857 Best trial: 2. Best value: 2.18787:  80%|â–Š| 4/5 [1:05:21<12:34, 754.64s/it, 3802
Best trial: 2. Best value: 2.18787:  80%|â–Š| 4/5 [1:05:21<12:34, 754.64s/it, 3802
Best trial: 2. Best value: 2.18787: 100%|â–ˆ| 5/5 [1:05:21<00:00, 525.56s/it, 3802
Best trial: 2. Best value: 2.18787: 100%|â–ˆ| 5/5 [1:05:21<00:00, 525.56s/it, 3921
Best trial: 2. Best value: 2.18787: 100%|â–ˆ| 5/5 [1:05:21<00:00, 784.32s/it, 3921
22593.9s 1858 2025-11-25 22:00:13 | INFO | walk_forward:optimize_hyperparameters:258 | Best trial: 2
22593.9s 1859 2025-11-25 22:00:13 | INFO | walk_forward:optimize_hyperparameters:259 | Best value: 2.1879
22593.9s 1860 2025-11-25 22:00:13 | INFO | walk_forward:optimize_hyperparameters:260 | Best params: {'learning_rate': 0.011816702763273903, 'max_depth': 7, 'n_estimators': 457, 'subsample': 0.6196791037799824, 'colsample_bytree': 0.8676509878366863, 'min_child_weight': 3, 'gamma': 0.22666773270062585, 'reg_alpha': 0.07255263472030558, 'reg_lambda': 0.5816962287501196}
22593.9s 1861 2025-11-25 22:00:13 | INFO | walk_forward:run_walk_forward_optimization:313 | Training model with optimized parameters
22594.0s 1862 2025-11-25 22:00:13 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
22626.7s 1863 2025-11-25 22:00:45 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9124, Val Loss: 0.9021, Train Acc: 0.6610, Val Acc: 0.6511
22639.2s 1864 2025-11-25 22:00:58 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9081, Val Loss: 0.8936, Train Acc: 0.6580, Val Acc: 0.6547
22651.7s 1865 2025-11-25 22:01:10 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9011, Val Loss: 0.9026, Train Acc: 0.6440, Val Acc: 0.6567
22664.4s 1866 2025-11-25 22:01:23 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8891, Val Loss: 0.9153, Train Acc: 0.6440, Val Acc: 0.6446
22664.4s 1867 2025-11-25 22:01:23 | INFO | lstm_model:fit:461 | Early stopping at epoch 40 - Val Loss: 0.9153
22664.6s 1868 2025-11-25 22:01:23 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
22713.4s 1869 2025-11-25 22:02:12 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9024, Val Loss: 0.9080, Train Acc: 0.6640, Val Acc: 0.6377
22737.6s 1870 2025-11-25 22:02:36 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.8982, Val Loss: 0.9087, Train Acc: 0.6400, Val Acc: 0.6393
22762.0s 1871 2025-11-25 22:03:01 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8987, Val Loss: 0.9087, Train Acc: 0.6360, Val Acc: 0.6380
22769.2s 1872 2025-11-25 22:03:08 | INFO | lstm_model:fit:461 | Early stopping at epoch 33 - Val Loss: 0.9091
22833.1s 1873 2025-11-25 22:04:12 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9025, Val Loss: 1.0982, Train Acc: 0.6540, Val Acc: 0.4145
22847.3s 1874 2025-11-25 22:04:26 | INFO | lstm_model:fit:461 | Early stopping at epoch 14 - Val Loss: 1.0938
22924.9s 1875 2025-11-25 22:05:43 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9475, Val Loss: 0.9968, Train Acc: 0.6010, Val Acc: 0.5788
22971.2s 1876 2025-11-25 22:06:30 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9461, Val Loss: 1.0044, Train Acc: 0.6080, Val Acc: 0.5773
23004.5s 1877 2025-11-25 22:07:03 | INFO | lstm_model:fit:461 | Early stopping at epoch 27 - Val Loss: 0.9969
23004.6s 1878 2025-11-25 22:07:03 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
23099.7s 1879 2025-11-25 22:08:38 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9547, Val Loss: 0.9112, Train Acc: 0.6000, Val Acc: 0.6546
23158.3s 1880 2025-11-25 22:09:37 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9525, Val Loss: 0.9176, Train Acc: 0.5800, Val Acc: 0.6542
23199.3s 1881 2025-11-25 22:10:18 | INFO | lstm_model:fit:461 | Early stopping at epoch 27 - Val Loss: 0.9066
23199.6s 1882 2025-11-25 22:10:18 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
23199.6s 1883 2025-11-25 22:10:18 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
23232.9s 1884 2025-11-25 22:10:51 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
23369.7s 1885 2025-11-25 22:13:08 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 0.9453
23505.8s 1886 2025-11-25 22:15:24 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 0.9444
23641.1s 1887 2025-11-25 22:17:40 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 0.9431
23775.3s 1888 2025-11-25 22:19:54 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 0.9437
23910.1s 1889 2025-11-25 22:22:09 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 0.9435
23910.7s 1890 2025-11-25 22:22:09 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (62024, 6)
23910.7s 1891 2025-11-25 22:22:09 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
23910.7s 1892 /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [22:22:09] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
23910.7s 1893 
23910.7s 1894 E.g. tree_method = "hist", device = "cuda"
23910.7s 1895 
23910.7s 1896 warnings.warn(smsg, UserWarning)
23911.3s 1897 /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [22:22:10] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
23911.3s 1898 
23911.3s 1899 E.g. tree_method = "hist", device = "cuda"
23911.3s 1900 
23911.3s 1901 warnings.warn(smsg, UserWarning)
23911.3s 1902 2025-11-25 22:22:10 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
23912.4s 1903 2025-11-25 22:22:11 | INFO | walk_forward:run_walk_forward_optimization:348 | OOS Balanced Accuracy: 0.4283
23912.4s 1904 2025-11-25 22:22:11 | INFO | walk_forward:run_walk_forward_optimization:349 | OOS F1 Score: 0.6503
23912.4s 1905 2025-11-25 22:22:11 | INFO | walk_forward:run_walk_forward_optimization:372 |
23912.4s 1906 Completed 3 Walk-Forward folds
23912.4s 1907 2025-11-25 22:22:11 | INFO | walk_forward:aggregate_results:402 |
23912.4s 1908 ============================================================
23912.4s 1909 2025-11-25 22:22:11 | INFO | walk_forward:aggregate_results:403 | Walk-Forward Optimization Summary
23912.4s 1910 2025-11-25 22:22:11 | INFO | walk_forward:aggregate_results:404 | ============================================================
23912.4s 1911 2025-11-25 22:22:11 | INFO | walk_forward:aggregate_results:405 | Total Folds: 3
23912.4s 1912 2025-11-25 22:22:11 | INFO | walk_forward:aggregate_results:406 | Avg Balanced Accuracy: 0.4494 Â± 0.0366
23912.4s 1913 2025-11-25 22:22:11 | INFO | walk_forward:aggregate_results:408 | Avg F1 Score: 0.5941 Â± 0.0641
23912.4s 1914 2025-11-25 22:22:11 | INFO | walk_forward:aggregate_results:410 | ============================================================
23912.4s 1915 2025-11-25 22:22:11 | INFO | main:train_model:445 | WFO summary saved to /kaggle/working/results/USD_CHF_wfo_summary.csv
23912.5s 1916 2025-11-25 22:22:11 | INFO | lstm_model:save_model:609 | LSTM model saved to /kaggle/working/models/USD_CHF_model_lstm_base.pth
23912.5s 1917 2025-11-25 22:22:11 | INFO | hybrid_ensemble:save_model:426 | Hybrid Ensemble saved to /kaggle/working/models/USD_CHF_model_*
23912.5s 1918 2025-11-25 22:22:11 | INFO | main:train_model:462 | Model saved to /kaggle/working/models/USD_CHF_model_*
23912.5s 1919 2025-11-25 22:22:11 | INFO | main:train_model:477 | Feature schema saved to /kaggle/working/models/USD_CHF_feature_schema.json
23912.5s 1920 2025-11-25 22:22:11 | INFO | main:generate_predictions:494 | ============================================================
23912.5s 1921 2025-11-25 22:22:11 | INFO | main:generate_predictions:495 | STEP 5: PREDICTION GENERATION
23912.5s 1922 2025-11-25 22:22:11 | INFO | main:generate_predictions:496 | ============================================================
23912.6s 1923 2025-11-25 22:22:11 | INFO | main:generate_predictions:586 |
23912.6s 1924 Latest Signal (2025-11-25 16:50:00):
23912.6s 1925 2025-11-25 22:22:11 | INFO | main:generate_predictions:587 |   Close: 0.80723
23912.6s 1926 2025-11-25 22:22:11 | INFO | main:generate_predictions:588 |   Signal: HOLD
23912.6s 1927 2025-11-25 22:22:11 | INFO | main:generate_predictions:589 |   Buy Confidence: 24.71%
23912.6s 1928 2025-11-25 22:22:11 | INFO | main:generate_predictions:590 |   Sell Confidence: 21.01%
23912.6s 1929 2025-11-25 22:22:11 | INFO | main:generate_predictions:591 |   Hold Confidence: 54.28%
23912.6s 1930 2025-11-25 22:22:11 | INFO | main:generate_predictions:594 |
23912.6s 1931 Fuzzy Quality Score: 14.0/100
23912.6s 1932 2025-11-25 22:22:11 | INFO | main:generate_predictions:595 |     - Confidence: 8.0/40
23912.6s 1933 2025-11-25 22:22:11 | INFO | main:generate_predictions:596 |     - Trend Alignment: 0.0/25
23912.6s 1934 2025-11-25 22:22:11 | INFO | main:generate_predictions:597 |     - Volatility Regime: 6.0/20
23912.6s 1935 2025-11-25 22:22:11 | INFO | main:generate_predictions:598 |     - Momentum Confirm: 0.0/15
23912.6s 1936 2025-11-25 22:22:11 | INFO | main:generate_predictions:599 |   Position Size: 0% of base
23912.6s 1937 2025-11-25 22:22:11 | INFO | main:generate_predictions:607 |
23912.6s 1938 Signal Quality Summary:
23912.6s 1939 2025-11-25 22:22:11 | INFO | main:generate_predictions:608 |     Total Signals: 7
23912.6s 1940 2025-11-25 22:22:11 | INFO | main:generate_predictions:609 |     High Quality (â‰¥60): 0 (0%)
23912.6s 1941 2025-11-25 22:22:11 | INFO | main:generate_predictions:614 | Predictions saved to /kaggle/working/results/USD_CHF_predictions.csv
23912.6s 1942 2025-11-25 22:22:11 | INFO | main:run_full_pipeline:667 | ============================================================
23912.6s 1943 2025-11-25 22:22:11 | INFO | main:run_full_pipeline:668 | PIPELINE COMPLETED SUCCESSFULLY in 3:25:07.174450
23912.6s 1944 2025-11-25 22:22:11 | INFO | main:run_full_pipeline:669 | ============================================================
23912.6s 1945 2025-11-25 22:22:11 | SUCCESS | main:main:701 | âœ“ USD_CHF training completed successfully
23912.6s 1946 2025-11-25 22:22:11 | INFO | main:main:702 |
23912.6s 1947 Latest USD_CHF Predictions:
23912.6s 1948 2025-11-25 22:22:11 | INFO | main:main:703 |              timestamp    close  ...  quality_momentum  signal
23912.6s 1949 95 2025-11-25 16:30:00  0.80837  ...               4.5    SELL
23912.6s 1950 96 2025-11-25 16:35:00  0.80811  ...               4.5    HOLD
23912.6s 1951 97 2025-11-25 16:40:00  0.80765  ...               0.0    HOLD
23912.6s 1952 98 2025-11-25 16:45:00  0.80739  ...               0.0    HOLD
23912.6s 1953 99 2025-11-25 16:50:00  0.80723  ...               0.0    HOLD
23912.6s 1954 
23912.6s 1955 [5 rows x 13 columns]
23912.6s 1956 2025-11-25 22:22:11 | INFO | main:main:686 |
23912.6s 1957 ================================================================================
23912.6s 1958 2025-11-25 22:22:11 | INFO | main:main:687 | STARTING TRAINING FOR USD_CAD
23912.6s 1959 2025-11-25 22:22:11 | INFO | main:main:688 | ================================================================================
23912.6s 1960 
23912.6s 1961 2025-11-25 22:22:11 | INFO | kaggle_loader:__init__:36 | FX Data Directory: /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data
23912.6s 1962 2025-11-25 22:22:11 | INFO | kaggle_loader:__init__:37 | Macro Events Directory: /kaggle/input/macros-and-ohlc/data/kaggle_dataset/macro_events
23912.6s 1963 2025-11-25 22:22:11 | INFO | news_loader:__init__:38 | Kaggle News Dataset: miguelaenlle/massive-stock-news-analysis-db-for-nlpbacktests
23912.6s 1964 2025-11-25 22:22:11 | INFO | news_loader:__init__:39 | Kaggle News Data Directory: /kaggle/input/massive-stock-news-analysis-db-for-nlpbacktests
23912.6s 1965 2025-11-25 22:22:11 | INFO | main:__init__:98 | Using Kaggle dataset
23912.6s 1966 2025-11-25 22:22:11 | INFO | sentiment_features:__init__:39 | Loading sentiment model: ProsusAI/finbert
23913.4s 1967 2025-11-25 22:22:12 | SUCCESS | sentiment_features:__init__:50 | âœ“ Sentiment model loaded successfully
23913.4s 1968 2025-11-25 22:22:12 | SUCCESS | main:__init__:117 | âœ“ Sentiment features enabled
23913.4s 1969 2025-11-25 22:22:12 | INFO | main:__init__:130 | Pipeline initialized for USD_CAD
23913.4s 1970 2025-11-25 22:22:12 | INFO | main:run_full_pipeline:630 | ============================================================
23913.4s 1971 2025-11-25 22:22:12 | INFO | main:run_full_pipeline:631 | FOREX CLASSIFIER PIPELINE - FULL EXECUTION
23913.4s 1972 2025-11-25 22:22:12 | INFO | main:run_full_pipeline:632 | Currency Pair: USD_CAD
23913.4s 1973 2025-11-25 22:22:12 | INFO | main:run_full_pipeline:633 | ============================================================
23913.4s 1974 2025-11-25 22:22:12 | INFO | main:fetch_data:141 | ============================================================
23913.4s 1975 2025-11-25 22:22:12 | INFO | main:fetch_data:142 | STEP 1: DATA ACQUISITION
23913.4s 1976 2025-11-25 22:22:12 | INFO | main:fetch_data:143 | ============================================================
23913.4s 1977 2025-11-25 22:22:12 | INFO | main:fetch_data:148 | Loading data for USD_CAD from Kaggle dataset
23913.4s 1978 2025-11-25 22:22:12 | INFO | kaggle_loader:load_symbol_data:74 | Loading USDCAD data from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data/USDCAD_M5.parquet
23913.5s 1979 2025-11-25 22:22:12 | INFO | kaggle_loader:load_symbol_data:77 | Loaded 80,000 candles for USDCAD
23913.5s 1980 2025-11-25 22:22:12 | INFO | kaggle_loader:load_symbol_data:78 | Date range: 2024-10-28 18:35:00 to 2025-11-25 17:30:00
23913.5s 1981 2025-11-25 22:22:12 | INFO | main:fetch_data:154 | Loaded 80,000 M5 candles
23913.5s 1982 2025-11-25 22:22:12 | INFO | kaggle_loader:load_symbol_data:74 | Loading USDCAD data from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data/USDCAD_H1.parquet
23913.5s 1983 2025-11-25 22:22:12 | INFO | kaggle_loader:load_symbol_data:77 | Loaded 7,000 candles for USDCAD
23913.5s 1984 2025-11-25 22:22:12 | INFO | kaggle_loader:load_symbol_data:78 | Date range: 2024-10-09 22:00:00 to 2025-11-25 17:00:00
23913.5s 1985 2025-11-25 22:22:12 | INFO | main:fetch_data:163 | Loaded 7,000 H1 candles
23913.5s 1986 2025-11-25 22:22:12 | INFO | kaggle_loader:load_symbol_data:74 | Loading USDCAD data from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/fx_data/USDCAD_H4.parquet
23913.6s 1987 2025-11-25 22:22:12 | INFO | kaggle_loader:load_symbol_data:77 | Loaded 2,000 candles for USDCAD
23913.6s 1988 2025-11-25 22:22:12 | INFO | kaggle_loader:load_symbol_data:78 | Date range: 2024-08-13 16:00:00 to 2025-11-25 16:00:00
23913.6s 1989 2025-11-25 22:22:12 | INFO | main:fetch_data:163 | Loaded 2,000 H4 candles
23913.6s 1990 2025-11-25 22:22:12 | INFO | kaggle_loader:load_macro_events:153 | Loading macro events for USDCAD from /kaggle/input/macros-and-ohlc/data/kaggle_dataset/macro_events/USDCAD_events.parquet
23913.6s 1991 2025-11-25 22:22:12 | INFO | kaggle_loader:load_macro_events:156 | Loaded 84 events for USDCAD
23913.6s 1992 2025-11-25 22:22:12 | INFO | kaggle_loader:load_macro_events:157 | Date range: 2024-10-09 17:29:28.981847 to 2025-10-18 17:29:28.981847
23913.6s 1993 2025-11-25 22:22:12 | SUCCESS | main:fetch_data:171 | âœ“ Loaded 84 macro events
23913.6s 1994 2025-11-25 22:22:12 | WARNING | news_loader:_download_and_unzip_data:53 | News dataset not found at /kaggle/input/massive-stock-news-analysis-db-for-nlpbacktests/analyst_ratings_processed.csv
23913.6s 1995 2025-11-25 22:22:12 | WARNING | news_loader:_download_and_unzip_data:54 | News sentiment features will be disabled. To enable, attach 'massive-stock-news-analysis-db-for-nlpbacktests' as input.
23913.6s 1996 2025-11-25 22:22:12 | INFO | news_loader:load_historical_news:105 | News dataset unavailable - returning empty DataFrame
23913.6s 1997 2025-11-25 22:22:12 | INFO | main:fetch_data:199 | Fetched 80000 primary price bars
23913.6s 1998 2025-11-25 22:22:12 | INFO | main:engineer_features:205 | ============================================================
23913.6s 1999 2025-11-25 22:22:12 | INFO | main:engineer_features:206 | STEP 2: FEATURE ENGINEERING
23913.6s 2000 2025-11-25 22:22:12 | INFO | main:engineer_features:207 | ============================================================
23913.6s 2001 2025-11-25 22:22:12 | INFO | main:engineer_features:213 | Calculating base technical features on primary timeframe...
23913.7s 2002 2025-11-25 22:22:12 | SUCCESS | main:engineer_features:219 | âœ“ Calculated 67 base features.
23913.7s 2003 2025-11-25 22:22:12 | INFO | technical_features:add_multi_timeframe_features:259 | Adding multi-timeframe features and regime classification...
23913.7s 2004 2025-11-25 22:22:12 | INFO | technical_features:add_multi_timeframe_features:263 | Calculating features for H1 timeframe...
23913.8s 2005 2025-11-25 22:22:12 | SUCCESS | technical_features:add_multi_timeframe_features:289 | âœ“ Merged H1 features.
23913.8s 2006 2025-11-25 22:22:12 | INFO | technical_features:add_multi_timeframe_features:263 | Calculating features for H4 timeframe...
23913.8s 2007 2025-11-25 22:22:12 | SUCCESS | technical_features:add_multi_timeframe_features:289 | âœ“ Merged H4 features.
23913.9s 2008 2025-11-25 22:22:12 | INFO | main:engineer_features:276 | Dropped 0 rows with NaNs after feature engineering.
23913.9s 2009 2025-11-25 22:22:12 | INFO | main:engineer_features:278 | âœ“ 86 total features created, 79800 samples ready.
23913.9s 2010 2025-11-25 22:22:12 | INFO | main:create_target:295 | ============================================================
23913.9s 2011 2025-11-25 22:22:12 | INFO | main:create_target:296 | STEP 3: TARGET CREATION
23913.9s 2012 2025-11-25 22:22:12 | INFO | main:create_target:297 | ============================================================
23913.9s 2013 2025-11-25 22:22:12 | INFO | main:create_target:314 | Using pip multiplier for USD_CAD: 10000
23913.9s 2014 2025-11-25 22:22:12 | INFO | main:create_target:325 | Using fixed threshold: 4.0 pips
23913.9s 2015 2025-11-25 22:22:12 | INFO | main:create_target:381 | Target class distribution:
23913.9s 2016 2025-11-25 22:22:12 | INFO | main:create_target:385 |   Buy: 17391 (21.8%)
23913.9s 2017 2025-11-25 22:22:12 | INFO | main:create_target:385 |   Sell: 16813 (21.1%)
23913.9s 2018 2025-11-25 22:22:12 | INFO | main:create_target:385 |   Hold: 45590 (57.1%)
23913.9s 2019 2025-11-25 22:22:12 | INFO | main:train_model:399 | ============================================================
23913.9s 2020 2025-11-25 22:22:12 | INFO | main:train_model:400 | STEP 4: MODEL TRAINING
23913.9s 2021 2025-11-25 22:22:12 | INFO | main:train_model:401 | ============================================================
23913.9s 2022 2025-11-25 22:22:12 | INFO | main:train_model:417 | Using 81 features for training
23913.9s 2023 2025-11-25 22:22:12 | INFO | walk_forward:run_walk_forward_optimization:285 | Starting Walk-Forward Optimization
23913.9s 2024 2025-11-25 22:22:13 | INFO | walk_forward:split:94 | Split 1: Train [2024-10-29 11:20:00 to 2025-04-29 11:15:00], Test [2025-04-29 11:20:00 to 2025-06-27 23:55:00]
23913.9s 2025 2025-11-25 22:22:13 | INFO | walk_forward:run_walk_forward_optimization:291 |
23913.9s 2026 ============================================================
23913.9s 2027 2025-11-25 22:22:13 | INFO | walk_forward:run_walk_forward_optimization:292 | Walk-Forward Fold 1
23913.9s 2028 2025-11-25 22:22:13 | INFO | walk_forward:run_walk_forward_optimization:293 | ============================================================
23914.0s 2029 2025-11-25 22:22:13 | INFO | walk_forward:optimize_hyperparameters:240 | Starting hyperparameter optimization
23914.0s 2030 [32m[I 2025-11-25 22:22:13,059][0m A new study created in memory with name: no-name-a9d5e101-09e8-49a5-8f6b-367cb6f03ae5[0m
23914.0s 2031 0%|                                                     | 0/5 [00:00<?, ?it/s]2025-11-25 22:22:13 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
23914.1s 2032 2025-11-25 22:22:13 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
23914.1s 2033 2025-11-25 22:22:13 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
23914.1s 2034 2025-11-25 22:22:13 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
23932.8s 2035 2025-11-25 22:22:31 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9569, Val Loss: 0.9878, Train Acc: 0.5920, Val Acc: 0.5595
23939.0s 2036 2025-11-25 22:22:38 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9582, Val Loss: 0.9878, Train Acc: 0.5790, Val Acc: 0.5569
23947.0s 2037 2025-11-25 22:22:45 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9377, Val Loss: 1.0052, Train Acc: 0.5830, Val Acc: 0.5639
23956.3s 2038 2025-11-25 22:22:55 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9323, Val Loss: 1.0019, Train Acc: 0.6240, Val Acc: 0.5612
23960.5s 2039 2025-11-25 22:22:59 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9036, Val Loss: 0.9855, Train Acc: 0.6600, Val Acc: 0.5710
23975.0s 2040 2025-11-25 22:23:14 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9108, Val Loss: 0.9829, Train Acc: 0.6350, Val Acc: 0.5667
23975.5s 2041 2025-11-25 22:23:14 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8647, Val Loss: 1.0887, Train Acc: 0.6750, Val Acc: 0.5400
23980.3s 2042 2025-11-25 22:23:19 | INFO | lstm_model:fit:461 | Early stopping at epoch 43 - Val Loss: 1.0301
23980.5s 2043 2025-11-25 22:23:19 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
23987.7s 2044 2025-11-25 22:23:26 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9585, Val Loss: 0.9852, Train Acc: 0.6000, Val Acc: 0.5571
23990.9s 2045 2025-11-25 22:23:30 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8803, Val Loss: 0.9840, Train Acc: 0.6000, Val Acc: 0.5784
23998.7s 2046 2025-11-25 22:23:37 | INFO | lstm_model:fit:461 | Early stopping at epoch 45 - Val Loss: 1.0132
23999.2s 2047 2025-11-25 22:23:38 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
24007.5s 2048 2025-11-25 22:23:46 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9528, Val Loss: 0.9846, Train Acc: 0.5900, Val Acc: 0.5628
24009.3s 2049 2025-11-25 22:23:48 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9307, Val Loss: 1.0031, Train Acc: 0.6210, Val Acc: 0.5491
24010.4s 2050 2025-11-25 22:23:49 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9716, Val Loss: 1.0168, Train Acc: 0.5660, Val Acc: 0.5472
24033.7s 2051 2025-11-25 22:24:12 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.8958, Val Loss: 0.9880, Train Acc: 0.6300, Val Acc: 0.5637
24035.5s 2052 2025-11-25 22:24:14 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9733, Val Loss: 1.0064, Train Acc: 0.5860, Val Acc: 0.5507
24035.7s 2053 2025-11-25 22:24:14 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9691, Val Loss: 1.0034, Train Acc: 0.5660, Val Acc: 0.5505
24041.0s 2054 2025-11-25 22:24:19 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9356, Val Loss: 0.9815, Train Acc: 0.5920, Val Acc: 0.5684
24041.0s 2055 2025-11-25 22:24:19 | INFO | lstm_model:fit:461 | Early stopping at epoch 22 - Val Loss: 1.0335
24055.4s 2056 2025-11-25 22:24:34 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8726, Val Loss: 1.0715, Train Acc: 0.6320, Val Acc: 0.5446
24065.0s 2057 2025-11-25 22:24:44 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9643, Val Loss: 0.9984, Train Acc: 0.5760, Val Acc: 0.5407
24069.5s 2058 2025-11-25 22:24:48 | INFO | lstm_model:fit:461 | Early stopping at epoch 46 - Val Loss: 1.0624
24070.0s 2059 2025-11-25 22:24:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
24071.6s 2060 2025-11-25 22:24:50 | INFO | lstm_model:fit:461 | Early stopping at epoch 22 - Val Loss: 1.0011
24071.6s 2061 2025-11-25 22:24:50 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9027, Val Loss: 0.9846, Train Acc: 0.6120, Val Acc: 0.5729
24083.6s 2062 2025-11-25 22:25:02 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9795, Val Loss: 1.0701, Train Acc: 0.5820, Val Acc: 0.4587
24091.2s 2063 2025-11-25 22:25:10 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8785, Val Loss: 1.0093, Train Acc: 0.6250, Val Acc: 0.5659
24094.9s 2064 2025-11-25 22:25:13 | INFO | lstm_model:fit:461 | Early stopping at epoch 13 - Val Loss: 1.0561
24106.9s 2065 2025-11-25 22:25:25 | INFO | lstm_model:fit:461 | Early stopping at epoch 48 - Val Loss: 1.0840
24107.2s 2066 2025-11-25 22:25:26 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
24124.0s 2067 2025-11-25 22:25:43 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9802, Val Loss: 1.0532, Train Acc: 0.5700, Val Acc: 0.4569
24148.2s 2068 2025-11-25 22:26:07 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9981, Val Loss: 1.0202, Train Acc: 0.5380, Val Acc: 0.5172
24155.7s 2069 2025-11-25 22:26:14 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 1.0551
24176.0s 2070 2025-11-25 22:26:35 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9719, Val Loss: 0.9997, Train Acc: 0.5870, Val Acc: 0.5464
24196.4s 2071 2025-11-25 22:26:55 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9955, Val Loss: 1.0194, Train Acc: 0.5400, Val Acc: 0.5218
24205.9s 2072 2025-11-25 22:27:05 | INFO | lstm_model:fit:461 | Early stopping at epoch 22 - Val Loss: 1.0187
24206.3s 2073 2025-11-25 22:27:05 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
24219.1s 2074 2025-11-25 22:27:18 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9695, Val Loss: 0.9983, Train Acc: 0.5800, Val Acc: 0.5532
24224.3s 2075 2025-11-25 22:27:23 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9991, Val Loss: 1.0181, Train Acc: 0.5360, Val Acc: 0.5230
24251.6s 2076 2025-11-25 22:27:50 | INFO | lstm_model:fit:461 | Early stopping at epoch 27 - Val Loss: 1.0074
24253.1s 2077 2025-11-25 22:27:52 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9736, Val Loss: 1.0004, Train Acc: 0.5700, Val Acc: 0.5470
24274.1s 2078 2025-11-25 22:28:13 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0026, Val Loss: 1.0334, Train Acc: 0.5390, Val Acc: 0.4832
24284.7s 2079 2025-11-25 22:28:23 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9946, Val Loss: 1.0183, Train Acc: 0.5510, Val Acc: 0.5218
24298.6s 2080 2025-11-25 22:28:37 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9675, Val Loss: 1.0118, Train Acc: 0.5870, Val Acc: 0.5491
24303.1s 2081 2025-11-25 22:28:42 | INFO | lstm_model:fit:461 | Early stopping at epoch 21 - Val Loss: 0.9979
24332.9s 2082 2025-11-25 22:29:11 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 1.0004, Val Loss: 1.0311, Train Acc: 0.5320, Val Acc: 0.4879
24345.5s 2083 2025-11-25 22:29:24 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9932, Val Loss: 1.0192, Train Acc: 0.5440, Val Acc: 0.5232
24390.4s 2084 2025-11-25 22:30:09 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9794, Val Loss: 1.0532, Train Acc: 0.5570, Val Acc: 0.4573
24393.0s 2085 2025-11-25 22:30:12 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9995, Val Loss: 1.0323, Train Acc: 0.5450, Val Acc: 0.4842
24406.8s 2086 2025-11-25 22:30:25 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.9905, Val Loss: 1.0173, Train Acc: 0.5160, Val Acc: 0.5240
24417.8s 2087 2025-11-25 22:30:36 | INFO | lstm_model:fit:461 | Early stopping at epoch 14 - Val Loss: 1.0554
24435.6s 2088 2025-11-25 22:30:54 | INFO | lstm_model:fit:461 | Early stopping at epoch 37 - Val Loss: 1.0317
24435.8s 2089 2025-11-25 22:30:54 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
24435.8s 2090 2025-11-25 22:30:54 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
24441.9s 2091 2025-11-25 22:31:00 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
24459.3s 2092 2025-11-25 22:31:18 | INFO | lstm_model:fit:461 | Early stopping at epoch 49 - Val Loss: 1.0215
24459.8s 2093 2025-11-25 22:31:18 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
24464.3s 2094 2025-11-25 22:31:23 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9802, Val Loss: 1.0527, Train Acc: 0.5720, Val Acc: 0.4565
24541.4s 2095 2025-11-25 22:32:40 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9771, Val Loss: 1.0564, Train Acc: 0.5610, Val Acc: 0.4559
24543.8s 2096 2025-11-25 22:32:42 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0018, Val Loss: 1.0304, Train Acc: 0.5520, Val Acc: 0.4836
24585.8s 2097 2025-11-25 22:33:24 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 1.0057
24593.4s 2098 2025-11-25 22:33:32 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9979, Val Loss: 1.0212, Train Acc: 0.5270, Val Acc: 0.5168
24615.3s 2099 2025-11-25 22:33:54 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 1.0001, Val Loss: 1.0338, Train Acc: 0.5530, Val Acc: 0.4858
24629.0s 2100 2025-11-25 22:34:07 | INFO | lstm_model:fit:461 | Early stopping at epoch 29 - Val Loss: 1.0581
24629.8s 2101 2025-11-25 22:34:08 | INFO | lstm_model:fit:461 | Early stopping at epoch 22 - Val Loss: 1.0325
24630.3s 2102 2025-11-25 22:34:09 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
24630.3s 2103 2025-11-25 22:34:09 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
24638.9s 2104 2025-11-25 22:34:17 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
24677.4s 2105 2025-11-25 22:34:56 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9963, Val Loss: 1.0177, Train Acc: 0.5260, Val Acc: 0.5234
24712.0s 2106 2025-11-25 22:35:30 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 1.0177
24712.3s 2107 2025-11-25 22:35:31 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
24724.6s 2108 2025-11-25 22:35:43 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 1.0034
24817.7s 2109 2025-11-25 22:37:16 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 1.0069
24829.8s 2110 2025-11-25 22:37:28 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9976, Val Loss: 1.0178, Train Acc: 0.5380, Val Acc: 0.5224
24863.9s 2111 2025-11-25 22:38:02 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 1.0028
24921.0s 2112 2025-11-25 22:38:59 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0017, Val Loss: 1.0349, Train Acc: 0.5530, Val Acc: 0.4838
24959.6s 2113 2025-11-25 22:39:38 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9957, Val Loss: 1.0174, Train Acc: 0.5200, Val Acc: 0.5242
24986.6s 2114 2025-11-25 22:40:05 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 1.0038
25003.3s 2115 2025-11-25 22:40:22 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 1.0014
25032.7s 2116 2025-11-25 22:40:51 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9992, Val Loss: 1.0324, Train Acc: 0.5410, Val Acc: 0.4895
25089.2s 2117 2025-11-25 22:41:48 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9924, Val Loss: 1.0175, Train Acc: 0.5390, Val Acc: 0.5207
25142.3s 2118 2025-11-25 22:42:41 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 1.0014
25142.3s 2119 2025-11-25 22:42:41 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (29349, 6)
25142.3s 2120 2025-11-25 22:42:41 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
25142.4s 2121 [22:42:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
25142.4s 2122 
25142.4s 2123 E.g. tree_method = "hist", device = "cuda"
25142.4s 2124 
25143.3s 2125 [22:42:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
25143.3s 2126 
25143.3s 2127 E.g. tree_method = "hist", device = "cuda"
25143.3s 2128 
25143.3s 2129 2025-11-25 22:42:42 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
25143.7s 2130 [32m[I 2025-11-25 22:42:42,805][0m Trial 0 finished with value: 1.1535074845905489 and parameters: {'learning_rate': 0.03742930753713157, 'max_depth': 3, 'n_estimators': 140, 'subsample': 0.6918782298468162, 'colsample_bytree': 0.7446960534058342, 'min_child_weight': 2, 'gamma': 0.13312566294266165, 'reg_alpha': 0.07252493562280242, 'reg_lambda': 0.973104399995864}. Best is trial 0 with value: 1.1535074845905489.[0m
25143.8s 2131 0%|                                                     | 0/5 [20:29<?, ?it/s]
Best trial: 0. Best value: 1.15351:   0%|                 | 0/5 [20:29<?, ?it/s]
Best trial: 0. Best value: 1.15351:  20%|â–ˆ    | 1/5 [20:29<1:21:58, 1229.75s/it]
Best trial: 0. Best value: 1.15351:  20%|â–| 1/5 [20:29<1:21:58, 1229.75s/it, 1222025-11-25 22:42:42 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
25144.1s 2132 2025-11-25 22:42:43 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9966, Val Loss: 1.0374, Train Acc: 0.5210, Val Acc: 0.4906
25153.7s 2133 2025-11-25 22:42:52 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 1.0015
25191.6s 2134 2025-11-25 22:43:30 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9575, Val Loss: 0.9927, Train Acc: 0.5750, Val Acc: 0.5589
25202.0s 2135 2025-11-25 22:43:41 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.9905, Val Loss: 1.0162, Train Acc: 0.5140, Val Acc: 0.5203
25204.0s 2136 2025-11-25 22:43:43 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9465, Val Loss: 0.9963, Train Acc: 0.6090, Val Acc: 0.5632
25205.8s 2137 2025-11-25 22:43:44 | INFO | lstm_model:fit:461 | Early stopping at epoch 37 - Val Loss: 1.0364
25206.2s 2138 2025-11-25 22:43:45 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
25206.2s 2139 2025-11-25 22:43:45 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
25217.0s 2140 2025-11-25 22:43:56 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9161, Val Loss: 0.9889, Train Acc: 0.6380, Val Acc: 0.5626
25229.3s 2141 2025-11-25 22:44:08 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.8672, Val Loss: 1.0036, Train Acc: 0.6660, Val Acc: 0.5606
25241.2s 2142 2025-11-25 22:44:20 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.8537, Val Loss: 1.0316, Train Acc: 0.6420, Val Acc: 0.5503
25251.0s 2143 2025-11-25 22:44:30 | INFO | lstm_model:fit:461 | Early stopping at epoch 58 - Val Loss: 1.0592
25251.5s 2144 2025-11-25 22:44:30 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
25276.4s 2145 2025-11-25 22:44:55 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.9891, Val Loss: 1.0172, Train Acc: 0.5380, Val Acc: 0.5195
25292.6s 2146 2025-11-25 22:45:11 | INFO | lstm_model:fit:461 | Early stopping at epoch 53 - Val Loss: 1.0166
25293.0s 2147 2025-11-25 22:45:12 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
25303.6s 2148 2025-11-25 22:45:22 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 1.0013
25309.1s 2149 2025-11-25 22:45:28 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
25319.7s 2150 2025-11-25 22:45:38 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9738, Val Loss: 0.9980, Train Acc: 0.5740, Val Acc: 0.5462
25342.9s 2151 2025-11-25 22:46:01 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9678, Val Loss: 1.0028, Train Acc: 0.5820, Val Acc: 0.5511
25365.9s 2152 2025-11-25 22:46:24 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9672, Val Loss: 1.0062, Train Acc: 0.5770, Val Acc: 0.5511
25382.4s 2153 2025-11-25 22:46:41 | INFO | lstm_model:fit:461 | Early stopping at epoch 37 - Val Loss: 1.0187
25459.5s 2154 2025-11-25 22:47:58 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 1.0014
25459.7s 2155 2025-11-25 22:47:58 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (29349, 6)
25459.7s 2156 2025-11-25 22:47:58 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
25459.8s 2157 [22:47:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
25459.8s 2158 
25459.8s 2159 E.g. tree_method = "hist", device = "cuda"
25459.8s 2160 
25460.5s 2161 [22:47:59] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
25460.5s 2162 
25460.5s 2163 E.g. tree_method = "hist", device = "cuda"
25460.5s 2164 
25460.5s 2165 2025-11-25 22:47:59 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
25460.9s 2166 [32m[I 2025-11-25 22:47:59,986][0m Trial 1 finished with value: 1.1636685343556472 and parameters: {'learning_rate': 0.061366200647151856, 'max_depth': 4, 'n_estimators': 164, 'subsample': 0.7142066925616122, 'colsample_bytree': 0.6789489177849448, 'min_child_weight': 6, 'gamma': 0.25010794419206556, 'reg_alpha': 0.07856848274834953, 'reg_lambda': 0.5712506153948855}. Best is trial 1 with value: 1.1636685343556472.[0m
25462.1s 2167 Best trial: 0. Best value: 1.15351:  20%|â–| 1/5 [25:46<1:21:58, 1229.75s/it, 122
Best trial: 1. Best value: 1.16367:  20%|â–| 1/5 [25:46<1:21:58, 1229.75s/it, 122
Best trial: 1. Best value: 1.16367:  40%|â–| 2/5 [25:46<34:38, 692.94s/it, 1229.7
Best trial: 1. Best value: 1.16367:  40%|â–| 2/5 [25:46<34:38, 692.94s/it, 1546.92025-11-25 22:48:01 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9781, Val Loss: 1.0563, Train Acc: 0.5580, Val Acc: 0.4552
25490.4s 2168 2025-11-25 22:48:29 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9767, Val Loss: 1.0560, Train Acc: 0.5560, Val Acc: 0.4536
25503.9s 2169 2025-11-25 22:48:42 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 1.0058
25509.5s 2170 2025-11-25 22:48:48 | INFO | lstm_model:fit:461 | Early stopping at epoch 27 - Val Loss: 1.0607
25510.3s 2171 2025-11-25 22:48:49 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0016, Val Loss: 1.0413, Train Acc: 0.5360, Val Acc: 0.4887
25571.8s 2172 2025-11-25 22:49:50 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 1.0000, Val Loss: 1.0331, Train Acc: 0.5290, Val Acc: 0.4844
25590.9s 2173 2025-11-25 22:50:09 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9973, Val Loss: 1.0177, Train Acc: 0.5460, Val Acc: 0.5218
25599.5s 2174 2025-11-25 22:50:18 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 1.0323
25599.8s 2175 2025-11-25 22:50:18 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
25599.9s 2176 2025-11-25 22:50:19 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
25624.3s 2177 2025-11-25 22:50:43 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 1.0044
25626.4s 2178 2025-11-25 22:50:45 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9958, Val Loss: 1.0174, Train Acc: 0.5530, Val Acc: 0.5259
25640.4s 2179 2025-11-25 22:50:59 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 1.0179
25640.8s 2180 2025-11-25 22:50:59 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
25707.2s 2181 2025-11-25 22:52:06 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
25712.4s 2182 2025-11-25 22:52:11 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 1.0027
25741.1s 2183 2025-11-25 22:52:40 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0024, Val Loss: 1.0333, Train Acc: 0.5190, Val Acc: 0.4850
25787.9s 2184 2025-11-25 22:53:26 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9992, Val Loss: 1.0316, Train Acc: 0.5340, Val Acc: 0.4842
25801.9s 2185 2025-11-25 22:53:40 | INFO | lstm_model:fit:461 | Early stopping at epoch 23 - Val Loss: 1.0319
25802.2s 2186 2025-11-25 22:53:41 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
25802.2s 2187 2025-11-25 22:53:41 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
25836.6s 2188 2025-11-25 22:54:15 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 1.0021
25848.3s 2189 2025-11-25 22:54:27 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
25893.8s 2190 2025-11-25 22:55:12 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 1.0061
25961.0s 2191 2025-11-25 22:56:19 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 1.0063
25969.0s 2192 2025-11-25 22:56:28 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 1.0018
25969.3s 2193 2025-11-25 22:56:28 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (29349, 6)
25969.3s 2194 2025-11-25 22:56:28 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
25969.4s 2195 [22:56:28] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
25969.4s 2196 
25969.4s 2197 E.g. tree_method = "hist", device = "cuda"
25969.4s 2198 
25970.3s 2199 [22:56:29] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
25970.3s 2200 
25970.3s 2201 E.g. tree_method = "hist", device = "cuda"
25970.3s 2202 
25970.3s 2203 2025-11-25 22:56:29 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
25971.0s 2204 [32m[I 2025-11-25 22:56:30,036][0m Trial 3 finished with value: 1.0903133903133904 and parameters: {'learning_rate': 0.003183999486110766, 'max_depth': 9, 'n_estimators': 298, 'subsample': 0.8649516458769599, 'colsample_bytree': 0.6795504678562506, 'min_child_weight': 7, 'gamma': 0.18241712197487925, 'reg_alpha': 0.03869914215669942, 'reg_lambda': 0.983253602061653}. Best is trial 1 with value: 1.1636685343556472.[0m
26037.4s 2205 Best trial: 1. Best value: 1.16367:  40%|â–| 2/5 [34:16<34:38, 692.94s/it, 1546.9
Best trial: 1. Best value: 1.16367:  40%|â–| 2/5 [34:16<34:38, 692.94s/it, 1546.9
Best trial: 1. Best value: 1.16367:  60%|â–Œ| 3/5 [34:16<20:18, 609.43s/it, 1546.9
Best trial: 1. Best value: 1.16367:  60%|â–Œ| 3/5 [34:16<20:18, 609.43s/it, 2056.92025-11-25 22:57:36 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 1.0028
26048.3s 2206 2025-11-25 22:57:47 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 1.0033
26133.6s 2207 2025-11-25 22:59:12 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 1.0016
26139.3s 2208 2025-11-25 22:59:18 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 1.0020
26218.6s 2209 2025-11-25 23:00:37 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 1.0010
26241.3s 2210 2025-11-25 23:01:00 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 1.0011
26303.1s 2211 2025-11-25 23:02:02 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 1.0013
26303.2s 2212 2025-11-25 23:02:02 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (29349, 6)
26303.2s 2213 2025-11-25 23:02:02 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
26303.3s 2214 [23:02:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
26303.3s 2215 
26303.3s 2216 E.g. tree_method = "hist", device = "cuda"
26303.3s 2217 
26303.9s 2218 [23:02:02] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
26303.9s 2219 
26303.9s 2220 E.g. tree_method = "hist", device = "cuda"
26303.9s 2221 
26303.9s 2222 2025-11-25 23:02:02 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
26304.4s 2223 [32m[I 2025-11-25 23:02:03,515][0m Trial 4 finished with value: 1.1707100591715975 and parameters: {'learning_rate': 0.005035941818783336, 'max_depth': 6, 'n_estimators': 458, 'subsample': 0.9792371155160211, 'colsample_bytree': 0.822795565838663, 'min_child_weight': 1, 'gamma': 0.20658032468713539, 'reg_alpha': 0.014575857538066972, 'reg_lambda': 1.2654601199978237}. Best is trial 4 with value: 1.1707100591715975.[0m
26326.5s 2224 Best trial: 1. Best value: 1.16367:  60%|â–Œ| 3/5 [39:50<20:18, 609.43s/it, 2056.9
Best trial: 4. Best value: 1.17071:  60%|â–Œ| 3/5 [39:50<20:18, 609.43s/it, 2056.9
Best trial: 4. Best value: 1.17071:  80%|â–Š| 4/5 [39:50<08:20, 500.49s/it, 2056.9
Best trial: 4. Best value: 1.17071:  80%|â–Š| 4/5 [39:50<08:20, 500.49s/it, 2390.42025-11-25 23:02:25 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 1.0012
26326.7s 2225 2025-11-25 23:02:25 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (29349, 6)
26326.7s 2226 2025-11-25 23:02:25 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
26326.7s 2227 [23:02:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
26326.7s 2228 
26326.7s 2229 E.g. tree_method = "hist", device = "cuda"
26326.7s 2230 
26327.2s 2231 [23:02:26] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
26327.2s 2232 
26327.2s 2233 E.g. tree_method = "hist", device = "cuda"
26327.2s 2234 
26327.2s 2235 2025-11-25 23:02:26 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
26327.7s 2236 [32m[I 2025-11-25 23:02:26,759][0m Trial 2 finished with value: 1.1687851019804907 and parameters: {'learning_rate': 0.006230782984248543, 'max_depth': 8, 'n_estimators': 439, 'subsample': 0.8186593820590965, 'colsample_bytree': 0.8105973285041911, 'min_child_weight': 3, 'gamma': 0.2798028075405904, 'reg_alpha': 0.08111855733399896, 'reg_lambda': 1.5803961531456723}. Best is trial 4 with value: 1.1707100591715975.[0m
26327.7s 2237 Best trial: 4. Best value: 1.17071:  80%|â–Š| 4/5 [40:13<08:20, 500.49s/it, 2390.4
Best trial: 4. Best value: 1.17071:  80%|â–Š| 4/5 [40:13<08:20, 500.49s/it, 2390.4
Best trial: 4. Best value: 1.17071: 100%|â–ˆ| 5/5 [40:13<00:00, 328.39s/it, 2390.4
Best trial: 4. Best value: 1.17071: 100%|â–ˆ| 5/5 [40:13<00:00, 328.39s/it, 2413.7
Best trial: 4. Best value: 1.17071: 100%|â–ˆ| 5/5 [40:13<00:00, 482.74s/it, 2413.7
26327.7s 2238 2025-11-25 23:02:26 | INFO | walk_forward:optimize_hyperparameters:258 | Best trial: 4
26327.7s 2239 2025-11-25 23:02:26 | INFO | walk_forward:optimize_hyperparameters:259 | Best value: 1.1707
26327.7s 2240 2025-11-25 23:02:26 | INFO | walk_forward:optimize_hyperparameters:260 | Best params: {'learning_rate': 0.005035941818783336, 'max_depth': 6, 'n_estimators': 458, 'subsample': 0.9792371155160211, 'colsample_bytree': 0.822795565838663, 'min_child_weight': 1, 'gamma': 0.20658032468713539, 'reg_alpha': 0.014575857538066972, 'reg_lambda': 1.2654601199978237}
26327.7s 2241 2025-11-25 23:02:26 | INFO | walk_forward:run_walk_forward_optimization:313 | Training model with optimized parameters
26327.7s 2242 2025-11-25 23:02:26 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
26347.5s 2243 2025-11-25 23:02:46 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9677, Val Loss: 1.0153, Train Acc: 0.5870, Val Acc: 0.5649
26354.6s 2244 2025-11-25 23:02:53 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9476, Val Loss: 1.0870, Train Acc: 0.5810, Val Acc: 0.4906
26357.4s 2245 2025-11-25 23:02:56 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 1.0736
26357.7s 2246 2025-11-25 23:02:56 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
26385.8s 2247 2025-11-25 23:03:24 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9775, Val Loss: 1.0324, Train Acc: 0.5490, Val Acc: 0.5045
26399.4s 2248 2025-11-25 23:03:38 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9734, Val Loss: 1.0267, Train Acc: 0.5740, Val Acc: 0.5025
26400.7s 2249 2025-11-25 23:03:39 | INFO | lstm_model:fit:461 | Early stopping at epoch 21 - Val Loss: 1.0279
26437.5s 2250 2025-11-25 23:04:16 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9932, Val Loss: 1.0323, Train Acc: 0.5420, Val Acc: 0.4906
26457.6s 2251 2025-11-25 23:04:36 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9897, Val Loss: 1.0306, Train Acc: 0.5590, Val Acc: 0.4911
26477.8s 2252 2025-11-25 23:04:56 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9891, Val Loss: 1.0301, Train Acc: 0.5620, Val Acc: 0.4874
26498.0s 2253 2025-11-25 23:05:17 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.9871, Val Loss: 1.0299, Train Acc: 0.5430, Val Acc: 0.4897
26502.2s 2254 2025-11-25 23:05:21 | INFO | lstm_model:fit:461 | Early stopping at epoch 42 - Val Loss: 1.0301
26546.7s 2255 2025-11-25 23:06:05 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0019, Val Loss: 1.0337, Train Acc: 0.5260, Val Acc: 0.4968
26573.1s 2256 2025-11-25 23:06:32 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9992, Val Loss: 1.0251, Train Acc: 0.5440, Val Acc: 0.4968
26584.0s 2257 2025-11-25 23:06:42 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 1.0291
26584.2s 2258 2025-11-25 23:06:43 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
26637.9s 2259 2025-11-25 23:07:36 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0069, Val Loss: 1.0729, Train Acc: 0.5070, Val Acc: 0.4443
26664.2s 2260 2025-11-25 23:08:03 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 1.0683
26664.5s 2261 2025-11-25 23:08:03 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
26664.5s 2262 2025-11-25 23:08:03 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
26682.4s 2263 2025-11-25 23:08:21 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
26759.5s 2264 2025-11-25 23:09:38 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 1.0158
26835.9s 2265 2025-11-25 23:10:54 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 1.0137
26912.4s 2266 2025-11-25 23:12:11 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 1.0129
26989.0s 2267 2025-11-25 23:13:28 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 1.0133
27067.3s 2268 2025-11-25 23:14:46 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 1.0128
27067.8s 2269 2025-11-25 23:14:46 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (36686, 6)
27067.8s 2270 2025-11-25 23:14:46 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
27067.9s 2271 /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [23:14:46] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
27067.9s 2272 
27067.9s 2273 E.g. tree_method = "hist", device = "cuda"
27067.9s 2274 
27067.9s 2275 warnings.warn(smsg, UserWarning)
27068.3s 2276 /usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning: [23:14:47] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
27068.3s 2277 
27068.3s 2278 E.g. tree_method = "hist", device = "cuda"
27068.3s 2279 
27068.3s 2280 warnings.warn(smsg, UserWarning)
27068.3s 2281 2025-11-25 23:14:47 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
27069.3s 2282 2025-11-25 23:14:48 | INFO | walk_forward:run_walk_forward_optimization:348 | OOS Balanced Accuracy: 0.4504
27069.3s 2283 2025-11-25 23:14:48 | INFO | walk_forward:run_walk_forward_optimization:349 | OOS F1 Score: 0.5466
27069.3s 2284 2025-11-25 23:14:48 | INFO | walk_forward:split:94 | Split 2: Train [2024-10-29 11:20:00 to 2025-06-27 23:55:00], Test [2025-06-30 00:05:00 to 2025-08-29 11:15:00]
27069.3s 2285 2025-11-25 23:14:48 | INFO | walk_forward:run_walk_forward_optimization:291 |
27069.3s 2286 ============================================================
27069.3s 2287 2025-11-25 23:14:48 | INFO | walk_forward:run_walk_forward_optimization:292 | Walk-Forward Fold 2
27069.3s 2288 2025-11-25 23:14:48 | INFO | walk_forward:run_walk_forward_optimization:293 | ============================================================
27069.4s 2289 2025-11-25 23:14:48 | INFO | walk_forward:optimize_hyperparameters:240 | Starting hyperparameter optimization
27069.4s 2290 [32m[I 2025-11-25 23:14:48,480][0m A new study created in memory with name: no-name-efcad70d-d525-496b-8da9-ac0f4c36ab53[0m
27069.5s 2291 0%|                                                     | 0/5 [00:00<?, ?it/s]2025-11-25 23:14:48 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
27069.5s 2292 2025-11-25 23:14:48 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
27069.5s 2293 2025-11-25 23:14:48 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
27069.5s 2294 2025-11-25 23:14:48 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 1/5
27099.0s 2295 2025-11-25 23:15:17 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9625, Val Loss: 1.0286, Train Acc: 0.5880, Val Acc: 0.5606
27108.8s 2296 2025-11-25 23:15:27 | INFO | lstm_model:fit:461 | Early stopping at epoch 15 - Val Loss: 1.0492
27109.2s 2297 2025-11-25 23:15:28 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
27120.6s 2298 2025-11-25 23:15:39 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9629, Val Loss: 1.0278, Train Acc: 0.5660, Val Acc: 0.5471
27128.0s 2299 2025-11-25 23:15:47 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9650, Val Loss: 1.0160, Train Acc: 0.5560, Val Acc: 0.5588
27128.7s 2300 2025-11-25 23:15:47 | INFO | lstm_model:fit:461 | Early stopping at epoch 14 - Val Loss: 1.0644
27129.2s 2301 2025-11-25 23:15:48 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
27145.5s 2302 2025-11-25 23:16:04 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 1.1585
27145.9s 2303 2025-11-25 23:16:04 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
27153.3s 2304 2025-11-25 23:16:12 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9632, Val Loss: 1.0423, Train Acc: 0.5660, Val Acc: 0.5595
27157.6s 2305 2025-11-25 23:16:16 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9777, Val Loss: 1.0418, Train Acc: 0.5780, Val Acc: 0.4741
27161.3s 2306 2025-11-25 23:16:20 | INFO | lstm_model:fit:461 | Early stopping at epoch 14 - Val Loss: 1.1154
27161.6s 2307 2025-11-25 23:16:20 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 1/5 completed
27180.7s 2308 2025-11-25 23:16:39 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 1.0420
27196.4s 2309 2025-11-25 23:16:55 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9771, Val Loss: 1.0479, Train Acc: 0.5560, Val Acc: 0.4741
27224.6s 2310 2025-11-25 23:17:23 | INFO | lstm_model:fit:461 | Early stopping at epoch 17 - Val Loss: 1.0500
27231.7s 2311 2025-11-25 23:17:30 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9773, Val Loss: 1.0420, Train Acc: 0.5560, Val Acc: 0.4749
27246.6s 2312 2025-11-25 23:17:45 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9981, Val Loss: 1.0295, Train Acc: 0.5720, Val Acc: 0.5073
27272.3s 2313 2025-11-25 23:18:11 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9733, Val Loss: 1.0431, Train Acc: 0.5700, Val Acc: 0.4711
27287.7s 2314 2025-11-25 23:18:26 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 1.0424
27295.1s 2315 2025-11-25 23:18:34 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9967, Val Loss: 1.0281, Train Acc: 0.5460, Val Acc: 0.5057
27301.6s 2316 2025-11-25 23:18:40 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9755, Val Loss: 1.0415, Train Acc: 0.5700, Val Acc: 0.4738
27333.4s 2317 2025-11-25 23:19:12 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9988, Val Loss: 1.0289, Train Acc: 0.5240, Val Acc: 0.5020
27333.7s 2318 2025-11-25 23:19:12 | INFO | lstm_model:fit:461 | Early stopping at epoch 28 - Val Loss: 1.0277
27368.6s 2319 2025-11-25 23:19:47 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9727, Val Loss: 1.0437, Train Acc: 0.5840, Val Acc: 0.4732
27387.1s 2320 2025-11-25 23:20:06 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9950, Val Loss: 1.0276, Train Acc: 0.5500, Val Acc: 0.5043
27409.2s 2321 2025-11-25 23:20:28 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9981, Val Loss: 1.0289, Train Acc: 0.5300, Val Acc: 0.5028
27413.7s 2322 2025-11-25 23:20:32 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0074, Val Loss: 1.0318, Train Acc: 0.5030, Val Acc: 0.4833
27437.0s 2323 2025-11-25 23:20:56 | INFO | lstm_model:fit:461 | Early stopping at epoch 28 - Val Loss: 1.0424
27444.5s 2324 2025-11-25 23:21:03 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 0.9850, Val Loss: 1.0223, Train Acc: 0.5530, Val Acc: 0.5251
27475.6s 2325 2025-11-25 23:21:34 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 1.0040, Val Loss: 1.0340, Train Acc: 0.5370, Val Acc: 0.4784
27496.6s 2326 2025-11-25 23:21:55 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9971, Val Loss: 1.0282, Train Acc: 0.5510, Val Acc: 0.4986
27500.4s 2327 2025-11-25 23:21:59 | INFO | lstm_model:fit:461 | Early stopping at epoch 24 - Val Loss: 1.0347
27500.9s 2328 2025-11-25 23:22:00 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
27502.9s 2329 2025-11-25 23:22:01 | INFO | lstm_model:fit:440 | Epoch 40/100 - Loss: 0.9626, Val Loss: 1.0095, Train Acc: 0.5660, Val Acc: 0.5327
27503.8s 2330 2025-11-25 23:22:02 | INFO | lstm_model:fit:461 | Early stopping at epoch 21 - Val Loss: 1.0292
27549.7s 2331 2025-11-25 23:22:48 | INFO | lstm_model:fit:440 | Epoch 50/100 - Loss: 0.9315, Val Loss: 0.9881, Train Acc: 0.5920, Val Acc: 0.5511
27601.3s 2332 2025-11-25 23:23:40 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0126, Val Loss: 1.0545, Train Acc: 0.5000, Val Acc: 0.4758
27605.4s 2333 2025-11-25 23:23:44 | INFO | lstm_model:fit:440 | Epoch 60/100 - Loss: 0.9075, Val Loss: 0.9598, Train Acc: 0.6070, Val Acc: 0.5655
27624.8s 2334 2025-11-25 23:24:03 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 0.9987, Val Loss: 1.0285, Train Acc: 0.5650, Val Acc: 0.5055
27661.4s 2335 2025-11-25 23:24:40 | INFO | lstm_model:fit:440 | Epoch 70/100 - Loss: 0.8966, Val Loss: 0.9751, Train Acc: 0.6260, Val Acc: 0.5572
27667.9s 2336 2025-11-25 23:24:47 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0058, Val Loss: 1.0337, Train Acc: 0.5130, Val Acc: 0.4813
27677.2s 2337 2025-11-25 23:24:56 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 1.0106, Val Loss: 1.0544, Train Acc: 0.5480, Val Acc: 0.4751
27716.6s 2338 2025-11-25 23:25:35 | INFO | lstm_model:fit:440 | Epoch 80/100 - Loss: 0.8900, Val Loss: 0.9644, Train Acc: 0.6340, Val Acc: 0.5581
27730.1s 2339 2025-11-25 23:25:49 | INFO | lstm_model:fit:461 | Early stopping at epoch 27 - Val Loss: 1.0519
27730.5s 2340 2025-11-25 23:25:49 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
27730.5s 2341 2025-11-25 23:25:49 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
27744.5s 2342 2025-11-25 23:26:03 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 0.9983, Val Loss: 1.0275, Train Acc: 0.5370, Val Acc: 0.5076
27746.4s 2343 2025-11-25 23:26:05 | INFO | lstm_model:fit:461 | Early stopping at epoch 86 - Val Loss: 0.9595
27746.9s 2344 2025-11-25 23:26:05 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
27751.0s 2345 2025-11-25 23:26:10 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 1.0338
27751.5s 2346 2025-11-25 23:26:10 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
27779.6s 2347 2025-11-25 23:26:38 | INFO | lstm_model:fit:461 | Early stopping at epoch 26 - Val Loss: 1.0281
27874.8s 2348 2025-11-25 23:28:13 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0056, Val Loss: 1.0360, Train Acc: 0.5240, Val Acc: 0.4732
27917.0s 2349 2025-11-25 23:28:56 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 1.0183
27947.2s 2350 2025-11-25 23:29:26 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 1.0040, Val Loss: 1.0330, Train Acc: 0.5240, Val Acc: 0.4821
27950.7s 2351 2025-11-25 23:29:29 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0110, Val Loss: 1.0670, Train Acc: 0.5210, Val Acc: 0.4809
28012.5s 2352 2025-11-25 23:30:31 | INFO | lstm_model:fit:461 | Early stopping at epoch 29 - Val Loss: 1.0320
28012.8s 2353 2025-11-25 23:30:31 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
28028.8s 2354 2025-11-25 23:30:47 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0063, Val Loss: 1.0322, Train Acc: 0.5410, Val Acc: 0.4798
28071.1s 2355 2025-11-25 23:31:30 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 1.0093, Val Loss: 1.0530, Train Acc: 0.5140, Val Acc: 0.4752
28071.1s 2356 2025-11-25 23:31:30 | INFO | lstm_model:fit:461 | Early stopping at epoch 20 - Val Loss: 1.0530
28071.5s 2357 2025-11-25 23:31:30 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
28071.5s 2358 2025-11-25 23:31:30 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
28095.4s 2359 2025-11-25 23:31:54 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 1.0163
28116.4s 2360 2025-11-25 23:32:15 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
28126.4s 2361 2025-11-25 23:32:25 | INFO | lstm_model:fit:461 | Early stopping at epoch 18 - Val Loss: 1.0334
28126.8s 2362 2025-11-25 23:32:25 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:155 | OOF prediction on fold 5/5
28153.6s 2363 2025-11-25 23:32:52 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0121, Val Loss: 1.0582, Train Acc: 0.5320, Val Acc: 0.4741
28245.8s 2364 2025-11-25 23:34:24 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 1.0094, Val Loss: 1.0543, Train Acc: 0.5250, Val Acc: 0.4749
28271.8s 2365 2025-11-25 23:34:50 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 1.0152
28318.1s 2366 2025-11-25 23:35:37 | INFO | lstm_model:fit:461 | Early stopping at epoch 28 - Val Loss: 1.0548
28318.5s 2367 2025-11-25 23:35:37 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
28318.5s 2368 2025-11-25 23:35:37 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
28365.8s 2369 2025-11-25 23:36:24 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
28401.1s 2370 2025-11-25 23:36:59 | INFO | lstm_model:fit:440 | Epoch 10/100 - Loss: 1.0113, Val Loss: 1.0540, Train Acc: 0.4760, Val Acc: 0.4764
28433.1s 2371 2025-11-25 23:37:32 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 1.0177
28447.7s 2372 2025-11-25 23:37:46 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 1.0149
28576.8s 2373 2025-11-25 23:39:55 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 1.0176
28604.5s 2374 2025-11-25 23:40:23 | INFO | lstm_model:fit:440 | Epoch 20/100 - Loss: 1.0109, Val Loss: 1.0589, Train Acc: 0.5090, Val Acc: 0.4746
28621.3s 2375 2025-11-25 23:40:40 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 1.0145
28621.3s 2376 2025-11-25 23:40:40 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (39344, 6)
28621.3s 2377 2025-11-25 23:40:40 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
28621.4s 2378 [23:40:40] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
28621.4s 2379 
28621.4s 2380 E.g. tree_method = "hist", device = "cuda"
28621.4s 2381 
28622.3s 2382 [23:40:41] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
28622.3s 2383 
28622.3s 2384 E.g. tree_method = "hist", device = "cuda"
28622.3s 2385 
28622.3s 2386 2025-11-25 23:40:41 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
28622.8s 2387 [32m[I 2025-11-25 23:40:41,933][0m Trial 1 finished with value: 1.4667669927263607 and parameters: {'learning_rate': 0.059954595456281776, 'max_depth': 5, 'n_estimators': 247, 'subsample': 0.7111661972206409, 'colsample_bytree': 0.6456123950320823, 'min_child_weight': 2, 'gamma': 0.04993260189647314, 'reg_alpha': 0.0690136321051009, 'reg_lambda': 1.682200845959178}. Best is trial 1 with value: 1.4667669927263607.[0m
28699.6s 2388 0%|                                                     | 0/5 [25:53<?, ?it/s]
Best trial: 1. Best value: 1.46677:   0%|                 | 0/5 [25:53<?, ?it/s]
Best trial: 1. Best value: 1.46677:  20%|â–ˆ    | 1/5 [25:53<1:43:33, 1553.45s/it]
Best trial: 1. Best value: 1.46677:  20%|â–| 1/5 [25:53<1:43:33, 1553.45s/it, 1552025-11-25 23:41:58 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 1.0173
28732.4s 2389 2025-11-25 23:42:31 | INFO | lstm_model:fit:440 | Epoch 30/100 - Loss: 1.0084, Val Loss: 1.0548, Train Acc: 0.5420, Val Acc: 0.4769
28734.6s 2390 2025-11-25 23:42:33 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 1.0156
28780.7s 2391 2025-11-25 23:43:19 | INFO | lstm_model:fit:461 | Early stopping at epoch 34 - Val Loss: 1.0529
28781.0s 2392 2025-11-25 23:43:20 | INFO | hybrid_ensemble:generate_out_of_fold_predictions:203 | Fold 5/5 completed
28781.0s 2393 2025-11-25 23:43:20 | INFO | hybrid_ensemble:fit:256 | Training XGBoost base learner on full dataset
28868.8s 2394 2025-11-25 23:44:47 | INFO | hybrid_ensemble:fit:269 | Training LSTM base learner on full dataset
28870.6s 2395 2025-11-25 23:44:49 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 1.0149
28871.7s 2396 2025-11-25 23:44:50 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 1.0155
29014.3s 2397 2025-11-25 23:47:13 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 1.0157
29047.8s 2398 2025-11-25 23:47:46 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 1.0150
29156.5s 2399 2025-11-25 23:49:35 | INFO | lstm_model:fit:466 | Epoch 20/100 - Loss: 1.0178
29156.8s 2400 2025-11-25 23:49:35 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 1.0145
29157.1s 2401 2025-11-25 23:49:36 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (39344, 6)
29157.1s 2402 2025-11-25 23:49:36 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
29157.1s 2403 [23:49:36] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
29157.1s 2404 
29157.1s 2405 E.g. tree_method = "hist", device = "cuda"
29157.1s 2406 
29157.9s 2407 [23:49:37] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
29157.9s 2408 
29157.9s 2409 E.g. tree_method = "hist", device = "cuda"
29157.9s 2410 
29157.9s 2411 2025-11-25 23:49:37 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
29158.5s 2412 [32m[I 2025-11-25 23:49:37,579][0m Trial 2 finished with value: 1.5302289683560586 and parameters: {'learning_rate': 0.0011781457933177028, 'max_depth': 8, 'n_estimators': 148, 'subsample': 0.7757310144645975, 'colsample_bytree': 0.956512815526775, 'min_child_weight': 5, 'gamma': 0.16817196255817612, 'reg_alpha': 0.07526097992701303, 'reg_lambda': 1.570113151519214}. Best is trial 2 with value: 1.5302289683560586.[0m
29200.1s 2413 Best trial: 1. Best value: 1.46677:  20%|â–| 1/5 [34:49<1:43:33, 1553.45s/it, 155
Best trial: 2. Best value: 1.53023:  20%|â–| 1/5 [34:49<1:43:33, 1553.45s/it, 155
Best trial: 2. Best value: 1.53023:  40%|â–| 2/5 [34:49<47:44, 954.74s/it, 1553.4
Best trial: 2. Best value: 1.53023:  40%|â–| 2/5 [34:49<47:44, 954.74s/it, 2089.12025-11-25 23:50:18 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 1.0157
29200.2s 2414 2025-11-25 23:50:19 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (39344, 6)
29200.2s 2415 2025-11-25 23:50:19 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
29200.2s 2416 [23:50:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
29200.2s 2417 
29200.2s 2418 E.g. tree_method = "hist", device = "cuda"
29200.2s 2419 
29200.9s 2420 [23:50:19] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
29200.9s 2421 
29200.9s 2422 E.g. tree_method = "hist", device = "cuda"
29200.9s 2423 
29200.9s 2424 2025-11-25 23:50:19 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
29201.5s 2425 [32m[I 2025-11-25 23:50:20,636][0m Trial 0 finished with value: 1.4748364368394564 and parameters: {'learning_rate': 0.04299989427617876, 'max_depth': 7, 'n_estimators': 376, 'subsample': 0.9531735193466098, 'colsample_bytree': 0.6311681427606524, 'min_child_weight': 6, 'gamma': 0.4730663845063222, 'reg_alpha': 0.01007184354774231, 'reg_lambda': 1.6014677396646997}. Best is trial 2 with value: 1.5302289683560586.[0m
29253.8s 2426 Best trial: 2. Best value: 1.53023:  40%|â–| 2/5 [35:32<47:44, 954.74s/it, 2089.1
Best trial: 2. Best value: 1.53023:  40%|â–| 2/5 [35:32<47:44, 954.74s/it, 2089.1
Best trial: 2. Best value: 1.53023:  60%|â–Œ| 3/5 [35:32<17:56, 538.45s/it, 2089.1
Best trial: 2. Best value: 1.53023:  60%|â–Œ| 3/5 [35:32<17:56, 538.45s/it, 2132.12025-11-25 23:51:12 | INFO | lstm_model:fit:466 | Epoch 40/100 - Loss: 1.0155
29331.3s 2427 2025-11-25 23:52:30 | INFO | lstm_model:fit:466 | Epoch 60/100 - Loss: 1.0152
29408.7s 2428 2025-11-25 23:53:47 | INFO | lstm_model:fit:466 | Epoch 80/100 - Loss: 1.0144
29486.3s 2429 2025-11-25 23:55:05 | INFO | lstm_model:fit:466 | Epoch 100/100 - Loss: 1.0151
29486.4s 2430 2025-11-25 23:55:05 | INFO | hybrid_ensemble:fit:285 | Meta-features shape: (39344, 6)
29486.4s 2431 2025-11-25 23:55:05 | INFO | hybrid_ensemble:fit:288 | Training XGBoost meta-classifier
29486.4s 2432 [23:55:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
29486.4s 2433 
29486.4s 2434 E.g. tree_method = "hist", device = "cuda"
29486.4s 2435 
29486.9s 2436 [23:55:05] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.
29486.9s 2437 
29486.9s 2438 E.g. tree_method = "hist", device = "cuda"
29486.9s 2439 
29486.9s 2440 2025-11-25 23:55:05 | INFO | hybrid_ensemble:fit:320 | Hybrid Ensemble training completed
29487.5s 2441 [32m[I 2025-11-25 23:55:06,516][0m Trial 3 finished with value: 1.5678851174934725 and parameters: {'learning_rate': 0.0015580830798230675, 'max_depth': 8, 'n_estimators': 282, 'subsample': 0.7736465234049984, 'colsample_bytree': 0.956872517928899, 'min_child_weight': 2, 'gamma': 0.3382425269754378, 'reg_alpha': 0.037327568939893245, 'reg_lambda': 1.6637756711316631}. Best is trial 3 with value: 1.5678851174934725.[0m
29487.5s 2442 Best trial: 2. Best value: 1.53023:  60%|â–Œ| 3/5 [40:18<17:56, 538.45s/it, 2132.1
Best trial: 3. Best value: 1.56789:  60%|â–Œ| 3/5 [40:18<17:56, 538.45s/it, 2132.1
Best trial: 3. Best value: 1.56789:  80%|â–Š| 4/5 [40:18<07:18, 438.74s/it, 2132.1
Best trial: 3. Best value: 1.56789:  80%|â–Š| 4/5 [40:18<07:18, 438.74s/it, 2418.0
Best trial: 3. Best value: 1.56789:  80%|â–Š| 4/5 [40:18<10:04, 604.51s/it, 2418.0
29487.5s 2443 2025-11-25 23:55:06 | ERROR | main:run_full_pipeline:674 | Pipeline failed: DataLoader worker (pid 2850) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
29487.5s 2444 2025-11-25 23:55:06 | ERROR | main:main:706 | âœ— USD_CAD training failed: DataLoader worker (pid 2850) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
29487.5s 2445 2025-11-25 23:55:06 | INFO | main:main:710 |
29487.5s 2446 ================================================================================
29487.5s 2447 2025-11-25 23:55:06 | INFO | main:main:711 | TRAINING SUMMARY
29487.5s 2448 2025-11-25 23:55:06 | INFO | main:main:712 | ================================================================================
29487.5s 2449 2025-11-25 23:55:06 | INFO | main:main:718 | Successful: 2/3 pairs
29487.5s 2450 2025-11-25 23:55:06 | INFO | main:main:720 |   - XAU_USD, USD_CHF
29487.5s 2451 2025-11-25 23:55:06 | WARNING | main:main:723 | Failed: 1 pairs
29487.5s 2452 2025-11-25 23:55:06 | WARNING | main:main:724 |   - USD_CAD
29487.5s 2453 2025-11-25 23:55:06 | INFO | main:main:728 |
29487.5s 2454 ================================================================================
29487.5s 2455 2025-11-25 23:55:06 | INFO | main:main:729 | GENERATING PORTFOLIO-LEVEL SIGNALS
29487.5s 2456 2025-11-25 23:55:06 | INFO | main:main:730 | ================================================================================
29487.5s 2457 
29487.5s 2458 2025-11-25 23:55:06 | INFO | portfolio_ensemble:add_pair_prediction:42 | Added predictions for XAU_USD (100 samples)
29487.5s 2459 2025-11-25 23:55:06 | INFO | portfolio_ensemble:add_pair_prediction:42 | Added predictions for USD_CHF (100 samples)
29487.6s 2460 2025-11-25 23:55:06 | INFO | portfolio_ensemble:get_aggregate_signals:74 | Generated 100 portfolio signals
29487.6s 2461 2025-11-25 23:55:06 | INFO | portfolio_ensemble:save_portfolio_signals:307 | Portfolio signals saved to /kaggle/working/results/portfolio_signals.csv
29487.6s 2462 2025-11-25 23:55:06 | INFO | main:main:755 |
29487.6s 2463 Portfolio Statistics:
29487.6s 2464 2025-11-25 23:55:06 | INFO | portfolio_ensemble:get_portfolio_statistics:287 | Portfolio Stats - Buy: 0.0%, Sell: 0.0%, Hold: 100.0%
29487.6s 2465 2025-11-25 23:55:06 | INFO | portfolio_ensemble:get_portfolio_statistics:289 | Avg Confidence: nan, Avg Active Pairs: 1.2
29487.6s 2466 2025-11-25 23:55:06 | INFO | main:main:757 |   Total Signals: 100
29487.6s 2467 2025-11-25 23:55:06 | INFO | main:main:758 |   Buy: 0.0%
29487.6s 2468 2025-11-25 23:55:06 | INFO | main:main:759 |   Sell: 0.0%
29487.6s 2469 2025-11-25 23:55:06 | INFO | main:main:760 |   Hold: 100.0%
29487.6s 2470 2025-11-25 23:55:06 | INFO | main:main:761 |   Avg Confidence: nan
29487.6s 2471 2025-11-25 23:55:06 | INFO | main:main:764 |
29487.6s 2472 Currency Pair Correlation Matrix:
29487.7s 2473 2025-11-25 23:55:06 | INFO | portfolio_ensemble:get_correlation_matrix:253 | Calculated pair correlation matrix
29487.7s 2474 2025-11-25 23:55:06 | INFO | main:main:766 |
29487.7s 2475 XAU_USD   USD_CHF
29487.7s 2476 XAU_USD  1.000000  0.073726
29487.7s 2477 USD_CHF  0.073726  1.000000
29487.7s 2478 2025-11-25 23:55:06 | SUCCESS | main:main:768 |
29487.7s 2479 âœ“ Portfolio signals saved to: /kaggle/working/results/portfolio_signals.csv
29487.7s 2480 2025-11-25 23:55:06 | INFO | main:main:770 |
29487.7s 2481 Latest Portfolio Signals:
29487.7s 2482 2025-11-25 23:55:06 | INFO | main:main:771 |              timestamp  ...  num_active_pairs
29487.7s 2483 90 2025-11-25 16:05:00  ...                 1
29487.7s 2484 91 2025-11-25 16:10:00  ...                 2
29487.7s 2485 92 2025-11-25 16:15:00  ...                 2
29487.7s 2486 93 2025-11-25 16:20:00  ...                 2
29487.7s 2487 94 2025-11-25 16:25:00  ...                 2
29487.7s 2488 95 2025-11-25 16:30:00  ...                 1
29487.7s 2489 96 2025-11-25 16:35:00  ...                 1
29487.7s 2490 97 2025-11-25 16:40:00  ...                 1
29487.7s 2491 98 2025-11-25 16:45:00  ...                 1
29487.7s 2492 99 2025-11-25 16:50:00  ...                 1
29487.7s 2493 
29487.7s 2494 [10 rows x 11 columns]
29496.1s 2495 /usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py:2915: FutureWarning: --Exporter.preprocessors=["remove_papermill_header.RemovePapermillHeader"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
29496.1s 2496 warn(
29496.1s 2497 [NbConvertApp] Converting notebook __notebook__.ipynb to notebook
29496.6s 2498 [NbConvertApp] Writing 300200 bytes to __notebook__.ipynb
29499.1s 2499 /usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py:2915: FutureWarning: --Exporter.preprocessors=["nbconvert.preprocessors.ExtractOutputPreprocessor"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.
29499.1s 2500 warn(
29499.1s 2501 [NbConvertApp] Converting notebook __notebook__.ipynb to html
29499.9s 2502 [NbConvertApp] Writing 548501 bytes to __results__.html